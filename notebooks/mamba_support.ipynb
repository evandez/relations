{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b360b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "115a4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from src import models, data, lens, functional\n",
    "from src.utils import experiment_utils\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d46d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 17:36:48 src.models INFO     loading state-spaces/mamba-2.8b-slimpj (device=cuda:0, fp16=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 17:36:48 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n",
      "2024-01-31 17:36:48 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-01-31 17:37:06 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "2024-01-31 17:37:15 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "2024-01-31 17:37:15 src.models INFO     dtype: torch.float32, device: cuda:0, memory: 10.31 GB\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"mamba-3b\", device=device, fp16=False)\n",
    "# mt = models.load_model(\"gptj\", device=device, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f51154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 17:37:15 src.data DEBUG    no paths provided, using default data dir: /home/local_arnab/Codes/relations/notebooks/../data\n",
      "2024-01-31 17:37:15 src.data DEBUG    /home/local_arnab/Codes/relations/notebooks/../data is directory, globbing for json files...\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/characteristic_gender.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/degree_gender.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_birthplace.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_gender.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_religion.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/occupation_age.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/occupation_gender.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/fruit_inside_color.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/fruit_outside_color.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/object_superclass.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/substance_phase.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/task_done_by_person.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/task_done_by_tool.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/word_sentiment.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/work_location.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/city_in_country.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/company_ceo.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/company_hq.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_capital_city.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_currency.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_language.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_largest_city.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/food_from_country.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/landmark_in_country.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/landmark_on_continent.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_band_lead_singer.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_father.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_mother.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_native_language.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_occupation.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_instrument.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_position_in_sport.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_pro_sport.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_university.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/pokemon_evolutions.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/presidents_birth_year.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/presidents_election_year.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/product_by_company.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/star_constellation.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/superhero_archnemesis.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/superhero_person.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_antonym.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_comparative.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_superlative.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/verb_past_tense.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/word_first_letter.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/word_last_letter.json\n",
      "2024-01-31 17:37:15 src.data DEBUG    found 47 relation files total, loading...\n"
     ]
    }
   ],
   "source": [
    "dataset = data.load_dataset()\n",
    "\n",
    "# relation_names = [r.name for r in dataset.relations]\n",
    "# relation_options = Menu(choices = relation_names, value = relation_names)\n",
    "# show(relation_options) # !caution: tested in a juputer-notebook. baukit visualizations are not supported in vscode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a17444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 17:37:15 src.data DEBUG    filtering to only relations: ['adjective superlative']\n",
      "adjective superlative -- 80 samples\n",
      "------------------------------------------------------\n",
      "2024-01-31 17:37:15 src.utils.experiment_utils INFO     setting all seeds to 12345\n",
      "quick -> quickest\n",
      "rich -> richest\n",
      "thick -> thickest\n",
      "strong -> strongest\n",
      "great -> greatest\n"
     ]
    }
   ],
   "source": [
    "relation_name = \"adjective superlative\"\n",
    "relation = dataset.filter(relation_names=[relation_name])[0]\n",
    "print(f\"{relation.name} -- {len(relation.samples)} samples\")\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "train, test = relation.split(5)\n",
    "print(\"\\n\".join([sample.__str__() for sample in train.samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145bf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "layer = 20\n",
    "beta = 8\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "674c3c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b0dd2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(mt.model, \"backbone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a1c8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backbone.layers.20'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.determine_layer_paths(mt)[layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6748a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = mt.tokenizer.eos_token + \" Michael Jordan professionally played the sport of\"\n",
    "\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f5fa043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baukit\n",
    "\n",
    "layer_out = models.determine_layer_paths(mt)[layer]\n",
    "mixer_out = models.determine_layer_paths(mt)[layer] + \".mixer\"\n",
    "layer_in = models.determine_layer_paths(mt)[layer+1]\n",
    "final_layer = models.determine_layer_paths(mt)[-1]\n",
    "final_mixer = models.determine_layer_paths(mt)[-1] + \".mixer\"\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt.model,\n",
    "    layers=[\n",
    "        layer_out,\n",
    "        mixer_out,\n",
    "        layer_in,\n",
    "        final_mixer,\n",
    "        final_layer,\n",
    "    ],\n",
    "    retain_input=True,\n",
    ") as traces:\n",
    "    output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2368bb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5940,  1.9729, -0.7331,  ...,  2.2618, -2.4105,  0.6027],\n",
       "         [ 1.2616,  0.6781, -0.8456,  ...,  1.3468, -2.0678,  3.0296],\n",
       "         [-0.0950,  1.0767, -0.0086,  ..., -0.8217,  0.7617,  0.6352],\n",
       "         ...,\n",
       "         [ 7.5944,  2.9077, -2.3740,  ..., -2.0662,  0.9440, -1.2279],\n",
       "         [-7.4484, -2.3972, -2.6358,  ..., -4.6405, -0.2366,  1.1990],\n",
       "         [-2.2326, -0.7476, -2.6844,  ..., -3.6317,  1.6523, -0.6629]]],\n",
       "       device='cuda:0', grad_fn=<MambaInnerFnBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces[final_mixer].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b400e94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.5940,  1.9729, -0.7331,  ...,  2.2618, -2.4105,  0.6027],\n",
       "          [ 1.2616,  0.6781, -0.8456,  ...,  1.3468, -2.0678,  3.0296],\n",
       "          [-0.0950,  1.0767, -0.0086,  ..., -0.8217,  0.7617,  0.6352],\n",
       "          ...,\n",
       "          [ 7.5944,  2.9077, -2.3740,  ..., -2.0662,  0.9440, -1.2279],\n",
       "          [-7.4484, -2.3972, -2.6358,  ..., -4.6405, -0.2366,  1.1990],\n",
       "          [-2.2326, -0.7476, -2.6844,  ..., -3.6317,  1.6523, -0.6629]]],\n",
       "        device='cuda:0', grad_fn=<MambaInnerFnBackward>),\n",
       " tensor([[[-2.9466,  0.8577,  3.0205,  ...,  0.9754, -0.4319, -1.6834],\n",
       "          [-0.6205,  0.6147,  0.7412,  ...,  2.2544, -3.0231,  1.3576],\n",
       "          [-0.1985, -1.1145, -0.9235,  ..., -0.4823, -0.7575, -1.0683],\n",
       "          ...,\n",
       "          [ 4.5634,  1.1499, -1.6278,  ..., -5.0547, -6.7761, -7.6065],\n",
       "          [ 3.3821, -3.7479, -3.7378,  ..., -5.0487, -9.0620, -2.6670],\n",
       "          [ 3.8406, -3.8000, -4.0094,  ..., -1.7394, -5.0764, -2.5944]]],\n",
       "        device='cuda:0', grad_fn=<LayerNormFnBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traces[final_layer].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e90b6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(traces[mixer_out].output, traces[layer_out].output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d238f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(mt.model, \"backbone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc342cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c755d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something\n"
     ]
    }
   ],
   "source": [
    "print(\"something\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b33032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 17:49:32 src.operators DEBUG    estimating J for prompt:\n",
      "<|endoftext|> The superlative form of great is greatest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of quick is\n",
      "2024-01-31 17:49:32 src.operators DEBUG    note that subject=quick, h_index=27\n",
      "h.shape=torch.Size([2560]) | h.requires_grad=True\n",
      "============> h.shape=torch.Size([2560])  |  hs[0, _h_index].shape=torch.Size([2560])  |  hs.shape=torch.Size([1, 29, 2560])\n",
      "True\n",
      "hs[0, _h_index]=tensor([ 0.0283,  0.0254, -0.0428,  ...,  0.1103, -0.0791, -0.0631],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "hs=tensor([[[-1.3572e-01, -3.0308e-01,  1.7413e-01,  ...,  2.6154e-01,\n",
      "          -1.8122e-01,  2.8485e-02],\n",
      "         [ 2.9972e-02, -1.6609e-01,  2.7416e-01,  ...,  1.4466e-01,\n",
      "           1.0326e-01, -6.8223e-02],\n",
      "         [ 3.1619e-01, -1.8137e-02,  1.3349e-01,  ..., -1.3597e-01,\n",
      "           7.1534e-03,  2.8467e-01],\n",
      "         ...,\n",
      "         [ 6.2527e-02, -9.4892e-02,  3.4228e-02,  ...,  1.3772e-01,\n",
      "          -2.5986e-02, -4.7467e-03],\n",
      "         [ 2.8289e-02,  2.5381e-02, -4.2841e-02,  ...,  1.1031e-01,\n",
      "          -7.9059e-02, -6.3080e-02],\n",
      "         [ 5.9596e-02, -1.3685e-04,  6.5397e-02,  ...,  9.1043e-02,\n",
      "          -6.5928e-02, -8.4913e-02]]], device='cuda:0',\n",
      "       grad_fn=<LayerNormFnBackward>)\n",
      "torch.Size([1, 29, 2560]) True\n",
      "h=tensor([ 0.0283,  0.0254, -0.0428,  ...,  0.1103, -0.0791, -0.0631],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_hs[0, _h_index]=tensor([ 0.0283,  0.0254, -0.0428,  ...,  0.1103, -0.0791, -0.0631],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Calculating Jacobians ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8bff90230f4dd29c81d5ada6b66ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 17:56:10 src.operators DEBUG    estimating J for prompt:\n",
      "<|endoftext|> The superlative form of great is greatest\n",
      "The superlative form of quick is quickest\n",
      "The superlative form of rich is\n",
      "2024-01-31 17:56:10 src.operators DEBUG    note that subject=rich, h_index=28\n",
      "h.shape=torch.Size([2560]) | h.requires_grad=True\n",
      "============> h.shape=torch.Size([2560])  |  hs[0, _h_index].shape=torch.Size([2560])  |  hs.shape=torch.Size([1, 30, 2560])\n",
      "True\n",
      "hs[0, _h_index]=tensor([ 0.4376, -0.0241, -0.0391,  ...,  0.1739, -0.0989, -0.0482],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "hs=tensor([[[-0.1357, -0.3031,  0.1741,  ...,  0.2615, -0.1812,  0.0285],\n",
      "         [ 0.0300, -0.1661,  0.2742,  ...,  0.1447,  0.1033, -0.0682],\n",
      "         [ 0.3162, -0.0181,  0.1335,  ..., -0.1360,  0.0072,  0.2847],\n",
      "         ...,\n",
      "         [ 0.0635, -0.0819,  0.0294,  ...,  0.1513, -0.0310, -0.0109],\n",
      "         [ 0.4376, -0.0241, -0.0391,  ...,  0.1739, -0.0989, -0.0482],\n",
      "         [ 0.0713, -0.0845,  0.0192,  ...,  0.0982, -0.0391, -0.0409]]],\n",
      "       device='cuda:0', grad_fn=<LayerNormFnBackward>)\n",
      "torch.Size([1, 30, 2560]) True\n",
      "h=tensor([ 0.4376, -0.0241, -0.0391,  ...,  0.1739, -0.0989, -0.0482],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_hs[0, _h_index]=tensor([ 0.4376, -0.0241, -0.0391,  ...,  0.1739, -0.0989, -0.0482],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Calculating Jacobians ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dd14cbdbdc4d77881041e861a743df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:03:20 src.operators DEBUG    estimating J for prompt:\n",
      "<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of thick is\n",
      "2024-01-31 18:03:20 src.operators DEBUG    note that subject=thick, h_index=28\n",
      "h.shape=torch.Size([2560]) | h.requires_grad=True\n",
      "============> h.shape=torch.Size([2560])  |  hs[0, _h_index].shape=torch.Size([2560])  |  hs.shape=torch.Size([1, 30, 2560])\n",
      "True\n",
      "hs[0, _h_index]=tensor([ 0.1792, -0.1925,  0.1866,  ...,  0.1049,  0.0875, -0.1577],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "hs=tensor([[[-0.1357, -0.3031,  0.1741,  ...,  0.2615, -0.1812,  0.0285],\n",
      "         [ 0.0300, -0.1661,  0.2742,  ...,  0.1447,  0.1033, -0.0682],\n",
      "         [ 0.3162, -0.0181,  0.1335,  ..., -0.1360,  0.0072,  0.2847],\n",
      "         ...,\n",
      "         [ 0.0618, -0.0891,  0.0310,  ...,  0.1397, -0.0154, -0.0161],\n",
      "         [ 0.1792, -0.1925,  0.1866,  ...,  0.1049,  0.0875, -0.1577],\n",
      "         [ 0.0570, -0.0134,  0.0744,  ...,  0.1234, -0.0077, -0.0785]]],\n",
      "       device='cuda:0', grad_fn=<LayerNormFnBackward>)\n",
      "torch.Size([1, 30, 2560]) True\n",
      "h=tensor([ 0.1792, -0.1925,  0.1866,  ...,  0.1049,  0.0875, -0.1577],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_hs[0, _h_index]=tensor([ 0.1792, -0.1925,  0.1866,  ...,  0.1049,  0.0875, -0.1577],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Calculating Jacobians ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711d22513a6342cfa27a8e6079682543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:10:20 src.operators DEBUG    estimating J for prompt:\n",
      "<|endoftext|> The superlative form of thick is thickest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of strong is\n",
      "2024-01-31 18:10:20 src.operators DEBUG    note that subject=strong, h_index=28\n",
      "h.shape=torch.Size([2560]) | h.requires_grad=True\n",
      "============> h.shape=torch.Size([2560])  |  hs[0, _h_index].shape=torch.Size([2560])  |  hs.shape=torch.Size([1, 30, 2560])\n",
      "True\n",
      "hs[0, _h_index]=tensor([ 0.0335,  0.0232, -0.3097,  ...,  0.1790,  0.0421,  0.0165],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "hs=tensor([[[-0.1357, -0.3031,  0.1741,  ...,  0.2615, -0.1812,  0.0285],\n",
      "         [ 0.0300, -0.1661,  0.2742,  ...,  0.1447,  0.1033, -0.0682],\n",
      "         [ 0.3162, -0.0181,  0.1335,  ..., -0.1360,  0.0072,  0.2847],\n",
      "         ...,\n",
      "         [ 0.0646, -0.0785,  0.0285,  ...,  0.1414, -0.0181, -0.0070],\n",
      "         [ 0.0335,  0.0232, -0.3097,  ...,  0.1790,  0.0421,  0.0165],\n",
      "         [ 0.0273, -0.0260,  0.0762,  ...,  0.1105, -0.0217, -0.0855]]],\n",
      "       device='cuda:0', grad_fn=<LayerNormFnBackward>)\n",
      "torch.Size([1, 30, 2560]) True\n",
      "h=tensor([ 0.0335,  0.0232, -0.3097,  ...,  0.1790,  0.0421,  0.0165],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_hs[0, _h_index]=tensor([ 0.0335,  0.0232, -0.3097,  ...,  0.1790,  0.0421,  0.0165],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Calculating Jacobians ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54772500bd844e5b86fee13babf2f619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:17:21 src.operators DEBUG    estimating J for prompt:\n",
      "<|endoftext|> The superlative form of strong is strongest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is\n",
      "2024-01-31 18:17:21 src.operators DEBUG    note that subject=great, h_index=27\n",
      "h.shape=torch.Size([2560]) | h.requires_grad=True\n",
      "============> h.shape=torch.Size([2560])  |  hs[0, _h_index].shape=torch.Size([2560])  |  hs.shape=torch.Size([1, 29, 2560])\n",
      "True\n",
      "hs[0, _h_index]=tensor([ 0.1518,  0.0916,  0.1254,  ...,  0.1513,  0.0455, -0.1086],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "hs=tensor([[[-0.1357, -0.3031,  0.1741,  ...,  0.2615, -0.1812,  0.0285],\n",
      "         [ 0.0300, -0.1661,  0.2742,  ...,  0.1447,  0.1033, -0.0682],\n",
      "         [ 0.3162, -0.0181,  0.1335,  ..., -0.1360,  0.0072,  0.2847],\n",
      "         ...,\n",
      "         [ 0.0586, -0.0954,  0.0282,  ...,  0.1394, -0.0248, -0.0157],\n",
      "         [ 0.1518,  0.0916,  0.1254,  ...,  0.1513,  0.0455, -0.1086],\n",
      "         [ 0.1030, -0.0233,  0.1251,  ...,  0.1093, -0.1207, -0.1453]]],\n",
      "       device='cuda:0', grad_fn=<LayerNormFnBackward>)\n",
      "torch.Size([1, 29, 2560]) True\n",
      "h=tensor([ 0.1518,  0.0916,  0.1254,  ...,  0.1513,  0.0455, -0.1086],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "new_hs[0, _h_index]=tensor([ 0.1518,  0.0916,  0.1254,  ...,  0.1513,  0.0455, -0.1086],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "Calculating Jacobians ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b234dbf047ef451aa4e61242be7fa3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.operators import JacobianIclMeanEstimator\n",
    "\n",
    "estimator = JacobianIclMeanEstimator(\n",
    "    mt = mt, \n",
    "    h_layer = layer,\n",
    "    beta = beta\n",
    ")\n",
    "operator = estimator(\n",
    "    relation.set(\n",
    "        samples=train.samples, \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63c5aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaLMHeadModel(\n",
       "  (backbone): MixerModel(\n",
       "    (embedding): Embedding(50280, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (24): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (25): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (26): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (27): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (28): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (29): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (30): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (31): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (32): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (33): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (34): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (35): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (36): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (37): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (38): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (39): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (40): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (41): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (42): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (43): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (44): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (45): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (46): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (47): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (48): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (49): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (50): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (51): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (52): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (53): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (54): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (55): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (56): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (57): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (58): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (59): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (60): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (61): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (62): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (63): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1dac42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Jh': [tensor([ 0.7549, -0.1307, -0.0154,  ..., -0.1416, -0.7521, -0.7254]),\n",
       "  tensor([-0.5954,  0.0357, -0.4120,  ...,  0.6513, -0.7774, -0.2348]),\n",
       "  tensor([-0.4962,  0.4409, -0.0178,  ..., -0.2932, -1.0436,  0.5390]),\n",
       "  tensor([-0.1647, -0.5315, -0.3003,  ...,  0.5408,  0.3185, -0.6637]),\n",
       "  tensor([-0.1539, -0.1978,  0.1350,  ...,  0.4827, -0.8228, -0.3690])],\n",
       " '|w|': [254.1029510498047,\n",
       "  206.6474151611328,\n",
       "  297.90087890625,\n",
       "  274.16131591796875,\n",
       "  310.1672668457031],\n",
       " '|b|': [273.321533203125,\n",
       "  266.7347717285156,\n",
       "  283.2568664550781,\n",
       "  309.2726135253906,\n",
       "  285.7717590332031]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "operator.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dfcbb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(' most', 49.004),\n",
       "  (' greatest', 46.628),\n",
       "  (' the', 44.854),\n",
       "  (' richest', 43.963),\n",
       "  ('\\n', 43.172),\n",
       "  (' (', 42.98),\n",
       "  (',', 42.945),\n",
       "  (' best', 42.763),\n",
       "  (' biggest', 42.729),\n",
       "  (' f', 42.31)],\n",
       " {})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.lens import logit_lens\n",
    "from src import models\n",
    "\n",
    "logit_lens(mt = mt, h = operator.metadata[\"Jh\"][0].to(models.determine_device(mt)) + operator.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4ad24c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' \"', prob=0.09106093645095825),\n",
       "  PredictedToken(token=' not', prob=0.08697717636823654),\n",
       "  PredictedToken(token=' good', prob=0.07184084504842758),\n",
       "  PredictedToken(token=' the', prob=0.06490873545408249),\n",
       "  PredictedToken(token=' better', prob=0.06266643106937408)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    # prompt = mt.tokenizer.eos_token + \" The capital of {} is\".format(\"France\"),\n",
    "    prompt = mt.tokenizer.eos_token + \" The superlative of {} is\".format(\"good\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b6eda",
   "metadata": {},
   "source": [
    "# Checking $faithfulness$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d79b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:25:48 src.functional DEBUG    filtering for knowns using prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of {} is\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='shy', sample.object='shyest', predicted=' shy' (p=0.983), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='tall', sample.object='tallest', predicted=' tall' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='healthy', sample.object='healthiest', predicted=' health' (p=0.971), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='loud', sample.object='loudest', predicted=' loud' (p=0.998), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='hard', sample.object='hardest', predicted=' hardest' (p=1.000), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='polite', sample.object='politest', predicted=' polit' (p=0.893), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='hot', sample.object='hottest', predicted=' hottest' (p=0.995), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='smooth', sample.object='smoothest', predicted=' smoot' (p=0.930), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='big', sample.object='biggest', predicted=' biggest' (p=0.998), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='mad', sample.object='maddest', predicted=' mad' (p=0.872), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='zesty', sample.object='zestiest', predicted=' z' (p=0.991), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='tough', sample.object='toughest', predicted=' toug' (p=0.992), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='cold', sample.object='coldest', predicted=' cold' (p=0.982), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='calm', sample.object='calmest', predicted=' calm' (p=0.868), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='fast', sample.object='fastest', predicted=' fastest' (p=0.997), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='wild', sample.object='wildest', predicted=' wild' (p=0.980), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='true', sample.object='truest', predicted=' tr' (p=0.941), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='brave', sample.object='bravest', predicted=' brav' (p=0.957), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='clean', sample.object='cleanest', predicted=' clean' (p=0.962), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='safe', sample.object='safest', predicted=' saf' (p=0.997), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='low', sample.object='lowest', predicted=' lowest' (p=0.979), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='lazy', sample.object='laziest', predicted=' la' (p=0.980), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='thin', sample.object='thinnest', predicted=' th' (p=0.970), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='fresh', sample.object='freshest', predicted=' fres' (p=0.901), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='easy', sample.object='easiest', predicted=' easiest' (p=0.986), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='high', sample.object='highest', predicted=' highest' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='dry', sample.object='driest', predicted=' dri' (p=0.966), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='wise', sample.object='wisest', predicted=' wis' (p=0.696), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='wrong', sample.object='wrongest', predicted=' wrong' (p=0.918), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='light', sample.object='lightest', predicted=' light' (p=0.963), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='messy', sample.object='messiest', predicted=' mess' (p=0.904), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='cheap', sample.object='cheapest', predicted=' cheapest' (p=0.988), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='fierce', sample.object='fiercest', predicted=' fierc' (p=0.958), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='sweet', sample.object='sweetest', predicted=' sweet' (p=0.933), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='small', sample.object='smallest', predicted=' smallest' (p=0.992), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='simple', sample.object='simplest', predicted=' simplest' (p=0.900), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='mean', sample.object='meanest', predicted=' mean' (p=0.871), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='angry', sample.object='angriest', predicted=' ang' (p=0.990), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='smart', sample.object='smartest', predicted=' smart' (p=0.977), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='narrow', sample.object='narrowest', predicted=' narrow' (p=0.996), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='slow', sample.object='slowest', predicted=' slow' (p=0.981), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='poor', sample.object='poorest', predicted=' poorest' (p=0.992), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='quiet', sample.object='quietest', predicted=' quiet' (p=0.993), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='heavy', sample.object='heaviest', predicted=' heav' (p=0.991), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='young', sample.object='youngest', predicted=' youngest' (p=0.996), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='weak', sample.object='weakest', predicted=' weak' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='full', sample.object='fullest', predicted=' full' (p=0.994), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='deep', sample.object='deepest', predicted=' deepest' (p=0.995), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='bright', sample.object='brightest', predicted=' brightest' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='new', sample.object='newest', predicted=' newest' (p=0.941), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='dirty', sample.object='dirtiest', predicted=' dirt' (p=0.992), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='crazy', sample.object='craziest', predicted=' c' (p=0.992), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='cruel', sample.object='cruelest', predicted=' cru' (p=0.500), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='hungry', sample.object='hungriest', predicted=' hung' (p=0.986), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='happy', sample.object='happiest', predicted=' happ' (p=0.995), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='ugly', sample.object='ugliest', predicted=' ug' (p=0.983), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='tiny', sample.object='tiniest', predicted=' t' (p=0.917), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='dark', sample.object='darkest', predicted=' dark' (p=0.994), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='near', sample.object='nearest', predicted=' nearest' (p=0.948), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='gentle', sample.object='gentlest', predicted=' gent' (p=0.978), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='funny', sample.object='funniest', predicted=' fun' (p=0.998), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='kind', sample.object='kindest', predicted=' kind' (p=0.990), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='wide', sample.object='widest', predicted=' wid' (p=0.997), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='dull', sample.object='dullest', predicted=' dull' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='witty', sample.object='wittiest', predicted=' w' (p=0.522), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='friendly', sample.object='friendliest', predicted=' friend' (p=0.992), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='short', sample.object='shortest', predicted=' shortest' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='wet', sample.object='wettest', predicted=' wet' (p=0.996), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='large', sample.object='largest', predicted=' largest' (p=0.999), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='good', sample.object='best', predicted=' greatest' (p=0.545), known=(✗)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='old', sample.object='oldest', predicted=' oldest' (p=0.995), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='long', sample.object='longest', predicted=' longest' (p=0.998), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='bad', sample.object='worst', predicted=' worst' (p=0.527), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='sad', sample.object='saddest', predicted=' sadd' (p=0.987), known=(✓)\n",
      "2024-01-31 18:25:51 src.functional DEBUG    sample.subject='little', sample.object='smallest', predicted=' least' (p=0.796), known=(✗)\n"
     ]
    }
   ],
   "source": [
    "test = functional.filter_relation_samples_based_on_provided_fewshots(\n",
    "    mt=mt, test_relation=test, prompt_template=operator.prompt_template, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ad18a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy -> happiest\n",
      "2024-01-31 18:25:54 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of happy is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' happ', prob=0.9729710221290588),\n",
       " PredictedToken(token='happ', prob=0.014340016059577465),\n",
       " PredictedToken(token=' Happ', prob=0.011374825611710548),\n",
       " PredictedToken(token=' happiness', prob=0.00113575195427984),\n",
       " PredictedToken(token=' happier', prob=9.16872886591591e-05)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [s for s in test.samples if s.subject == \"happy\"][0]\n",
    "print(sample)\n",
    "operator(subject = sample.subject).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e717d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject],\n",
    "    h_layer= operator.h_layer,\n",
    ")\n",
    "h = hs_and_zs.h_by_subj[sample.subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69136b",
   "metadata": {},
   "source": [
    "## Approximating LM computation $F$ as an affine transformation\n",
    "\n",
    "### $$ F(\\mathbf{s}, c_r) \\approx \\beta \\, W_r \\mathbf{s} + b_r $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8bf8b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(' happ', 0.995),\n",
       "  (' Happ', 0.003),\n",
       "  ('happ', 0.002),\n",
       "  (' happiness', 0.0),\n",
       "  (' happier', 0.0),\n",
       "  (' happy', 0.0),\n",
       "  (' richest', 0.0),\n",
       "  (' unh', 0.0),\n",
       "  (' Happy', 0.0),\n",
       "  (' health', 0.0)],\n",
       " {})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 5 * (operator.weight @ h) + operator.bias\n",
    "\n",
    "lens.logit_lens(\n",
    "    mt = mt,\n",
    "    h = z,\n",
    "    get_proba = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0725d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of angry is\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.subject='angry', sample.object='angriest', predicted=\" ang\", (p=0.775745689868927), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of bad is\"\n",
      "sample.subject='bad', sample.object='worst', predicted=\" bad\", (p=0.9749193787574768), known=(✗)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of big is\"\n",
      "sample.subject='big', sample.object='biggest', predicted=\" biggest\", (p=0.5625869035720825), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of brave is\"\n",
      "sample.subject='brave', sample.object='bravest', predicted=\" brav\", (p=0.9575327038764954), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of bright is\"\n",
      "sample.subject='bright', sample.object='brightest', predicted=\" brightest\", (p=0.40108248591423035), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of calm is\"\n",
      "sample.subject='calm', sample.object='calmest', predicted=\" calm\", (p=0.999763548374176), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of cheap is\"\n",
      "sample.subject='cheap', sample.object='cheapest', predicted=\" cheapest\", (p=0.7544383406639099), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of clean is\"\n",
      "sample.subject='clean', sample.object='cleanest', predicted=\" clean\", (p=0.998528242111206), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of cold is\"\n",
      "sample.subject='cold', sample.object='coldest', predicted=\" cold\", (p=0.9945520758628845), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of crazy is\"\n",
      "sample.subject='crazy', sample.object='craziest', predicted=\" Cra\", (p=0.7701652646064758), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of cruel is\"\n",
      "sample.subject='cruel', sample.object='cruelest', predicted=\" cruel\", (p=0.8837106227874756), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of dark is\"\n",
      "sample.subject='dark', sample.object='darkest', predicted=\" dark\", (p=0.9957723021507263), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of deep is\"\n",
      "sample.subject='deep', sample.object='deepest', predicted=\" deep\", (p=0.4586693346500397), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of dirty is\"\n",
      "sample.subject='dirty', sample.object='dirtiest', predicted=\" dirt\", (p=0.9808223843574524), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of dry is\"\n",
      "sample.subject='dry', sample.object='driest', predicted=\" dry\", (p=0.9266034960746765), known=(✗)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of dull is\"\n",
      "sample.subject='dull', sample.object='dullest', predicted=\" dull\", (p=0.9999997615814209), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of easy is\"\n",
      "sample.subject='easy', sample.object='easiest', predicted=\" easiest\", (p=0.9928169250488281), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of fast is\"\n",
      "sample.subject='fast', sample.object='fastest', predicted=\" fastest\", (p=0.9924682974815369), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of fierce is\"\n",
      "sample.subject='fierce', sample.object='fiercest', predicted=\" fierc\", (p=0.7227872014045715), known=(✓)\n",
      "2024-01-31 18:26:02 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of fresh is\"\n",
      "sample.subject='fresh', sample.object='freshest', predicted=\" fresh\", (p=0.6980343461036682), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of friendly is\"\n",
      "sample.subject='friendly', sample.object='friendliest', predicted=\" friend\", (p=0.9637898206710815), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of full is\"\n",
      "sample.subject='full', sample.object='fullest', predicted=\" full\", (p=0.9995930790901184), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of funny is\"\n",
      "sample.subject='funny', sample.object='funniest', predicted=\" fun\", (p=0.9983420372009277), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of gentle is\"\n",
      "sample.subject='gentle', sample.object='gentlest', predicted=\" gentle\", (p=0.8224493265151978), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of happy is\"\n",
      "sample.subject='happy', sample.object='happiest', predicted=\" happ\", (p=0.9729710221290588), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of hard is\"\n",
      "sample.subject='hard', sample.object='hardest', predicted=\" hardest\", (p=0.998719334602356), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of healthy is\"\n",
      "sample.subject='healthy', sample.object='healthiest', predicted=\" health\", (p=0.9853364825248718), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of heavy is\"\n",
      "sample.subject='heavy', sample.object='heaviest', predicted=\" heavy\", (p=0.9446228742599487), known=(✗)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of high is\"\n",
      "sample.subject='high', sample.object='highest', predicted=\" highest\", (p=0.7975645661354065), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of hot is\"\n",
      "sample.subject='hot', sample.object='hottest', predicted=\" hot\", (p=0.8139018416404724), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of hungry is\"\n",
      "sample.subject='hungry', sample.object='hungriest', predicted=\" hungry\", (p=0.40508055686950684), known=(✗)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of kind is\"\n",
      "sample.subject='kind', sample.object='kindest', predicted=\" KIND\", (p=0.9274871349334717), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of large is\"\n",
      "sample.subject='large', sample.object='largest', predicted=\" largest\", (p=0.9105159640312195), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of lazy is\"\n",
      "sample.subject='lazy', sample.object='laziest', predicted=\" lazy\", (p=0.9972719550132751), known=(✗)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of light is\"\n",
      "sample.subject='light', sample.object='lightest', predicted=\" light\", (p=0.9966986775398254), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of long is\"\n",
      "sample.subject='long', sample.object='longest', predicted=\" longest\", (p=0.9777936339378357), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of loud is\"\n",
      "sample.subject='loud', sample.object='loudest', predicted=\" loud\", (p=0.9997989535331726), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of low is\"\n",
      "sample.subject='low', sample.object='lowest', predicted=\" lowest\", (p=0.9334912300109863), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of mad is\"\n",
      "sample.subject='mad', sample.object='maddest', predicted=\" mad\", (p=0.9458179473876953), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of mean is\"\n",
      "sample.subject='mean', sample.object='meanest', predicted=\" mean\", (p=0.9687018394470215), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of messy is\"\n",
      "sample.subject='messy', sample.object='messiest', predicted=\" messy\", (p=0.9951819777488708), known=(✗)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of narrow is\"\n",
      "sample.subject='narrow', sample.object='narrowest', predicted=\" narrow\", (p=0.9999765157699585), known=(✓)\n",
      "2024-01-31 18:26:03 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of near is\"\n",
      "sample.subject='near', sample.object='nearest', predicted=\" farther\", (p=0.2911508083343506), known=(✗)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of new is\"\n",
      "sample.subject='new', sample.object='newest', predicted=\" greatest\", (p=0.40924710035324097), known=(✗)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of old is\"\n",
      "sample.subject='old', sample.object='oldest', predicted=\" oldest\", (p=0.7740670442581177), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of polite is\"\n",
      "sample.subject='polite', sample.object='politest', predicted=\" polite\", (p=0.7188719511032104), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of poor is\"\n",
      "sample.subject='poor', sample.object='poorest', predicted=\" poorest\", (p=0.9748165011405945), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of quiet is\"\n",
      "sample.subject='quiet', sample.object='quietest', predicted=\" quiet\", (p=0.9999024868011475), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of sad is\"\n",
      "sample.subject='sad', sample.object='saddest', predicted=\" sadd\", (p=0.4435186982154846), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of safe is\"\n",
      "sample.subject='safe', sample.object='safest', predicted=\" saf\", (p=0.8660973310470581), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of short is\"\n",
      "sample.subject='short', sample.object='shortest', predicted=\" shortest\", (p=0.6514906287193298), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of shy is\"\n",
      "sample.subject='shy', sample.object='shyest', predicted=\" shy\", (p=0.9999773502349854), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of simple is\"\n",
      "sample.subject='simple', sample.object='simplest', predicted=\" most\", (p=0.3800671100616455), known=(✗)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of slow is\"\n",
      "sample.subject='slow', sample.object='slowest', predicted=\" slow\", (p=0.7402400374412537), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of small is\"\n",
      "sample.subject='small', sample.object='smallest', predicted=\" biggest\", (p=0.3304924964904785), known=(✗)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of smart is\"\n",
      "sample.subject='smart', sample.object='smartest', predicted=\" smart\", (p=0.9968915581703186), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of smooth is\"\n",
      "sample.subject='smooth', sample.object='smoothest', predicted=\" smooth\", (p=0.9990033507347107), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of sweet is\"\n",
      "sample.subject='sweet', sample.object='sweetest', predicted=\" sweet\", (p=0.986024022102356), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of tall is\"\n",
      "sample.subject='tall', sample.object='tallest', predicted=\" tall\", (p=0.9672069549560547), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of thin is\"\n",
      "sample.subject='thin', sample.object='thinnest', predicted=\" thin\", (p=0.9979992508888245), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of tiny is\"\n",
      "sample.subject='tiny', sample.object='tiniest', predicted=\" tiny\", (p=0.906904399394989), known=(✗)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of tough is\"\n",
      "sample.subject='tough', sample.object='toughest', predicted=\" toug\", (p=0.6014488339424133), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of true is\"\n",
      "sample.subject='true', sample.object='truest', predicted=\" tr\", (p=0.5633991956710815), known=(✓)\n",
      "2024-01-31 18:26:04 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of ugly is\"\n",
      "sample.subject='ugly', sample.object='ugliest', predicted=\" ug\", (p=0.9163463115692139), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of weak is\"\n",
      "sample.subject='weak', sample.object='weakest', predicted=\" weak\", (p=0.9989797472953796), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of wet is\"\n",
      "sample.subject='wet', sample.object='wettest', predicted=\" wet\", (p=0.9999493360519409), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of wide is\"\n",
      "sample.subject='wide', sample.object='widest', predicted=\" wid\", (p=0.7724905014038086), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of wild is\"\n",
      "sample.subject='wild', sample.object='wildest', predicted=\" wild\", (p=0.9953979849815369), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of wise is\"\n",
      "sample.subject='wise', sample.object='wisest', predicted=\" wise\", (p=0.9367215037345886), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of witty is\"\n",
      "sample.subject='witty', sample.object='wittiest', predicted=\" merry\", (p=0.43980351090431213), known=(✗)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of wrong is\"\n",
      "sample.subject='wrong', sample.object='wrongest', predicted=\" most\", (p=0.6151532530784607), known=(✗)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of young is\"\n",
      "sample.subject='young', sample.object='youngest', predicted=\" youngest\", (p=0.9988935589790344), known=(✓)\n",
      "2024-01-31 18:26:05 src.operators DEBUG    computing h from prompt \"<|endoftext|> The superlative form of quick is quickest\n",
      "The superlative form of rich is richest\n",
      "The superlative form of thick is thickest\n",
      "The superlative form of strong is strongest\n",
      "The superlative form of great is greatest\n",
      "The superlative form of zesty is\"\n",
      "sample.subject='zesty', sample.object='zestiest', predicted=\" spicy\", (p=0.4157714545726776), known=(✗)\n",
      "------------------------------------------------------------\n",
      "Faithfulness (@1) = 0.8082191780821918\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for sample in test.samples:\n",
    "    predictions = operator(subject = sample.subject).predictions\n",
    "    known_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=predictions[0].token, target=sample.object\n",
    "    )\n",
    "    print(f\"{sample.subject=}, {sample.object=}, \", end=\"\")\n",
    "    print(f'predicted=\"{functional.format_whitespace(predictions[0].token)}\", (p={predictions[0].prob}), known=({functional.get_tick_marker(known_flag)})')\n",
    "    \n",
    "    correct += known_flag\n",
    "    wrong += not known_flag\n",
    "    \n",
    "faithfulness = correct/(correct + wrong)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Faithfulness (@1) = {faithfulness}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a13389",
   "metadata": {},
   "source": [
    "# $causality$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da2f8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "rank = 100\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25ac7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-31 18:26:10 src.utils.experiment_utils INFO     setting all seeds to 12345\n"
     ]
    }
   ],
   "source": [
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "test_targets = functional.random_edit_targets(test.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d83c9b",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a13c0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Changing the mapping (angry -> angriest) to (angry -> smallest)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = test.samples[0]\n",
    "target = test_targets[source]\n",
    "\n",
    "f\"Changing the mapping ({source}) to ({source.subject} -> {target.object})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f67c8",
   "metadata": {},
   "source": [
    "### Calculate $\\Delta \\mathbf{s}$ such that $\\mathbf{s} + \\Delta \\mathbf{s} \\approx \\mathbf{s}'$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img align=\"center\" src=\"../causality_crop\" style=\"width:80%;\"/>\n",
    "</p>\n",
    "\n",
    "Under the relation $r =\\, $*plays the instrument*, and given the subject $s =\\, $*Miles Davis*, the model will predict $o =\\, $*trumpet* **(a)**; and given the subject $s' =\\, $*Cat Stevens*, the model will now predict $o' =\\, $*guiter* **(b)**. \n",
    "\n",
    "If the computation from $\\mathbf{s}$ to $\\mathbf{o}$ is well-approximated by $operator$ parameterized by $W_r$ and $b_r$ **(c)**, then $\\Delta{\\mathbf{s}}$ **(d)** should tell us the direction of change from $\\mathbf{s}$ to $\\mathbf{s}'$. Thus, $\\tilde{\\mathbf{s}}=\\mathbf{s}+\\Delta\\mathbf{s}$ would be an approximation of $\\mathbf{s}'$ and patching $\\tilde{\\mathbf{s}}$ in place of $\\mathbf{s}$ should change the prediction to $o'$ = *guitar* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53c632ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_s(\n",
    "    operator, \n",
    "    source_subject, \n",
    "    target_subject,\n",
    "    rank = 100,\n",
    "    fix_latent_norm = None, # if set, will fix the norms of z_source and z_target\n",
    "):\n",
    "    w_p_inv = functional.low_rank_pinv(\n",
    "        matrix = operator.weight,\n",
    "        rank=rank,\n",
    "    )\n",
    "    hs_and_zs = functional.compute_hs_and_zs(\n",
    "        mt = mt,\n",
    "        prompt_template = operator.prompt_template,\n",
    "        subjects = [source_subject, target_subject],\n",
    "        h_layer= operator.h_layer,\n",
    "        z_layer=-1,\n",
    "    )\n",
    "\n",
    "    z_source = hs_and_zs.z_by_subj[source_subject]\n",
    "    z_target = hs_and_zs.z_by_subj[target_subject]\n",
    "    \n",
    "    z_source *= fix_latent_norm / z_source.norm() if fix_latent_norm is not None else 1.0\n",
    "    z_target *= z_source.norm() / z_target.norm() if fix_latent_norm is not None else 1.0\n",
    "\n",
    "    delta_s = w_p_inv @  (z_target.squeeze() - z_source.squeeze())\n",
    "\n",
    "    return delta_s, hs_and_zs\n",
    "\n",
    "delta_s, hs_and_zs = get_delta_s(\n",
    "    operator = operator,\n",
    "    source_subject = source.subject,\n",
    "    target_subject = target.subject,\n",
    "    rank = rank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab1c7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' most', 0.62),\n",
       " (' smallest', 0.301),\n",
       " (' m', 0.03),\n",
       " (' shortest', 0.01),\n",
       " (' least', 0.004),\n",
       " (' biggest', 0.002),\n",
       " (' the', 0.002),\n",
       " (' mild', 0.002),\n",
       " (' might', 0.002),\n",
       " (' me', 0.001)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baukit\n",
    "\n",
    "def get_intervention(h, int_layer, subj_idx):\n",
    "    def edit_output(output, layer):\n",
    "        if(layer != int_layer):\n",
    "            return output\n",
    "        functional.untuple(output)[:, subj_idx] = h \n",
    "        return output\n",
    "    return edit_output\n",
    "\n",
    "prompt = operator.prompt_template.format(source.subject)\n",
    "\n",
    "h_index, inputs = functional.find_subject_token_index(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    subject=source.subject,\n",
    ")\n",
    "\n",
    "h_layer, z_layer = models.determine_layer_paths(model = mt, layers = [layer, -1])\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model, layers = [h_layer, z_layer],\n",
    "    edit_output=get_intervention(\n",
    "#         h = hs_and_zs.h_by_subj[source.subject],         # let the computation proceed as usual\n",
    "        h = hs_and_zs.h_by_subj[source.subject] + delta_s, # replace s with s + delta_s\n",
    "        int_layer = h_layer, \n",
    "        subj_idx = h_index\n",
    "    )\n",
    ") as traces:\n",
    "    outputs = mt(\n",
    "        input_ids = inputs.input_ids,\n",
    "        attention_mask = inputs.attention_mask,\n",
    "    )\n",
    "\n",
    "logits = outputs.logits[0][-1] if hasattr(outputs, \"logits\") else outputs[0][-1]\n",
    "lens.interpret_logits(\n",
    "    mt = mt, \n",
    "    logits = logits, \n",
    "    get_proba=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c272c1",
   "metadata": {},
   "source": [
    "## Measuring causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51efa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.editors import LowRankPInvEditor\n",
    "\n",
    "svd = torch.svd(operator.weight.float())\n",
    "editor = LowRankPInvEditor(\n",
    "    lre=operator,\n",
    "    rank=rank,\n",
    "    svd=svd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "88be35dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping angry -> smallest | edit result=' smallest' (p=0.917) | success=(✓)\n",
      "Mapping bad -> biggest | edit result=' biggest' (p=0.987) | success=(✓)\n",
      "Mapping big -> meanest | edit result=' most' (p=0.857) | success=(✗)\n",
      "Mapping brave -> saddest | edit result=' sadd' (p=0.957) | success=(✓)\n",
      "Mapping bright -> hardest | edit result=' hardest' (p=0.999) | success=(✓)\n",
      "Mapping calm -> longest | edit result=' longest' (p=0.989) | success=(✓)\n",
      "Mapping cheap -> smoothest | edit result=' smoot' (p=0.675) | success=(✓)\n",
      "Mapping clean -> fullest | edit result=' full' (p=0.972) | success=(✓)\n",
      "Mapping cold -> saddest | edit result=' sadd' (p=0.947) | success=(✓)\n",
      "Mapping crazy -> easiest | edit result=' easiest' (p=0.910) | success=(✓)\n",
      "Mapping cruel -> smoothest | edit result=' smoot' (p=0.811) | success=(✓)\n",
      "Mapping dark -> lightest | edit result=' light' (p=0.922) | success=(✓)\n",
      "Mapping deep -> zestiest | edit result=' most' (p=0.378) | success=(✗)\n",
      "Mapping dirty -> gentlest | edit result=' most' (p=0.517) | success=(✗)\n",
      "Mapping dry -> youngest | edit result=' youngest' (p=0.983) | success=(✓)\n",
      "Mapping dull -> happiest | edit result=' happ' (p=0.989) | success=(✓)\n",
      "Mapping easy -> poorest | edit result=' poorest' (p=0.949) | success=(✓)\n",
      "Mapping fast -> darkest | edit result=' dark' (p=0.973) | success=(✓)\n",
      "Mapping fierce -> wisest | edit result=' wis' (p=0.480) | success=(✓)\n",
      "Mapping fresh -> slowest | edit result=' slow' (p=0.665) | success=(✓)\n",
      "Mapping friendly -> wettest | edit result=' wet' (p=0.968) | success=(✓)\n",
      "Mapping full -> funniest | edit result=' fun' (p=0.946) | success=(✓)\n",
      "Mapping funny -> fiercest | edit result=' fierc' (p=0.803) | success=(✓)\n",
      "Mapping gentle -> heaviest | edit result=' heav' (p=0.989) | success=(✓)\n",
      "Mapping happy -> craziest | edit result=' c' (p=0.351) | success=(✓)\n",
      "Mapping hard -> happiest | edit result=' happ' (p=0.948) | success=(✓)\n",
      "Mapping healthy -> oldest | edit result=' oldest' (p=0.995) | success=(✓)\n",
      "Mapping heavy -> nearest | edit result=' nearest' (p=0.944) | success=(✓)\n",
      "Mapping high -> bravest | edit result=' brav' (p=0.641) | success=(✓)\n",
      "Mapping hot -> thinnest | edit result=' th' (p=0.963) | success=(✓)\n",
      "Mapping hungry -> oldest | edit result=' oldest' (p=0.995) | success=(✓)\n",
      "Mapping kind -> bravest | edit result=' brav' (p=0.634) | success=(✓)\n",
      "Mapping large -> widest | edit result=' wid' (p=0.995) | success=(✓)\n",
      "Mapping lazy -> smallest | edit result=' smallest' (p=0.584) | success=(✓)\n",
      "Mapping light -> angriest | edit result=' ang' (p=0.947) | success=(✓)\n",
      "Mapping long -> angriest | edit result=' ang' (p=0.921) | success=(✓)\n",
      "Mapping loud -> friendliest | edit result=' most' (p=0.468) | success=(✗)\n",
      "Mapping low -> funniest | edit result=' fun' (p=0.975) | success=(✓)\n",
      "Mapping mad -> loudest | edit result=' loud' (p=0.988) | success=(✓)\n",
      "Mapping mean -> deepest | edit result=' deepest' (p=0.982) | success=(✓)\n",
      "Mapping messy -> smallest | edit result=' smallest' (p=0.844) | success=(✓)\n",
      "Mapping narrow -> dirtiest | edit result=' dirt' (p=0.945) | success=(✓)\n",
      "Mapping near -> gentlest | edit result=' most' (p=0.843) | success=(✗)\n",
      "Mapping new -> safest | edit result=' saf' (p=0.997) | success=(✓)\n",
      "Mapping old -> hottest | edit result=' hottest' (p=0.998) | success=(✓)\n",
      "Mapping polite -> wisest | edit result=' w' (p=0.815) | success=(✓)\n",
      "Mapping poor -> nearest | edit result=' nearest' (p=0.960) | success=(✓)\n",
      "Mapping quiet -> calmest | edit result=' calm' (p=0.864) | success=(✓)\n",
      "Mapping sad -> hottest | edit result=' hottest' (p=0.994) | success=(✓)\n",
      "Mapping safe -> dullest | edit result=' dull' (p=0.957) | success=(✓)\n",
      "Mapping short -> weakest | edit result=' weak' (p=0.994) | success=(✓)\n",
      "Mapping shy -> heaviest | edit result=' heav' (p=0.982) | success=(✓)\n",
      "Mapping simple -> zestiest | edit result=' z' (p=0.359) | success=(✓)\n",
      "Mapping slow -> gentlest | edit result=' most' (p=0.554) | success=(✗)\n",
      "Mapping small -> largest | edit result=' largest' (p=0.992) | success=(✓)\n",
      "Mapping smart -> smoothest | edit result=' smoot' (p=0.967) | success=(✓)\n",
      "Mapping smooth -> wildest | edit result=' wild' (p=0.772) | success=(✓)\n",
      "Mapping sweet -> easiest | edit result=' easiest' (p=0.860) | success=(✓)\n",
      "Mapping tall -> calmest | edit result=' quiet' (p=0.582) | success=(✗)\n",
      "Mapping thin -> fullest | edit result=' full' (p=0.940) | success=(✓)\n",
      "Mapping tiny -> maddest | edit result=' most' (p=0.653) | success=(✗)\n",
      "Mapping tough -> worst | edit result=' worst' (p=0.590) | success=(✓)\n",
      "Mapping true -> freshest | edit result=' fres' (p=0.783) | success=(✓)\n",
      "Mapping ugly -> hottest | edit result=' hottest' (p=0.997) | success=(✓)\n",
      "Mapping weak -> oldest | edit result=' oldest' (p=0.990) | success=(✓)\n",
      "Mapping wet -> wrongest | edit result=' worst' (p=0.238) | success=(✗)\n",
      "Mapping wide -> newest | edit result=' newest' (p=0.820) | success=(✓)\n",
      "Mapping wild -> friendliest | edit result=' most' (p=0.567) | success=(✗)\n",
      "Mapping wise -> safest | edit result=' saf' (p=0.991) | success=(✓)\n",
      "Mapping witty -> narrowest | edit result=' narrow' (p=0.805) | success=(✓)\n",
      "Mapping wrong -> worst | edit result=' worst' (p=0.254) | success=(✓)\n",
      "Mapping young -> cheapest | edit result=' cheapest' (p=0.771) | success=(✓)\n",
      "Mapping zesty -> cleanest | edit result=' clean' (p=0.845) | success=(✓)\n",
      "------------------------------------------------------------\n",
      "Causality (@1) = 0.863013698630137\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# precomputing latents to speed things up\n",
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject for sample in test.samples],\n",
    "    h_layer= operator.h_layer,\n",
    "    z_layer=-1,\n",
    "    batch_size = 2\n",
    ")\n",
    "\n",
    "success = 0\n",
    "fails = 0\n",
    "\n",
    "for sample in test.samples:\n",
    "    target = test_targets.get(sample)\n",
    "    assert target is not None\n",
    "    edit_result = editor(\n",
    "        subject = sample.subject,\n",
    "        target = target.subject\n",
    "    )\n",
    "    \n",
    "    success_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=edit_result.predicted_tokens[0].token, target=target.object\n",
    "    )\n",
    "    \n",
    "    print(f\"Mapping {sample.subject} -> {target.object} | edit result={edit_result.predicted_tokens[0]} | success=({functional.get_tick_marker(success_flag)})\")\n",
    "    \n",
    "    success += success_flag\n",
    "    fails += not success_flag\n",
    "    \n",
    "causality = success / (success + fails)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Causality (@1) = {causality}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048477e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
