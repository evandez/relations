{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b360b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f696b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/fact/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115a4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.1+cu117', '11.7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "torch.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f54a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import models, data, lens, functional\n",
    "from src.utils import experiment_utils\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d46d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-10 18:05:00 src.models INFO     loading state-spaces/mamba-2.8b-slimpj (device=cuda:0, fp16=False)\n",
      "2024-02-10 18:05:00 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "{'d_model': 2560, 'n_layer': 64, 'vocab_size': 50277, 'ssm_cfg': {}, 'rms_norm': True, 'residual_in_fp32': True, 'fused_add_norm': False, 'pad_vocab_size_multiple': 8}\n",
      "============> Block.__init__() | norm_cls=functools.partial(<class 'mamba.mamba_ssm.models.mixer_seq_simple.RMSNorm'>, eps=1e-05, device=None, dtype=None) | dim=2560<============\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RMSNorm.__init__() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m mt \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmamba-3b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../src/models.py:427\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, fp16)\u001b[0m\n\u001b[1;32m    424\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (device=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, fp16=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfp16\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mamba_variant:\n\u001b[0;32m--> 427\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMamba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     model \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mAutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../mamba/mamba_ssm/models/mixer_seq_simple.py:284\u001b[0m, in \u001b[0;36mMambaLMHeadModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name, device, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mprint\u001b[39m(config_data)\n\u001b[1;32m    283\u001b[0m config \u001b[38;5;241m=\u001b[39m MambaConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_data)\n\u001b[0;32m--> 284\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m    286\u001b[0m     load_state_dict_hf(pretrained_model_name, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    287\u001b[0m )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../mamba/mamba_ssm/models/mixer_seq_simple.py:232\u001b[0m, in \u001b[0;36mMambaLMHeadModel.__init__\u001b[0;34m(self, config, initializer_cfg, device, dtype)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vocab_size \u001b[38;5;241m%\u001b[39m pad_vocab_size_multiple \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    229\u001b[0m     vocab_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pad_vocab_size_multiple \u001b[38;5;241m-\u001b[39m (\n\u001b[1;32m    230\u001b[0m         vocab_size \u001b[38;5;241m%\u001b[39m pad_vocab_size_multiple\n\u001b[1;32m    231\u001b[0m     )\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m \u001b[43mMixerModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssm_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssm_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrms_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrms_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused_add_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfused_add_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(d_model, vocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Initialize weights and apply final processing\u001b[39;00m\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../mamba/mamba_ssm/models/mixer_seq_simple.py:140\u001b[0m, in \u001b[0;36mMixerModel.__init__\u001b[0;34m(self, d_model, n_layer, vocab_size, ssm_cfg, norm_epsilon, rms_norm, initializer_cfg, fused_add_norm, residual_in_fp32, device, dtype)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_norm_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m rms_norm_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import Triton LayerNorm / RMSNorm kernels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[0;32m--> 140\u001b[0m     [\n\u001b[1;32m    141\u001b[0m         create_block(\n\u001b[1;32m    142\u001b[0m             d_model,\n\u001b[1;32m    143\u001b[0m             ssm_cfg\u001b[38;5;241m=\u001b[39mssm_cfg,\n\u001b[1;32m    144\u001b[0m             norm_epsilon\u001b[38;5;241m=\u001b[39mnorm_epsilon,\n\u001b[1;32m    145\u001b[0m             rms_norm\u001b[38;5;241m=\u001b[39mrms_norm,\n\u001b[1;32m    146\u001b[0m             residual_in_fp32\u001b[38;5;241m=\u001b[39mresidual_in_fp32,\n\u001b[1;32m    147\u001b[0m             fused_add_norm\u001b[38;5;241m=\u001b[39mfused_add_norm,\n\u001b[1;32m    148\u001b[0m             layer_idx\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs,\n\u001b[1;32m    150\u001b[0m         )\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layer)\n\u001b[1;32m    152\u001b[0m     ]\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f \u001b[38;5;241m=\u001b[39m (nn\u001b[38;5;241m.\u001b[39mLayerNorm \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rms_norm \u001b[38;5;28;01melse\u001b[39;00m RMSNorm)(\n\u001b[1;32m    156\u001b[0m     d_model, eps\u001b[38;5;241m=\u001b[39mnorm_epsilon, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    160\u001b[0m     partial(\n\u001b[1;32m    161\u001b[0m         _init_weights,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../mamba/mamba_ssm/models/mixer_seq_simple.py:141\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_norm_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m rms_norm_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import Triton LayerNorm / RMSNorm kernels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m    140\u001b[0m     [\n\u001b[0;32m--> 141\u001b[0m         \u001b[43mcreate_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m            \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m            \u001b[49m\u001b[43mssm_cfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssm_cfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnorm_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrms_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrms_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfused_add_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfused_add_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layer)\n\u001b[1;32m    152\u001b[0m     ]\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_f \u001b[38;5;241m=\u001b[39m (nn\u001b[38;5;241m.\u001b[39mLayerNorm \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rms_norm \u001b[38;5;28;01melse\u001b[39;00m RMSNorm)(\n\u001b[1;32m    156\u001b[0m     d_model, eps\u001b[38;5;241m=\u001b[39mnorm_epsilon, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    160\u001b[0m     partial(\n\u001b[1;32m    161\u001b[0m         _init_weights,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../mamba/mamba_ssm/models/mixer_seq_simple.py:64\u001b[0m, in \u001b[0;36mcreate_block\u001b[0;34m(d_model, ssm_cfg, norm_epsilon, rms_norm, residual_in_fp32, fused_add_norm, layer_idx, device, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m mixer_cls \u001b[38;5;241m=\u001b[39m partial(Mamba, layer_idx\u001b[38;5;241m=\u001b[39mlayer_idx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mssm_cfg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[1;32m     61\u001b[0m norm_cls \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m     62\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLayerNorm \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rms_norm \u001b[38;5;28;01melse\u001b[39;00m RMSNorm, eps\u001b[38;5;241m=\u001b[39mnorm_epsilon, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs\n\u001b[1;32m     63\u001b[0m )\n\u001b[0;32m---> 64\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[43mBlock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixer_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfused_add_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfused_add_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidual_in_fp32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m block\u001b[38;5;241m.\u001b[39mlayer_idx \u001b[38;5;241m=\u001b[39m layer_idx\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m block\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../mamba/mamba_ssm/modules/mamba_simple.py:385\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[0;34m(self, dim, mixer_cls, norm_cls, fused_add_norm, residual_in_fp32)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmixer \u001b[38;5;241m=\u001b[39m mixer_cls(dim)\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m============> Block.__init__() | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_cls\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m<============\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m \u001b[43mnorm_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused_add_norm:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m RMSNorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSNorm import fails\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: RMSNorm.__init__() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"mamba-3b\", device=device, fp16=False)\n",
    "# mt = models.load_model(\"gptj\", device=device, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0620a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import baukit\n",
    "\n",
    "# mt.model.config.fused_add_norm = False\n",
    "\n",
    "# for block_path in models.determine_layer_paths(mt):\n",
    "#     block = baukit.get_module(mt.model, block_path)\n",
    "#     setattr(block, \"fused_add_norm\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c253f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model.backbone.layers[0].fused_add_norm, mt.model.config.fused_add_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fcd03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaConfig(d_model=2560, n_layer=64, vocab_size=50277, ssm_cfg={}, rms_norm=True, residual_in_fp32=True, fused_add_norm=False, pad_vocab_size_multiple=8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fe59d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.typing import Mamba\n",
    "\n",
    "isinstance(mt.model, Mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e27323d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"mamba\" in str(type(mt.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a921c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.is_mamba=True | self.is_mamba_fast=True\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      ">>>>>>>>>>>>>>>> Block.forward() | self.fused_add_norm=False <<<<<<<<<<<<<<<<<<<\n",
      "<class 'mamba_ssm.ops.triton.layernorm.RMSNorm'>\n",
      "------------------------------- MixerModel.forward() | self.fused_add_norm=False -------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Paris', prob=0.34679484367370605),\n",
       "  PredictedToken(token=' a', prob=0.07820745557546616),\n",
       "  PredictedToken(token=' the', prob=0.059068549424409866),\n",
       "  PredictedToken(token=' located', prob=0.052434541285037994),\n",
       "  PredictedToken(token=' also', prob=0.02528112567961216)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    prompt = mt.tokenizer.eos_token + \" The capital of {} is\".format(\"France\"),\n",
    "    # prompt = mt.tokenizer.eos_token + \" The superlative of {} is\".format(\"good\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f9f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaLMHeadModel(\n",
       "  (backbone): MixerModel(\n",
       "    (embedding): Embedding(50280, 2560)\n",
       "    (layers): ModuleList(\n",
       "      (0): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (24): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (25): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (26): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (27): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (28): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (29): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (30): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (31): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (32): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (33): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (34): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (35): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (36): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (37): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (38): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (39): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (40): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (41): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (42): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (43): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (44): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (45): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (46): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (47): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (48): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (49): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (50): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (51): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (52): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (53): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (54): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (55): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (56): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (57): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (58): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (59): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (60): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (61): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (62): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "      (63): Block(\n",
       "        (mixer): Mamba(\n",
       "          (in_proj): Linear(in_features=2560, out_features=10240, bias=False)\n",
       "          (conv1d): Conv1d(5120, 5120, kernel_size=(4,), stride=(1,), padding=(3,), groups=5120)\n",
       "          (act): SiLU()\n",
       "          (x_proj): Linear(in_features=5120, out_features=192, bias=False)\n",
       "          (dt_proj): Linear(in_features=160, out_features=5120, bias=True)\n",
       "          (out_proj): Linear(in_features=5120, out_features=2560, bias=False)\n",
       "        )\n",
       "        (norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm_f): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2560, out_features=50280, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32fdbcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.is_mamba=True | self.is_mamba_fast=True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Paris', prob=0.34679484367370605),\n",
       "  PredictedToken(token=' a', prob=0.07820745557546616),\n",
       "  PredictedToken(token=' the', prob=0.059068549424409866),\n",
       "  PredictedToken(token=' located', prob=0.052434541285037994),\n",
       "  PredictedToken(token=' also', prob=0.02528112567961216)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    prompt = mt.tokenizer.eos_token + \" The capital of {} is\".format(\"France\"),\n",
    "    # prompt = mt.tokenizer.eos_token + \" The superlative of {} is\".format(\"good\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e712ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f51154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-09 09:50:51 src.data DEBUG    no paths provided, using default data dir: /home/local_arnab/Codes/relations/notebooks/../data\n",
      "2024-02-09 09:50:51 src.data DEBUG    /home/local_arnab/Codes/relations/notebooks/../data is directory, globbing for json files...\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/characteristic_gender.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/degree_gender.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_birthplace.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_gender.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_religion.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/occupation_age.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/occupation_gender.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/fruit_inside_color.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/fruit_outside_color.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/object_superclass.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/substance_phase.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/task_done_by_person.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/task_done_by_tool.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/word_sentiment.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/work_location.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/city_in_country.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/company_ceo.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/company_hq.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_capital_city.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_currency.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_language.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_largest_city.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/food_from_country.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/landmark_in_country.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/landmark_on_continent.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_band_lead_singer.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_father.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_mother.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_native_language.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_occupation.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_instrument.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_position_in_sport.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_pro_sport.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_university.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/pokemon_evolutions.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/presidents_birth_year.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/presidents_election_year.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/product_by_company.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/star_constellation.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/superhero_archnemesis.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/superhero_person.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_antonym.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_comparative.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_superlative.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/verb_past_tense.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/word_first_letter.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/word_last_letter.json\n",
      "2024-02-09 09:50:51 src.data DEBUG    found 47 relation files total, loading...\n"
     ]
    }
   ],
   "source": [
    "dataset = data.load_dataset()\n",
    "\n",
    "# relation_names = [r.name for r in dataset.relations]\n",
    "# relation_options = Menu(choices = relation_names, value = relation_names)\n",
    "# show(relation_options) # !caution: tested in a juputer-notebook. baukit visualizations are not supported in vscode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a17444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-09 09:50:52 src.data DEBUG    filtering to only relations: ['country capital city']\n",
      "country capital city -- 24 samples\n",
      "------------------------------------------------------\n",
      "2024-02-09 09:50:52 src.utils.experiment_utils INFO     setting all seeds to 12345\n",
      "China -> Beijing\n",
      "Japan -> Tokyo\n",
      "Italy -> Rome\n",
      "Brazil -> Bras\\u00edlia\n",
      "Turkey -> Ankara\n"
     ]
    }
   ],
   "source": [
    "relation_name = \"country capital city\"\n",
    "relation = dataset.filter(relation_names=[relation_name])[0]\n",
    "print(f\"{relation.name} -- {len(relation.samples)} samples\")\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "train, test = relation.split(5)\n",
    "print(\"\\n\".join([sample.__str__() for sample in train.samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145bf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "layer = 20\n",
    "beta = 8\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83b33032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-09 09:50:54 src.utils.experiment_utils INFO     setting all seeds to 12345\n",
      "2024-02-09 09:50:54 src.operators WARNING  relation has > 1 prompt_templates, will use first (The capital city of {} is)\n",
      "2024-02-09 09:50:54 src.operators DEBUG    estimating J for prompt:\n",
      "<|endoftext|> The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of China is\n",
      "2024-02-09 09:50:54 src.operators DEBUG    note that subject=China, h_index=26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.is_mamba=True | self.is_mamba_fast=True\n",
      "h.shape=torch.Size([2560]) | h.requires_grad=True\n",
      "self.is_mamba=True | self.is_mamba_fast=True\n",
      "Calculating Jacobians ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca49af81d444f1c84623284ee578bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m experiment_utils\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m12345\u001b[39m)\n\u001b[1;32m      4\u001b[0m estimator \u001b[38;5;241m=\u001b[39m JacobianIclMeanEstimator(\n\u001b[1;32m      5\u001b[0m     mt \u001b[38;5;241m=\u001b[39m mt, \n\u001b[1;32m      6\u001b[0m     h_layer \u001b[38;5;241m=\u001b[39m layer,\n\u001b[1;32m      7\u001b[0m     beta \u001b[38;5;241m=\u001b[39m beta\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m operator \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrelation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../src/operators.py:251\u001b[0m, in \u001b[0;36mJacobianIclMeanEstimator.__call__\u001b[0;34m(self, relation)\u001b[0m\n\u001b[1;32m    244\u001b[0m     h_index, inputs \u001b[38;5;241m=\u001b[39m functional\u001b[38;5;241m.\u001b[39mfind_subject_token_index(\n\u001b[1;32m    245\u001b[0m         mt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmt,\n\u001b[1;32m    246\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    247\u001b[0m         subject\u001b[38;5;241m=\u001b[39msample\u001b[38;5;241m.\u001b[39msubject,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    249\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnote that subject=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;241m.\u001b[39msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, h_index=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 251\u001b[0m     approx \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder_1_approx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mh_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     approxes\u001b[38;5;241m.\u001b[39mappend(approx)\n\u001b[1;32m    262\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([approx\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;28;01mfor\u001b[39;00m approx \u001b[38;5;129;01min\u001b[39;00m approxes])\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fact/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fact/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../src/functional.py:190\u001b[0m, in \u001b[0;36morder_1_approx\u001b[0;34m(mt, prompt, h_layer, h_index, h, z_layer, z_index, inputs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m h \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mt\u001b[38;5;241m.\u001b[39mmodel, Mamba):\n\u001b[0;32m--> 190\u001b[0m     weight \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_z_from_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mjacobian(compute_z_from_h, h, vectorize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Codes/relations/notebooks/../src/functional.py:182\u001b[0m, in \u001b[0;36morder_1_approx.<locals>.calculate_jacobian\u001b[0;34m(function, h)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(h\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m    181\u001b[0m     mt\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 182\u001b[0m     \u001b[43mz_est\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     jacobian\u001b[38;5;241m.\u001b[39mappend(copy\u001b[38;5;241m.\u001b[39mdeepcopy(h\u001b[38;5;241m.\u001b[39mgrad))\n\u001b[1;32m    184\u001b[0m     h\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mzero_()\n",
      "File \u001b[0;32m~/miniconda3/envs/fact/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fact/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from src.operators import JacobianIclMeanEstimator\n",
    "experiment_utils.set_seed(12345)\n",
    "\n",
    "estimator = JacobianIclMeanEstimator(\n",
    "    mt = mt, \n",
    "    h_layer = layer,\n",
    "    beta = beta\n",
    ")\n",
    "operator = estimator(\n",
    "    relation.set(\n",
    "        samples=train.samples, \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69b7cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mamba-3b'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbc72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = \"../results/cached_o1_approxes\"\n",
    "path = os.path.join(\n",
    "    root_path,\n",
    "    mt.name,\n",
    "    relation_name.lower().replace(\" \", \"_\"),\n",
    "    str(layer),\n",
    ")\n",
    "\n",
    "approxes = []\n",
    "for cached_file in os.listdir(path):\n",
    "    approx = functional.load_cached_linear_operator(file_path = os.path.join(path, cached_file))\n",
    "    approxes.append(approx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4af14f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of {} is\n"
     ]
    }
   ],
   "source": [
    "weight = torch.stack([approx.weight for approx in approxes]).mean(dim=0)\n",
    "bias = torch.stack([approx.bias for approx in approxes]).mean(dim=0)\n",
    "\n",
    "prompt_template = relation.prompt_templates[0]\n",
    "\n",
    "prompt_template_icl = functional.make_prompt(\n",
    "    mt = mt,\n",
    "    prompt_template=prompt_template,\n",
    "    subject=\"{}\",\n",
    "    examples = [\n",
    "        data.RelationSample.from_dict(approx.metadata[\"sample\"]) \n",
    "        for approx in approxes\n",
    "    ][:min(3, len(approxes))],\n",
    ")\n",
    "\n",
    "print(prompt_template_icl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import LinearRelationOperator\n",
    "operator = LinearRelationOperator(\n",
    "    mt = mt,\n",
    "    weight = weight,\n",
    "    bias = bias,\n",
    "    h_layer = approxes[0].h_layer,\n",
    "    z_layer = approxes[0].z_layer,\n",
    "    beta = 5,\n",
    "    prompt_template = prompt_template_icl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dfcbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lens import logit_lens\n",
    "from src import models\n",
    "\n",
    "# logit_lens(mt = mt, h = operator.metadata[\"Jh\"][0].to(models.determine_device(mt)) + operator.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4ad24c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Paris', prob=0.34679311513900757),\n",
       "  PredictedToken(token=' a', prob=0.07820795476436615),\n",
       "  PredictedToken(token=' the', prob=0.05906893312931061),\n",
       "  PredictedToken(token=' located', prob=0.05243447795510292),\n",
       "  PredictedToken(token=' also', prob=0.0252813883125782)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    prompt = mt.tokenizer.eos_token + \" The capital of {} is\".format(\"France\"),\n",
    "    # prompt = mt.tokenizer.eos_token + \" The superlative of {} is\".format(\"good\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b6eda",
   "metadata": {},
   "source": [
    "# Checking $faithfulness$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d79b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 14:44:50 src.functional DEBUG    filtering for knowns using prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of {} is\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='South Korea', sample.object='Seoul', predicted=' Seoul' (p=0.969), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Colombia', sample.object='Bogot\\\\u00e1', predicted=' Bog' (p=0.739), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Saudi Arabia', sample.object='Riyadh', predicted=' R' (p=0.807), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='France', sample.object='Paris', predicted=' Paris' (p=0.976), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Mexico', sample.object='Mexico City', predicted=' Mexico' (p=0.956), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Pakistan', sample.object='Islamabad', predicted=' Islam' (p=0.941), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Argentina', sample.object='Buenos Aires', predicted=' Buenos' (p=0.947), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Nigeria', sample.object='Abuja', predicted=' Abu' (p=0.724), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='India', sample.object='New Delhi', predicted=' New' (p=0.746), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Canada', sample.object='Ottawa', predicted=' Ottawa' (p=0.927), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Egypt', sample.object='Cairo', predicted=' Cairo' (p=0.980), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Chile', sample.object='Santiago', predicted=' Santiago' (p=0.969), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Australia', sample.object='Canberra', predicted=' Can' (p=0.874), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Venezuela', sample.object='Caracas', predicted=' Car' (p=0.956), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Peru', sample.object='Lima', predicted=' L' (p=0.955), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Germany', sample.object='Berlin', predicted=' Berlin' (p=0.976), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Spain', sample.object='Madrid', predicted=' Madrid' (p=0.964), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='United States', sample.object='Washington D.C.', predicted=' Washington' (p=0.946), known=()\n",
      "2024-02-07 14:44:50 src.functional DEBUG    sample.subject='Russia', sample.object='Moscow', predicted=' Moscow' (p=0.972), known=()\n"
     ]
    }
   ],
   "source": [
    "test = functional.filter_relation_samples_based_on_provided_fewshots(\n",
    "    mt=mt, test_relation=test, prompt_template=operator.prompt_template, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ad18a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France -> Paris\n",
      "2024-02-07 14:44:57 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of France is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Paris', prob=0.8592612743377686),\n",
       " PredictedToken(token=' ', prob=0.056149572134017944),\n",
       " PredictedToken(token=' Capital', prob=0.035243552178144455),\n",
       " PredictedToken(token='\\n', prob=0.0163775235414505),\n",
       " PredictedToken(token=' -', prob=0.004834211431443691)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [s for s in test.samples if s.subject == \"France\"][0]\n",
    "print(sample)\n",
    "operator(subject = sample.subject).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e717d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject],\n",
    "    h_layer= operator.h_layer,\n",
    ")\n",
    "h = hs_and_zs.h_by_subj[sample.subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69136b",
   "metadata": {},
   "source": [
    "## Approximating LM computation $F$ as an affine transformation\n",
    "\n",
    "### $$ F(\\mathbf{s}, c_r) \\approx \\beta \\, W_r \\mathbf{s} + b_r $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8bf8b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(' Paris', 0.859),\n",
       "  (' ', 0.056),\n",
       "  (' Capital', 0.035),\n",
       "  ('\\n', 0.016),\n",
       "  (' -', 0.005),\n",
       "  (' (', 0.005),\n",
       "  (' capital', 0.004),\n",
       "  (' in', 0.003),\n",
       "  (' Cairo', 0.002),\n",
       "  ('...', 0.002)],\n",
       " {})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 5 * (operator.weight @ h) + operator.bias\n",
    "\n",
    "lens.logit_lens(\n",
    "    mt = mt,\n",
    "    h = z,\n",
    "    get_proba = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0725d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Argentina is\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.subject='Argentina', sample.object='Buenos Aires', predicted=\"\\n\", (p=0.20366910099983215), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Australia is\"\n",
      "sample.subject='Australia', sample.object='Canberra', predicted=\" Capital\", (p=0.7717655897140503), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Canada is\"\n",
      "sample.subject='Canada', sample.object='Ottawa', predicted=\" Capital\", (p=0.35436227917671204), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Chile is\"\n",
      "sample.subject='Chile', sample.object='Santiago', predicted=\" Capital\", (p=0.605689287185669), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Colombia is\"\n",
      "sample.subject='Colombia', sample.object='Bogot\\\\u00e1', predicted=\" Bog\", (p=0.36636996269226074), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Egypt is\"\n",
      "sample.subject='Egypt', sample.object='Cairo', predicted=\" Cairo\", (p=0.997891366481781), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of France is\"\n",
      "sample.subject='France', sample.object='Paris', predicted=\" Paris\", (p=0.8592612743377686), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Germany is\"\n",
      "sample.subject='Germany', sample.object='Berlin', predicted=\" Berlin\", (p=0.8202896118164062), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of India is\"\n",
      "sample.subject='India', sample.object='New Delhi', predicted=\" Delhi\", (p=0.502575159072876), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Mexico is\"\n",
      "sample.subject='Mexico', sample.object='Mexico City', predicted=\" Mexico\", (p=0.6341054439544678), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Nigeria is\"\n",
      "sample.subject='Nigeria', sample.object='Abuja', predicted=\" Abu\", (p=0.286549836397171), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Pakistan is\"\n",
      "sample.subject='Pakistan', sample.object='Islamabad', predicted=\" Islam\", (p=0.9234731197357178), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Peru is\"\n",
      "sample.subject='Peru', sample.object='Lima', predicted=\" Capital\", (p=0.694509744644165), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Russia is\"\n",
      "sample.subject='Russia', sample.object='Moscow', predicted=\" Moscow\", (p=0.9923985600471497), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Saudi Arabia is\"\n",
      "sample.subject='Saudi Arabia', sample.object='Riyadh', predicted=\" Islam\", (p=0.29507988691329956), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of South Korea is\"\n",
      "sample.subject='South Korea', sample.object='Seoul', predicted=\" Seoul\", (p=0.756904125213623), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Spain is\"\n",
      "sample.subject='Spain', sample.object='Madrid', predicted=\" \", (p=0.3683183491230011), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of United States is\"\n",
      "sample.subject='United States', sample.object='Washington D.C.', predicted=\" Washington\", (p=0.7139011025428772), known=()\n",
      "2024-02-07 14:45:01 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of Venezuela is\"\n",
      "sample.subject='Venezuela', sample.object='Caracas', predicted=\" Capital\", (p=0.6135460138320923), known=()\n",
      "------------------------------------------------------------\n",
      "Faithfulness (@1) = 0.5263157894736842\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for sample in test.samples:\n",
    "    predictions = operator(subject = sample.subject).predictions\n",
    "    known_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=predictions[0].token, target=sample.object\n",
    "    )\n",
    "    print(f\"{sample.subject=}, {sample.object=}, \", end=\"\")\n",
    "    print(f'predicted=\"{functional.format_whitespace(predictions[0].token)}\", (p={predictions[0].prob}), known=({functional.get_tick_marker(known_flag)})')\n",
    "    \n",
    "    correct += known_flag\n",
    "    wrong += not known_flag\n",
    "    \n",
    "faithfulness = correct/(correct + wrong)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Faithfulness (@1) = {faithfulness}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a13389",
   "metadata": {},
   "source": [
    "# $causality$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da2f8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "rank = 100\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25ac7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 14:45:06 src.utils.experiment_utils INFO     setting all seeds to 12345\n"
     ]
    }
   ],
   "source": [
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "test_targets = functional.random_edit_targets(test.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d83c9b",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a13c0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Changing the mapping (Argentina -> Buenos Aires) to (Argentina -> Riyadh)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = test.samples[0]\n",
    "target = test_targets[source]\n",
    "\n",
    "f\"Changing the mapping ({source}) to ({source.subject} -> {target.object})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f67c8",
   "metadata": {},
   "source": [
    "### Calculate $\\Delta \\mathbf{s}$ such that $\\mathbf{s} + \\Delta \\mathbf{s} \\approx \\mathbf{s}'$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img align=\"center\" src=\"../causality_crop\" style=\"width:80%;\"/>\n",
    "</p>\n",
    "\n",
    "Under the relation $r =\\, $*plays the instrument*, and given the subject $s =\\, $*Miles Davis*, the model will predict $o =\\, $*trumpet* **(a)**; and given the subject $s' =\\, $*Cat Stevens*, the model will now predict $o' =\\, $*guiter* **(b)**. \n",
    "\n",
    "If the computation from $\\mathbf{s}$ to $\\mathbf{o}$ is well-approximated by $operator$ parameterized by $W_r$ and $b_r$ **(c)**, then $\\Delta{\\mathbf{s}}$ **(d)** should tell us the direction of change from $\\mathbf{s}$ to $\\mathbf{s}'$. Thus, $\\tilde{\\mathbf{s}}=\\mathbf{s}+\\Delta\\mathbf{s}$ would be an approximation of $\\mathbf{s}'$ and patching $\\tilde{\\mathbf{s}}$ in place of $\\mathbf{s}$ should change the prediction to $o'$ = *guitar* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53c632ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_s(\n",
    "    operator, \n",
    "    source_subject, \n",
    "    target_subject,\n",
    "    rank = 100,\n",
    "    fix_latent_norm = None, # if set, will fix the norms of z_source and z_target\n",
    "):\n",
    "    w_p_inv = functional.low_rank_pinv(\n",
    "        matrix = operator.weight,\n",
    "        rank=rank,\n",
    "    )\n",
    "    hs_and_zs = functional.compute_hs_and_zs(\n",
    "        mt = mt,\n",
    "        prompt_template = operator.prompt_template,\n",
    "        subjects = [source_subject, target_subject],\n",
    "        h_layer= operator.h_layer,\n",
    "        z_layer=-1,\n",
    "    )\n",
    "\n",
    "    z_source = hs_and_zs.z_by_subj[source_subject]\n",
    "    z_target = hs_and_zs.z_by_subj[target_subject]\n",
    "    \n",
    "    z_source *= fix_latent_norm / z_source.norm() if fix_latent_norm is not None else 1.0\n",
    "    z_target *= z_source.norm() / z_target.norm() if fix_latent_norm is not None else 1.0\n",
    "\n",
    "    delta_s = w_p_inv @  (z_target.squeeze() - z_source.squeeze())\n",
    "\n",
    "    return delta_s, hs_and_zs\n",
    "\n",
    "delta_s, hs_and_zs = get_delta_s(\n",
    "    operator = operator,\n",
    "    source_subject = source.subject,\n",
    "    target_subject = target.subject,\n",
    "    rank = rank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab1c7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Me', 0.592),\n",
       " (' R', 0.181),\n",
       " (' Jed', 0.063),\n",
       " (' Mak', 0.046),\n",
       " (' Med', 0.013),\n",
       " (' Dh', 0.012),\n",
       " (' Saudi', 0.011),\n",
       " (' Dubai', 0.005),\n",
       " (' Kuwait', 0.005),\n",
       " (' K', 0.004)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baukit\n",
    "\n",
    "def get_intervention(h, int_layer, subj_idx):\n",
    "    def edit_output(output, layer):\n",
    "        if(layer != int_layer):\n",
    "            return output\n",
    "        functional.untuple(output)[:, subj_idx] = h \n",
    "        return output\n",
    "    return edit_output\n",
    "\n",
    "prompt = operator.prompt_template.format(source.subject)\n",
    "\n",
    "h_index, inputs = functional.find_subject_token_index(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    subject=source.subject,\n",
    ")\n",
    "\n",
    "h_layer, z_layer = models.determine_layer_paths(model = mt, layers = [layer, -1])\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model, layers = [h_layer, z_layer],\n",
    "    edit_output=get_intervention(\n",
    "#         h = hs_and_zs.h_by_subj[source.subject],         # let the computation proceed as usual\n",
    "        h = hs_and_zs.h_by_subj[source.subject] + delta_s, # replace s with s + delta_s\n",
    "        int_layer = h_layer, \n",
    "        subj_idx = h_index\n",
    "    )\n",
    ") as traces:\n",
    "    outputs = mt(\n",
    "        input_ids = inputs.input_ids,\n",
    "        attention_mask = inputs.attention_mask,\n",
    "    )\n",
    "\n",
    "logits = outputs.logits[0][-1] if hasattr(outputs, \"logits\") else outputs[0][-1]\n",
    "lens.interpret_logits(\n",
    "    mt = mt, \n",
    "    logits = logits, \n",
    "    get_proba=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c272c1",
   "metadata": {},
   "source": [
    "## Measuring causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51efa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.editors import LowRankPInvEditor\n",
    "\n",
    "svd = torch.svd(operator.weight.float())\n",
    "editor = LowRankPInvEditor(\n",
    "    lre=operator,\n",
    "    rank=rank,\n",
    "    svd=svd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88be35dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-07 14:45:11 src.editors DEBUG    computing low-rank pinv (rel=<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Nigeria is Abuja\n",
      "The capital city of Colombia is Bogot\\u00e1\n",
      "The capital city of {} is)\n",
      "Mapping Argentina -> Riyadh | edit result=' Me' (p=0.456) | success=()\n",
      "Mapping Australia -> Buenos Aires | edit result=' Buenos' (p=0.187) | success=()\n",
      "Mapping Canada -> Abuja | edit result=' Abu' (p=0.435) | success=()\n",
      "Mapping Chile -> Lima | edit result=' L' (p=0.974) | success=()\n",
      "Mapping Colombia -> Berlin | edit result=' Bog' (p=0.925) | success=()\n",
      "Mapping Egypt -> Mexico City | edit result=' Mexico' (p=0.894) | success=()\n",
      "Mapping France -> Riyadh | edit result=' Me' (p=0.669) | success=()\n",
      "Mapping Germany -> Cairo | edit result=' Cairo' (p=0.934) | success=()\n",
      "Mapping India -> Lima | edit result=' L' (p=0.890) | success=()\n",
      "Mapping Mexico -> Santiago | edit result=' Su' (p=0.205) | success=()\n",
      "Mapping Nigeria -> Riyadh | edit result=' Abu' (p=0.722) | success=()\n",
      "Mapping Pakistan -> New Delhi | edit result=' New' (p=0.724) | success=()\n",
      "Mapping Peru -> Caracas | edit result=' Car' (p=0.872) | success=()\n",
      "Mapping Russia -> Cairo | edit result=' Cairo' (p=0.926) | success=()\n",
      "Mapping Saudi Arabia -> Caracas | edit result=' Bog' (p=0.115) | success=()\n",
      "Mapping South Korea -> Cairo | edit result=' Cairo' (p=0.954) | success=()\n",
      "Mapping Spain -> Islamabad | edit result=' Islam' (p=0.818) | success=()\n",
      "Mapping United States -> Ottawa | edit result=' Ottawa' (p=0.606) | success=()\n",
      "Mapping Venezuela -> Madrid | edit result=' Madrid' (p=0.762) | success=()\n",
      "------------------------------------------------------------\n",
      "Causality (@1) = 0.6842105263157895\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# precomputing latents to speed things up\n",
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject for sample in test.samples],\n",
    "    h_layer= operator.h_layer,\n",
    "    z_layer=-1,\n",
    "    batch_size = 2\n",
    ")\n",
    "\n",
    "success = 0\n",
    "fails = 0\n",
    "\n",
    "for sample in test.samples:\n",
    "    target = test_targets.get(sample)\n",
    "    assert target is not None\n",
    "    edit_result = editor(\n",
    "        subject = sample.subject,\n",
    "        target = target.subject\n",
    "    )\n",
    "    \n",
    "    success_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=edit_result.predicted_tokens[0].token, target=target.object\n",
    "    )\n",
    "    \n",
    "    print(f\"Mapping {sample.subject} -> {target.object} | edit result={edit_result.predicted_tokens[0]} | success=({functional.get_tick_marker(success_flag)})\")\n",
    "    \n",
    "    success += success_flag\n",
    "    fails += not success_flag\n",
    "    \n",
    "causality = success / (success + fails)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Causality (@1) = {causality}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d14acef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import save_linear_operator\n",
    "\n",
    "save_linear_operator(\n",
    "    approx = operator,\n",
    "    file_name = \"lre_capital\",\n",
    "    path = \"cached\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1cbbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_loaded = functional.load_cached_linear_operator(mt = mt, file_path = \"cached/lre_capital.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2069b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c55042",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = mt.tokenizer.eos_token + \" Michael Jordan professionally played the sport of\"\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "models.determine_layer_paths(mt)[layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5459d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baukit\n",
    "\n",
    "layer_out = models.determine_layer_paths(mt)[layer]\n",
    "mixer_out = models.determine_layer_paths(mt)[layer] + \".mixer\"\n",
    "layer_in = models.determine_layer_paths(mt)[layer+1]\n",
    "final_layer = models.determine_layer_paths(mt)[-1]\n",
    "final_mixer = models.determine_layer_paths(mt)[-1] + \".mixer\"\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt.model,\n",
    "    layers=[\n",
    "        layer_out,\n",
    "        mixer_out,\n",
    "        layer_in,\n",
    "        final_mixer,\n",
    "        final_layer,\n",
    "        \"backbone\"\n",
    "    ],\n",
    "    retain_input=True,\n",
    ") as traces:\n",
    "    output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87121bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[\"backbone\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7473e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[final_layer].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = baukit.get_module(mt.model, \"backbone.norm_f\").weight\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
    "\n",
    "        return output\n",
    "\n",
    "custom_rms = RMSNorm(d_model = models.determine_hidden_size(mt))\n",
    "block_output, residual = traces[final_layer].output\n",
    "backbone_output = custom_rms(block_output + residual)\n",
    "\n",
    "backbone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(traces[mixer_out].output, traces[layer_out].output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baukit.get_module(mt.model, \"backbone.norm_f\").bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96443785",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(mt.model, \"backbone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ecaaf9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time: 46.666666666666664 hours, Size: 20.3125 GB'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = 32\n",
    "n_approx = 25\n",
    "time_per_approx = 7 # in minutes\n",
    "size_per_approx = 26 # in MB\n",
    "n_threads = 2\n",
    "\n",
    "\n",
    "total_time = n_layers * n_approx * time_per_approx\n",
    "total_time /= n_threads\n",
    "total_time /= 60\n",
    "\n",
    "total_size = n_layers * n_approx * size_per_approx\n",
    "total_size /= 1024\n",
    "\n",
    "f\"Time: {total_time} hours, Size: {total_size} GB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c378c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.determine_layers(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4285ebcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32,\n",
       "       34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(0, 64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ae65e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
