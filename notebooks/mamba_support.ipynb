{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b360b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f696b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/local_arnab/miniconda3/envs/fact/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115a4228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.13.1+cu117', '11.7')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "torch.__version__, torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f54a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import models, data, lens, functional\n",
    "from src.utils import experiment_utils\n",
    "\n",
    "import logging\n",
    "from src.utils import logging_utils\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=logging_utils.DEFAULT_FORMAT,\n",
    "    datefmt=logging_utils.DEFAULT_DATEFMT,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d46d0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-19 14:20:52 src.models INFO     loading state-spaces/mamba-2.8b-slimpj (device=cuda:0, fp16=False)\n",
      "2024-02-19 14:20:52 urllib3.connectionpool DEBUG    Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-19 14:20:52 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "2024-02-19 14:20:52 root WARNING  !!! turning off fused_add_norm for to avoid using Triton !!! CAIS cluster can't import triton functions (temporary patch)\n",
      "2024-02-19 14:20:52 mamba.mamba_ssm.models.mixer_seq_simple INFO     {'d_model': 2560, 'n_layer': 64, 'vocab_size': 50277, 'ssm_cfg': {}, 'rms_norm': True, 'residual_in_fp32': True, 'fused_add_norm': False, 'pad_vocab_size_multiple': 8}\n",
      "2024-02-19 14:21:10 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /state-spaces/mamba-2.8b-slimpj/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
      "2024-02-19 14:21:20 urllib3.connectionpool DEBUG    https://huggingface.co:443 \"HEAD /EleutherAI/gpt-neox-20b/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-19 14:21:20 src.models INFO     dtype: torch.float32, device: cuda:0, memory: 10.31 GB\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"mamba-3b\", device=device, fp16=False)\n",
    "# mt = models.load_model(\"gptj\", device=device, fp16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0620a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import baukit\n",
    "\n",
    "# mt.model.config.fused_add_norm = False\n",
    "\n",
    "# for block_path in models.determine_layer_paths(mt):\n",
    "#     block = baukit.get_module(mt.model, block_path)\n",
    "#     setattr(block, \"fused_add_norm\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c253f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model.backbone.layers[0].fused_add_norm, mt.model.config.fused_add_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9fcd03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MambaConfig(d_model=2560, n_layer=64, vocab_size=50277, ssm_cfg={}, rms_norm=True, residual_in_fp32=True, fused_add_norm=False, pad_vocab_size_multiple=8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1fe59d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.typing import Mamba\n",
    "\n",
    "isinstance(mt.model, Mamba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e27323d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"mamba\" in str(type(mt.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a921c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Paris', prob=0.34679365158081055),\n",
       "  PredictedToken(token=' a', prob=0.0782080739736557),\n",
       "  PredictedToken(token=' the', prob=0.059068791568279266),\n",
       "  PredictedToken(token=' located', prob=0.05243435874581337),\n",
       "  PredictedToken(token=' also', prob=0.025281231850385666)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    prompt = mt.tokenizer.eos_token + \" The capital of {} is\".format(\"France\"),\n",
    "    # prompt = mt.tokenizer.eos_token + \" The superlative of {} is\".format(\"good\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f9f678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f51154e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-12 13:11:25 src.data DEBUG    no paths provided, using default data dir: /home/local_arnab/Codes/relations/notebooks/../data\n",
      "2024-02-12 13:11:25 src.data DEBUG    /home/local_arnab/Codes/relations/notebooks/../data is directory, globbing for json files...\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/characteristic_gender.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/degree_gender.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_birthplace.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_gender.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/name_religion.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/occupation_age.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/bias/occupation_gender.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/fruit_inside_color.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/fruit_outside_color.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/object_superclass.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/substance_phase.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/task_done_by_person.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/task_done_by_tool.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/word_sentiment.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/commonsense/work_location.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/city_in_country.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/company_ceo.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/company_hq.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_capital_city.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_currency.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_language.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/country_largest_city.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/food_from_country.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/landmark_in_country.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/landmark_on_continent.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_band_lead_singer.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_father.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_mother.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_native_language.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_occupation.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_instrument.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_position_in_sport.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_plays_pro_sport.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/person_university.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/pokemon_evolutions.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/presidents_birth_year.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/presidents_election_year.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/product_by_company.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/star_constellation.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/superhero_archnemesis.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/factual/superhero_person.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_antonym.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_comparative.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/adj_superlative.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/verb_past_tense.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/word_first_letter.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found relation file: /home/local_arnab/Codes/relations/notebooks/../data/linguistic/word_last_letter.json\n",
      "2024-02-12 13:11:25 src.data DEBUG    found 47 relation files total, loading...\n"
     ]
    }
   ],
   "source": [
    "dataset = data.load_dataset()\n",
    "\n",
    "# relation_names = [r.name for r in dataset.relations]\n",
    "# relation_options = Menu(choices = relation_names, value = relation_names)\n",
    "# show(relation_options) # !caution: tested in a juputer-notebook. baukit visualizations are not supported in vscode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a17444f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-12 13:11:27 src.data DEBUG    filtering to only relations: ['country capital city']\n",
      "country capital city -- 24 samples\n",
      "------------------------------------------------------\n",
      "2024-02-12 13:11:27 src.utils.experiment_utils INFO     setting all seeds to 12345\n",
      "China -> Beijing\n",
      "Japan -> Tokyo\n",
      "Italy -> Rome\n",
      "Brazil -> Bras\\u00edlia\n",
      "Turkey -> Ankara\n"
     ]
    }
   ],
   "source": [
    "relation_name = \"country capital city\"\n",
    "relation = dataset.filter(relation_names=[relation_name])[0]\n",
    "print(f\"{relation.name} -- {len(relation.samples)} samples\")\n",
    "print(\"------------------------------------------------------\")\n",
    "\n",
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "train, test = relation.split(5)\n",
    "print(\"\\n\".join([sample.__str__() for sample in train.samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "145bf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "layer = 20\n",
    "beta = 8\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83b33032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.operators import JacobianIclMeanEstimator\n",
    "# experiment_utils.set_seed(12345)\n",
    "\n",
    "# estimator = JacobianIclMeanEstimator(\n",
    "#     mt = mt, \n",
    "#     h_layer = layer,\n",
    "#     beta = beta\n",
    "# )\n",
    "# operator = estimator(\n",
    "#     relation.set(\n",
    "#         samples=train.samples, \n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6155e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def add_npz_extension(path: str):\n",
    "    return path if path.endswith(\".npz\") else path + \".npz\"\n",
    "\n",
    "def load_o1_approxes(path: str, sample_subjects: Optional[list[str]] = None):\n",
    "    approxes = []\n",
    "    to_load = sample_subjects if sample_subjects is not None else os.listdir(path)\n",
    "    for cached_file in to_load:\n",
    "        file_path = add_npz_extension(os.path.join(path, cached_file))\n",
    "        approx = functional.load_cached_linear_operator(file_path = file_path)\n",
    "        approxes.append(approx)\n",
    "    return approxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "508e6d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "n_train_samples = 5\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bbc72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "root_path = \"../results/cached_o1_approxes\"\n",
    "path = os.path.join(\n",
    "    root_path,\n",
    "    mt.name,\n",
    "    relation_name.lower().replace(\" \", \"_\"),\n",
    "    str(layer),\n",
    ")\n",
    "\n",
    "all_cached_files = list(os.listdir(path))\n",
    "\n",
    "train_subj_files = random.sample(all_cached_files, n_train_samples)\n",
    "\n",
    "train_approxes = load_o1_approxes(\n",
    "    path = path, \n",
    "    sample_subjects = train_subj_files\n",
    ")\n",
    "\n",
    "train_samples = [\n",
    "    data.RelationSample.from_dict(approx.metadata[\"sample\"]) \n",
    "    for approx in train_approxes\n",
    "]\n",
    "\n",
    "train_relation = relation.set(samples=train_samples)\n",
    "\n",
    "test_relation = relation.set(\n",
    "    samples = list(set(relation.samples) - set(train_relation.samples))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4af14f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|> The capital city of Turkey is Ankara\n",
      "The capital city of Canada is Ottawa\n",
      "The capital city of Australia is Canberra\n",
      "The capital city of Mexico is Mexico City\n",
      "The capital city of Spain is Madrid\n",
      "The capital city of {} is\n"
     ]
    }
   ],
   "source": [
    "weight = torch.stack([approx.weight for approx in train_approxes]).mean(dim=0)\n",
    "bias = torch.stack([approx.bias for approx in train_approxes]).mean(dim=0)\n",
    "\n",
    "prompt_template = relation.prompt_templates[0]\n",
    "\n",
    "prompt_template_icl = functional.make_prompt(\n",
    "    mt = mt,\n",
    "    prompt_template=prompt_template,\n",
    "    subject=\"{}\",\n",
    "    examples = train_samples\n",
    ")\n",
    "\n",
    "print(prompt_template_icl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32a2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import LinearRelationOperator\n",
    "operator = LinearRelationOperator(\n",
    "    mt = mt,\n",
    "    weight = weight,\n",
    "    bias = bias,\n",
    "    h_layer = train_approxes[0].h_layer,\n",
    "    z_layer = train_approxes[0].z_layer,\n",
    "    beta = 5,\n",
    "    prompt_template = prompt_template_icl,\n",
    "    metadata = {\n",
    "        \"Jh\": [\n",
    "            (approx.weight @ approx.h).detach().cpu().numpy()\n",
    "            for approx in train_approxes\n",
    "        ],\n",
    "        \"|w|\": [approx.weight.norm().item() for approx in train_approxes],\n",
    "        \"|b|\": [approx.bias.norm().item() for approx in train_approxes],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dfcbb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lens import logit_lens\n",
    "from src import models\n",
    "\n",
    "# logit_lens(mt = mt, h = operator.metadata[\"Jh\"][0].to(models.determine_device(mt)) + operator.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4ad24c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token=' Paris', prob=0.34679365158081055),\n",
       "  PredictedToken(token=' a', prob=0.0782080739736557),\n",
       "  PredictedToken(token=' the', prob=0.059068791568279266),\n",
       "  PredictedToken(token=' located', prob=0.05243435874581337),\n",
       "  PredictedToken(token=' also', prob=0.025281231850385666)]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    prompt = mt.tokenizer.eos_token + \" The capital of {} is\".format(\"France\"),\n",
    "    # prompt = mt.tokenizer.eos_token + \" The superlative of {} is\".format(\"good\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b6eda",
   "metadata": {},
   "source": [
    "# Checking $faithfulness$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d79b613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-10 19:39:14 src.functional DEBUG    filtering for knowns using prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of {} is\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Argentina', sample.object='Buenos Aires', predicted=' Buenos' (p=0.940), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Australia', sample.object='Canberra', predicted=' Can' (p=0.880), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Canada', sample.object='Ottawa', predicted=' Ottawa' (p=0.923), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Chile', sample.object='Santiago', predicted=' Santiago' (p=0.956), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Colombia', sample.object='Bogot\\\\u00e1', predicted=' Bog' (p=0.971), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Egypt', sample.object='Cairo', predicted=' Cairo' (p=0.973), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='France', sample.object='Paris', predicted=' Paris' (p=0.984), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Germany', sample.object='Berlin', predicted=' Berlin' (p=0.979), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='India', sample.object='New Delhi', predicted=' New' (p=0.798), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Mexico', sample.object='Mexico City', predicted=' Mexico' (p=0.956), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Nigeria', sample.object='Abuja', predicted=' Abu' (p=0.684), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Pakistan', sample.object='Islamabad', predicted=' Islam' (p=0.924), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Peru', sample.object='Lima', predicted=' L' (p=0.952), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Russia', sample.object='Moscow', predicted=' Moscow' (p=0.955), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Saudi Arabia', sample.object='Riyadh', predicted=' R' (p=0.739), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='South Korea', sample.object='Seoul', predicted=' Seoul' (p=0.960), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Spain', sample.object='Madrid', predicted=' Madrid' (p=0.972), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='United States', sample.object='Washington D.C.', predicted=' Washington' (p=0.958), known=(✓)\n",
      "2024-02-10 19:39:14 src.functional DEBUG    sample.subject='Venezuela', sample.object='Caracas', predicted=' Car' (p=0.965), known=(✓)\n"
     ]
    }
   ],
   "source": [
    "test = functional.filter_relation_samples_based_on_provided_fewshots(\n",
    "    mt=mt, test_relation=test, prompt_template=operator.prompt_template, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ad18a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France -> Paris\n",
      "2024-02-10 19:39:15 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of France is\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PredictedToken(token=' Paris', prob=0.9998692274093628),\n",
       " PredictedToken(token='Paris', prob=8.898161468096077e-05),\n",
       " PredictedToken(token=' France', prob=2.8840533559559844e-05),\n",
       " PredictedToken(token=' ', prob=1.2266428711882327e-05),\n",
       " PredictedToken(token='\\n', prob=1.4412353266379796e-07)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = [s for s in test.samples if s.subject == \"France\"][0]\n",
    "print(sample)\n",
    "operator(subject = sample.subject).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e717d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject],\n",
    "    h_layer= operator.h_layer,\n",
    ")\n",
    "h = hs_and_zs.h_by_subj[sample.subject]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69136b",
   "metadata": {},
   "source": [
    "## Approximating LM computation $F$ as an affine transformation\n",
    "\n",
    "### $$ F(\\mathbf{s}, c_r) \\approx \\beta \\, W_r \\mathbf{s} + b_r $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8bf8b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(' Paris', 0.993),\n",
       "  (' ', 0.006),\n",
       "  ('\\n', 0.0),\n",
       "  (' (', 0.0),\n",
       "  (' -', 0.0),\n",
       "  ('...', 0.0),\n",
       "  ('Paris', 0.0),\n",
       "  (' London', 0.0),\n",
       "  ('.', 0.0),\n",
       "  (' in', 0.0)],\n",
       " {})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 5 * (operator.weight @ h) + operator.bias\n",
    "\n",
    "lens.logit_lens(\n",
    "    mt = mt,\n",
    "    h = z,\n",
    "    get_proba = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0725d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Argentina is\"\n",
      "sample.subject='Argentina', sample.object='Buenos Aires', predicted=\" Buenos\", (p=0.9804379940032959), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Australia is\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample.subject='Australia', sample.object='Canberra', predicted=\" Sydney\", (p=0.9073606133460999), known=(✗)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Canada is\"\n",
      "sample.subject='Canada', sample.object='Ottawa', predicted=\" Ottawa\", (p=0.31801214814186096), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Chile is\"\n",
      "sample.subject='Chile', sample.object='Santiago', predicted=\" Santiago\", (p=0.9200029373168945), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Colombia is\"\n",
      "sample.subject='Colombia', sample.object='Bogot\\\\u00e1', predicted=\" Bog\", (p=0.9952797889709473), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Egypt is\"\n",
      "sample.subject='Egypt', sample.object='Cairo', predicted=\" Cairo\", (p=0.99892657995224), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of France is\"\n",
      "sample.subject='France', sample.object='Paris', predicted=\" Paris\", (p=0.9998692274093628), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Germany is\"\n",
      "sample.subject='Germany', sample.object='Berlin', predicted=\" Berlin\", (p=0.9997690320014954), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of India is\"\n",
      "sample.subject='India', sample.object='New Delhi', predicted=\" Delhi\", (p=0.36132386326789856), known=(✗)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Mexico is\"\n",
      "sample.subject='Mexico', sample.object='Mexico City', predicted=\" Mexico\", (p=0.9996106028556824), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Nigeria is\"\n",
      "sample.subject='Nigeria', sample.object='Abuja', predicted=\" Ank\", (p=0.4195845127105713), known=(✗)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Pakistan is\"\n",
      "sample.subject='Pakistan', sample.object='Islamabad', predicted=\" Islam\", (p=0.8355852961540222), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Peru is\"\n",
      "sample.subject='Peru', sample.object='Lima', predicted=\" capital\", (p=0.46575939655303955), known=(✗)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Russia is\"\n",
      "sample.subject='Russia', sample.object='Moscow', predicted=\" Moscow\", (p=0.9991151690483093), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Saudi Arabia is\"\n",
      "sample.subject='Saudi Arabia', sample.object='Riyadh', predicted=\" \", (p=0.31656473875045776), known=(✗)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of South Korea is\"\n",
      "sample.subject='South Korea', sample.object='Seoul', predicted=\" Seoul\", (p=0.9710599184036255), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Spain is\"\n",
      "sample.subject='Spain', sample.object='Madrid', predicted=\" Madrid\", (p=0.8863762617111206), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of United States is\"\n",
      "sample.subject='United States', sample.object='Washington D.C.', predicted=\" Washington\", (p=0.43413934111595154), known=(✓)\n",
      "2024-02-10 19:39:22 src.operators DEBUG    computing h from prompt \"<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of Venezuela is\"\n",
      "sample.subject='Venezuela', sample.object='Caracas', predicted=\" Richmond\", (p=0.5755122303962708), known=(✗)\n",
      "------------------------------------------------------------\n",
      "Faithfulness (@1) = 0.6842105263157895\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "for sample in test.samples:\n",
    "    predictions = operator(subject = sample.subject).predictions\n",
    "    known_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=predictions[0].token, target=sample.object\n",
    "    )\n",
    "    print(f\"{sample.subject=}, {sample.object=}, \", end=\"\")\n",
    "    print(f'predicted=\"{functional.format_whitespace(predictions[0].token)}\", (p={predictions[0].prob}), known=({functional.get_tick_marker(known_flag)})')\n",
    "    \n",
    "    correct += known_flag\n",
    "    wrong += not known_flag\n",
    "    \n",
    "faithfulness = correct/(correct + wrong)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Faithfulness (@1) = {faithfulness}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a13389",
   "metadata": {},
   "source": [
    "# $causality$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da2f8eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### hparams ###################\n",
    "rank = 100\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "25ac7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-10 19:39:25 src.utils.experiment_utils INFO     setting all seeds to 12345\n"
     ]
    }
   ],
   "source": [
    "experiment_utils.set_seed(12345) # set seed to a constant value for sampling consistency\n",
    "test_targets = functional.random_edit_targets(test.samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d83c9b",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a13c0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Changing the mapping (Argentina -> Buenos Aires) to (Argentina -> Riyadh)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = test.samples[0]\n",
    "target = test_targets[source]\n",
    "\n",
    "f\"Changing the mapping ({source}) to ({source.subject} -> {target.object})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f67c8",
   "metadata": {},
   "source": [
    "### Calculate $\\Delta \\mathbf{s}$ such that $\\mathbf{s} + \\Delta \\mathbf{s} \\approx \\mathbf{s}'$\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img align=\"center\" src=\"../causality_crop\" style=\"width:80%;\"/>\n",
    "</p>\n",
    "\n",
    "Under the relation $r =\\, $*plays the instrument*, and given the subject $s =\\, $*Miles Davis*, the model will predict $o =\\, $*trumpet* **(a)**; and given the subject $s' =\\, $*Cat Stevens*, the model will now predict $o' =\\, $*guiter* **(b)**. \n",
    "\n",
    "If the computation from $\\mathbf{s}$ to $\\mathbf{o}$ is well-approximated by $operator$ parameterized by $W_r$ and $b_r$ **(c)**, then $\\Delta{\\mathbf{s}}$ **(d)** should tell us the direction of change from $\\mathbf{s}$ to $\\mathbf{s}'$. Thus, $\\tilde{\\mathbf{s}}=\\mathbf{s}+\\Delta\\mathbf{s}$ would be an approximation of $\\mathbf{s}'$ and patching $\\tilde{\\mathbf{s}}$ in place of $\\mathbf{s}$ should change the prediction to $o'$ = *guitar* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53c632ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_s(\n",
    "    operator, \n",
    "    source_subject, \n",
    "    target_subject,\n",
    "    rank = 100,\n",
    "    fix_latent_norm = None, # if set, will fix the norms of z_source and z_target\n",
    "):\n",
    "    w_p_inv = functional.low_rank_pinv(\n",
    "        matrix = operator.weight,\n",
    "        rank=rank,\n",
    "    )\n",
    "    hs_and_zs = functional.compute_hs_and_zs(\n",
    "        mt = mt,\n",
    "        prompt_template = operator.prompt_template,\n",
    "        subjects = [source_subject, target_subject],\n",
    "        h_layer= operator.h_layer,\n",
    "        z_layer=-1,\n",
    "    )\n",
    "\n",
    "    z_source = hs_and_zs.z_by_subj[source_subject]\n",
    "    z_target = hs_and_zs.z_by_subj[target_subject]\n",
    "    \n",
    "    z_source *= fix_latent_norm / z_source.norm() if fix_latent_norm is not None else 1.0\n",
    "    z_target *= z_source.norm() / z_target.norm() if fix_latent_norm is not None else 1.0\n",
    "\n",
    "    delta_s = w_p_inv @  (z_target.squeeze() - z_source.squeeze())\n",
    "\n",
    "    return delta_s, hs_and_zs\n",
    "\n",
    "delta_s, hs_and_zs = get_delta_s(\n",
    "    operator = operator,\n",
    "    source_subject = source.subject,\n",
    "    target_subject = target.subject,\n",
    "    rank = rank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab1c7e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' R', 0.591),\n",
       " (' Me', 0.133),\n",
       " (' Saudi', 0.033),\n",
       " (' Jed', 0.024),\n",
       " (' Ri', 0.02),\n",
       " ('\\n', 0.011),\n",
       " (' Mak', 0.006),\n",
       " (' \\\\', 0.006),\n",
       " (' _____', 0.006),\n",
       " (' Dh', 0.005)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import baukit\n",
    "\n",
    "def get_intervention(h, int_layer, subj_idx):\n",
    "    def edit_output(output, layer):\n",
    "        if(layer != int_layer):\n",
    "            return output\n",
    "        functional.untuple(output)[:, subj_idx] = h \n",
    "        return output\n",
    "    return edit_output\n",
    "\n",
    "prompt = operator.prompt_template.format(source.subject)\n",
    "\n",
    "h_index, inputs = functional.find_subject_token_index(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    subject=source.subject,\n",
    ")\n",
    "\n",
    "h_layer, z_layer = models.determine_layer_paths(model = mt, layers = [layer, -1])\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model, layers = [h_layer, z_layer],\n",
    "    edit_output=get_intervention(\n",
    "#         h = hs_and_zs.h_by_subj[source.subject],         # let the computation proceed as usual\n",
    "        h = hs_and_zs.h_by_subj[source.subject] + delta_s, # replace s with s + delta_s\n",
    "        int_layer = h_layer, \n",
    "        subj_idx = h_index\n",
    "    )\n",
    ") as traces:\n",
    "    outputs = mt(\n",
    "        input_ids = inputs.input_ids,\n",
    "        attention_mask = inputs.attention_mask,\n",
    "    )\n",
    "\n",
    "logits = outputs.logits[0][-1] if hasattr(outputs, \"logits\") else outputs[0][-1]\n",
    "lens.interpret_logits(\n",
    "    mt = mt, \n",
    "    logits = logits, \n",
    "    get_proba=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c272c1",
   "metadata": {},
   "source": [
    "## Measuring causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51efa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.editors import LowRankPInvEditor\n",
    "\n",
    "svd = torch.svd(operator.weight.float())\n",
    "editor = LowRankPInvEditor(\n",
    "    lre=operator,\n",
    "    rank=rank,\n",
    "    svd=svd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88be35dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-10 19:39:31 src.editors DEBUG    computing low-rank pinv (rel=<|endoftext|> The capital city of China is Beijing\n",
      "The capital city of Japan is Tokyo\n",
      "The capital city of Italy is Rome\n",
      "The capital city of Brazil is Bras\\u00edlia\n",
      "The capital city of Turkey is Ankara\n",
      "The capital city of {} is)\n",
      "Mapping Argentina -> Riyadh | edit result=' R' (p=0.478) | success=(✓)\n",
      "Mapping Australia -> Buenos Aires | edit result=' Buenos' (p=0.875) | success=(✓)\n",
      "Mapping Canada -> Abuja | edit result=' Lag' (p=0.786) | success=(✗)\n",
      "Mapping Chile -> Lima | edit result=' L' (p=0.947) | success=(✓)\n",
      "Mapping Colombia -> Berlin | edit result=' Berlin' (p=0.891) | success=(✓)\n",
      "Mapping Egypt -> Mexico City | edit result=' Mexico' (p=0.954) | success=(✓)\n",
      "Mapping France -> Riyadh | edit result=' Me' (p=0.477) | success=(✗)\n",
      "Mapping Germany -> Cairo | edit result=' Cairo' (p=0.917) | success=(✓)\n",
      "Mapping India -> Lima | edit result=' L' (p=0.932) | success=(✓)\n",
      "Mapping Mexico -> Santiago | edit result=' Santiago' (p=0.585) | success=(✓)\n",
      "Mapping Nigeria -> Riyadh | edit result=' R' (p=0.425) | success=(✓)\n",
      "Mapping Pakistan -> New Delhi | edit result=' New' (p=0.752) | success=(✓)\n",
      "Mapping Peru -> Caracas | edit result=' Car' (p=0.819) | success=(✓)\n",
      "Mapping Russia -> Cairo | edit result=' Cairo' (p=0.885) | success=(✓)\n",
      "Mapping Saudi Arabia -> Caracas | edit result=' Car' (p=0.612) | success=(✓)\n",
      "Mapping South Korea -> Cairo | edit result=' Cairo' (p=0.892) | success=(✓)\n",
      "Mapping Spain -> Islamabad | edit result=' Islam' (p=0.696) | success=(✓)\n",
      "Mapping United States -> Ottawa | edit result=' Ottawa' (p=0.825) | success=(✓)\n",
      "Mapping Venezuela -> Madrid | edit result=' Madrid' (p=0.945) | success=(✓)\n",
      "------------------------------------------------------------\n",
      "Causality (@1) = 0.8947368421052632\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# precomputing latents to speed things up\n",
    "hs_and_zs = functional.compute_hs_and_zs(\n",
    "    mt = mt,\n",
    "    prompt_template = operator.prompt_template,\n",
    "    subjects = [sample.subject for sample in test.samples],\n",
    "    h_layer= operator.h_layer,\n",
    "    z_layer=-1,\n",
    "    batch_size = 2\n",
    ")\n",
    "\n",
    "success = 0\n",
    "fails = 0\n",
    "\n",
    "for sample in test.samples:\n",
    "    target = test_targets.get(sample)\n",
    "    assert target is not None\n",
    "    edit_result = editor(\n",
    "        subject = sample.subject,\n",
    "        target = target.subject\n",
    "    )\n",
    "    \n",
    "    success_flag = functional.is_nontrivial_prefix(\n",
    "        prediction=edit_result.predicted_tokens[0].token, target=target.object\n",
    "    )\n",
    "    \n",
    "    print(f\"Mapping {sample.subject} -> {target.object} | edit result={edit_result.predicted_tokens[0]} | success=({functional.get_tick_marker(success_flag)})\")\n",
    "    \n",
    "    success += success_flag\n",
    "    fails += not success_flag\n",
    "    \n",
    "causality = success / (success + fails)\n",
    "\n",
    "print(\"------------------------------------------------------------\")\n",
    "print(f\"Causality (@1) = {causality}\")\n",
    "print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d14acef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.functional import save_linear_operator\n",
    "\n",
    "save_linear_operator(\n",
    "    approx = operator,\n",
    "    file_name = \"lre_capital\",\n",
    "    path = \"cached\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1cbbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_loaded = functional.load_cached_linear_operator(mt = mt, file_path = \"cached/lre_capital.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2069b",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c55042",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = mt.tokenizer.eos_token + \" Michael Jordan professionally played the sport of\"\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "models.determine_layer_paths(mt)[layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5459d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baukit\n",
    "\n",
    "layer_out = models.determine_layer_paths(mt)[layer]\n",
    "mixer_out = models.determine_layer_paths(mt)[layer] + \".mixer\"\n",
    "layer_in = models.determine_layer_paths(mt)[layer+1]\n",
    "final_layer = models.determine_layer_paths(mt)[-1]\n",
    "final_mixer = models.determine_layer_paths(mt)[-1] + \".mixer\"\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    module=mt.model,\n",
    "    layers=[\n",
    "        layer_out,\n",
    "        mixer_out,\n",
    "        layer_in,\n",
    "        final_mixer,\n",
    "        final_layer,\n",
    "        \"backbone\"\n",
    "    ],\n",
    "    retain_input=True,\n",
    ") as traces:\n",
    "    output = mt(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87121bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[\"backbone\"].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7473e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[final_layer].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,\n",
    "                 d_model: int,\n",
    "                 eps: float = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = baukit.get_module(mt.model, \"backbone.norm_f\").weight\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps) * self.weight\n",
    "\n",
    "        return output\n",
    "\n",
    "custom_rms = RMSNorm(d_model = models.determine_hidden_size(mt))\n",
    "block_output, residual = traces[final_layer].output\n",
    "backbone_output = custom_rms(block_output + residual)\n",
    "\n",
    "backbone_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(traces[mixer_out].output, traces[layer_out].output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c1334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "baukit.get_module(mt.model, \"backbone.norm_f\").bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96443785",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(mt.model, \"backbone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ecaaf9c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Time: 46.666666666666664 hours, Size: 20.3125 GB'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers = 32\n",
    "n_approx = 25\n",
    "time_per_approx = 7 # in minutes\n",
    "size_per_approx = 26 # in MB\n",
    "n_threads = 2\n",
    "\n",
    "\n",
    "total_time = n_layers * n_approx * time_per_approx\n",
    "total_time /= n_threads\n",
    "total_time /= 60\n",
    "\n",
    "total_size = n_layers * n_approx * size_per_approx\n",
    "total_size /= 1024\n",
    "\n",
    "f\"Time: {total_time} hours, Size: {total_size} GB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4285ebcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "layers = np.arange(0, 64, 2).tolist()\n",
    "layers[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f7ae65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46, 50, 54, 58, 62]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f6ee9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 4 8 12 16 20 24 28 32 36 40 44 48 52 56 60'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([str(l) for l in layers[::2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a8ef6748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.666666666666664"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(16 * time_per_approx * n_approx)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c101157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21 * 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8c4b8862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(47 * 32 * 25 * 26) // 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a2ccdb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "512/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6272f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
