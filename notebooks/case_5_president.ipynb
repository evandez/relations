{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import transformers\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from relations import estimate\n",
    "from util import model_utils\n",
    "from baukit import nethook\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/gpt-j-6B ==> device: cuda:0, memory: 12219206136\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\" # \"facebook/galactica-6.7b\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "n_embd_field = \"hidden_size\"\n",
    "\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "print(f\"{MODEL_NAME} ==> device: {model.device}, memory: {model.get_memory_footprint()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George Washington',\n",
       " 'John Adams',\n",
       " 'Thomas Jefferson',\n",
       " 'James Madison',\n",
       " 'James Monroe',\n",
       " 'John Quincy Adams',\n",
       " 'Andrew Jackson',\n",
       " 'Martin Van Buren',\n",
       " 'William Henry Harrison',\n",
       " 'John Tyler',\n",
       " 'James K. Polk',\n",
       " 'Zachary Taylor',\n",
       " 'Millard Fillmore',\n",
       " 'Franklin Pierce',\n",
       " 'James Buchanan',\n",
       " 'Abraham Lincoln',\n",
       " 'Andrew Johnson',\n",
       " 'Ulysses S. Grant',\n",
       " 'Rutherford B. Hayes',\n",
       " 'James Garfield',\n",
       " 'Chester A. Arthur',\n",
       " 'Grover Cleveland',\n",
       " 'Benjamin Harrison',\n",
       " 'Grover Cleveland',\n",
       " 'William McKinley',\n",
       " 'Theodore Roosevelt',\n",
       " 'William Howard Taft',\n",
       " 'Woodrow Wilson',\n",
       " 'Warren G. Harding',\n",
       " 'Calvin Coolidge',\n",
       " 'Herbert Hoover',\n",
       " 'Franklin D. Roosevelt',\n",
       " 'Harry S. Truman',\n",
       " 'Dwight D. Eisenhower',\n",
       " 'John F. Kennedy',\n",
       " 'Lyndon B. Johnson',\n",
       " 'Richard M. Nixon',\n",
       " 'Gerald R. Ford',\n",
       " 'James Carter',\n",
       " 'Ronald Reagan',\n",
       " 'George H. W. Bush',\n",
       " 'William J. Clinton',\n",
       " 'George W. Bush',\n",
       " 'Barack Obama',\n",
       " 'Donald Trump',\n",
       " 'Joe Biden']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents = []\n",
    "with open(\"data/list_of_potus.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    presidents = [p.strip() for p in lines[1:len(lines):3]]\n",
    "\n",
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard M. Nixon was succeeded by Gerald R. Ford\n",
      "Woodrow Wilson was succeeded by Warren G. Harding\n",
      "James Carter was succeeded by Ronald Reagan\n",
      "{} was succeeded by\n"
     ]
    }
   ],
   "source": [
    "relation_prompt = \"was succeeded by\"\n",
    "prev_presidents = random.sample(range(len(presidents)-1), k = 3)\n",
    "\n",
    "icl_prompt = \"\"\n",
    "for p in prev_presidents:\n",
    "    icl_prompt += f\"{presidents[p]} {relation_prompt} {presidents[p+1]}\\n\"\n",
    "icl_prompt += \"{} \" + relation_prompt\n",
    "print(icl_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington >> John Adams ===> [(' John', 0.5504), (' George', 0.0637), (' James', 0.0466), (' William', 0.0405), (' Thomas', 0.0375)] :: True\n",
      "John Adams >> Thomas Jefferson ===> [(' John', 0.5808), (' Thomas', 0.1492), (' James', 0.1009), (' George', 0.0524), (' Benjamin', 0.0165)] :: False\n",
      "Thomas Jefferson >> James Madison ===> [(' James', 0.5005), (' John', 0.2328), (' Andrew', 0.0926), (' Martin', 0.033), (' George', 0.0223)] :: True\n",
      "James Madison >> James Monroe ===> [(' James', 0.5485), (' John', 0.1168), (' Thomas', 0.0841), (' William', 0.0828), (' George', 0.0345)] :: True\n",
      "James Monroe >> John Quincy Adams ===> [(' John', 0.7057), (' Andrew', 0.0677), (' William', 0.0544), (' James', 0.0465), (' Thomas', 0.0346)] :: True\n",
      "John Quincy Adams >> Andrew Jackson ===> [(' Andrew', 0.2332), (' John', 0.1845), (' Martin', 0.1415), (' William', 0.1288), (' James', 0.0722)] :: True\n",
      "Andrew Jackson >> Martin Van Buren ===> [(' Martin', 0.7347), (' John', 0.092), (' William', 0.0622), (' James', 0.0285), (' Bill', 0.0137)] :: True\n",
      "Martin Van Buren >> William Henry Harrison ===> [(' William', 0.5409), (' John', 0.0804), (' James', 0.057), (' Martin', 0.0561), (' Andrew', 0.0411)] :: True\n",
      "William Henry Harrison >> John Tyler ===> [(' Benjamin', 0.5494), (' John', 0.3034), (' William', 0.0656), (' Andrew', 0.0104), (' Martin', 0.0085)] :: False\n",
      "John Tyler >> James K. Polk ===> [(' William', 0.3463), (' James', 0.21), (' Martin', 0.161), (' Mill', 0.104), (' Andrew', 0.0232)] :: False\n",
      "James K. Polk >> Zachary Taylor ===> [(' James', 0.1961), (' Zach', 0.1961), (' William', 0.1458), (' Franklin', 0.0844), (' Martin', 0.0688)] :: False\n",
      "Zachary Taylor >> Millard Fillmore ===> [(' U', 0.2742), (' Mill', 0.2345), (' Abraham', 0.2238), (' Andrew', 0.0641), (' John', 0.0333)] :: False\n",
      "Millard Fillmore >> Franklin Pierce ===> [(' Franklin', 0.2949), (' Zach', 0.2369), (' Martin', 0.0988), (' William', 0.0988), (' Abraham', 0.0885)] :: True\n",
      "Franklin Pierce >> James Buchanan ===> [(' James', 0.4738), (' Abraham', 0.0773), (' Chester', 0.0738), (' John', 0.0693), (' Martin', 0.0593)] :: True\n",
      "James Buchanan >> Abraham Lincoln ===> [(' Abraham', 0.7852), (' William', 0.0828), (' Andrew', 0.0345), (' Franklin', 0.0171), (' Gro', 0.0171)] :: True\n",
      "Abraham Lincoln >> Andrew Johnson ===> [(' Andrew', 0.468), (' James', 0.0921), (' U', 0.0718), (' William', 0.0429), (' Lyndon', 0.0355)] :: True\n",
      "Andrew Johnson >> Ulysses S. Grant ===> [(' U', 0.6674), (' Lyndon', 0.0822), (' Abraham', 0.0726), (' Martin', 0.0218), (' Rutherford', 0.0215)] :: True\n",
      "Ulysses S. Grant >> Rutherford B. Hayes ===> [(' Rutherford', 0.5431), (' Chester', 0.1417), (' Gro', 0.082), (' Andrew', 0.0649), (' William', 0.0446)] :: True\n",
      "Rutherford B. Hayes >> James Garfield ===> [(' James', 0.2148), (' U', 0.1699), (' Benjamin', 0.1365), (' William', 0.1344), (' Rutherford', 0.0815)] :: True\n",
      "James Garfield >> Chester A. Arthur ===> [(' Chester', 0.9773), (' William', 0.0064), (' Arthur', 0.0043), (' Andrew', 0.0035), (' Rutherford', 0.0019)] :: True\n",
      "Chester A. Arthur >> Grover Cleveland ===> [(' Gro', 0.8232), (' William', 0.0854), (' Benjamin', 0.0391), (' Theodore', 0.0188), (' Chester', 0.0104)] :: True\n",
      "Grover Cleveland >> Benjamin Harrison ===> [(' Benjamin', 0.9271), (' William', 0.0447), (' Theodore', 0.0044), (' James', 0.0033), (' Calvin', 0.0028)] :: True\n",
      "Benjamin Harrison >> Grover Cleveland ===> [(' William', 0.7008), (' Gro', 0.154), (' Benjamin', 0.0402), (' Calvin', 0.0184), (' Chester', 0.0157)] :: False\n",
      "Grover Cleveland >> William McKinley ===> [(' Benjamin', 0.9271), (' William', 0.0447), (' Theodore', 0.0044), (' James', 0.0033), (' Calvin', 0.0028)] :: False\n",
      "William McKinley >> Theodore Roosevelt ===> [(' William', 0.5135), (' Theodore', 0.3999), (' Benjamin', 0.0313), (' Gro', 0.0148), (' Teddy', 0.0064)] :: False\n",
      "Theodore Roosevelt >> William Howard Taft ===> [(' William', 0.7518), (' Calvin', 0.1413), (' Franklin', 0.0245), (' Herbert', 0.0151), (' his', 0.0073)] :: True\n",
      "William Howard Taft >> Woodrow Wilson ===> [(' Calvin', 0.2776), (' William', 0.1849), (' Theodore', 0.1176), (' Herbert', 0.0916), (' Wood', 0.0475)] :: False\n",
      "Woodrow Wilson >> Warren G. Harding ===> [(' Calvin', 0.2261), (' Franklin', 0.1102), (' Warren', 0.0988), (' Harry', 0.0858), (' James', 0.0581)] :: False\n",
      "Warren G. Harding >> Calvin Coolidge ===> [(' Calvin', 0.8961), (' Herbert', 0.0192), (' John', 0.0126), (' Franklin', 0.0122), (' James', 0.0083)] :: True\n",
      "Calvin Coolidge >> Herbert Hoover ===> [(' Herbert', 0.8366), (' Warren', 0.0645), (' Charles', 0.0423), (' Calvin', 0.0291), (' John', 0.0076)] :: True\n",
      "Herbert Hoover >> Franklin D. Roosevelt ===> [(' Franklin', 0.3398), (' Jimmy', 0.1532), (' Calvin', 0.1394), (' Richard', 0.0638), (' John', 0.0563)] :: True\n",
      "Franklin D. Roosevelt >> Harry S. Truman ===> [(' Harry', 0.3467), (' John', 0.1256), (' Dwight', 0.1236), (' Herbert', 0.0963), ('\\n', 0.0318)] :: True\n",
      "Harry S. Truman >> Dwight D. Eisenhower ===> [(' Dwight', 0.8381), (' John', 0.0411), (' D', 0.0171), (' Richard', 0.0151), (' Bill', 0.014)] :: True\n",
      "Dwight D. Eisenhower >> John F. Kennedy ===> [(' John', 0.6009), (' Richard', 0.2013), (' Gerald', 0.0256), (' Jimmy', 0.0222), (' Bill', 0.0222)] :: True\n",
      "John F. Kennedy >> Lyndon B. Johnson ===> [(' Lyndon', 0.8652), (' Richard', 0.0733), (' Barack', 0.0123), (' Gerald', 0.0058), (' John', 0.0057)] :: True\n",
      "Lyndon B. Johnson >> Richard M. Nixon ===> [(' Richard', 0.8871), (' Jimmy', 0.0449), (' John', 0.0157), (' Hu', 0.0117), (' Gerald', 0.0044)] :: True\n",
      "Richard M. Nixon >> Gerald R. Ford ===> [(' Gerald', 0.4281), (' Jimmy', 0.2637), (' George', 0.1152), (' Ronald', 0.0357), (' James', 0.0261)] :: True\n",
      "Gerald R. Ford >> James Carter ===> [(' Jimmy', 0.846), (' Richard', 0.0378), (' James', 0.0303), (' George', 0.0259), ('\\n', 0.0077)] :: False\n",
      "James Carter >> Ronald Reagan ===> [(' Jimmy', 0.3724), (' George', 0.2258), (' Bill', 0.1307), (' William', 0.0386), (' Ronald', 0.0352)] :: False\n",
      "Ronald Reagan >> George H. W. Bush ===> [(' George', 0.7171), (' Bill', 0.1083), (' Barack', 0.0411), (' William', 0.0234), (' Jimmy', 0.0163)] :: True\n",
      "George H. W. Bush >> William J. Clinton ===> [(' Bill', 0.8261), (' William', 0.0971), (' George', 0.0459), (' Clinton', 0.0063), (' Barack', 0.0028)] :: False\n",
      "William J. Clinton >> George W. Bush ===> [(' George', 0.82), (' Barack', 0.1059), (' Bill', 0.0318), (' Donald', 0.0105), (' William', 0.0074)] :: True\n",
      "George W. Bush >> Barack Obama ===> [(' Barack', 0.7891), (' Bill', 0.1329), (' George', 0.0122), (' Donald', 0.0099), (' Barr', 0.0065)] :: True\n",
      "Barack Obama >> Donald Trump ===> [(' Donald', 0.9808), (' Barack', 0.0034), (' Trump', 0.0028), (' Hillary', 0.0017), (' George', 0.0012)] :: True\n",
      "Donald Trump >> Joe Biden ===> [(' Barack', 0.2214), (' Donald', 0.1385), (' Hillary', 0.1301), (' Bill', 0.0967), (' Mike', 0.0359)] :: False\n"
     ]
    }
   ],
   "source": [
    "filter_by_model_knowledge = []\n",
    "for prev, nxt in zip(presidents[:-1], presidents[1:]):\n",
    "    txt, ret_dict = model_utils.generate_fast(\n",
    "        model, tokenizer, \n",
    "        prompts=[icl_prompt.format(prev)], max_new_tokens=10, \n",
    "        get_answer_tokens=True, argmax_greedy=True\n",
    "    )\n",
    "\n",
    "    tick = nxt.startswith(ret_dict['answer'][0]['top_token'].strip())\n",
    "    print(f\"{prev} >> {nxt} ===> {[(ans['token'], ans['p']) for ans in ret_dict['answer'][0]['candidates']]} :: {tick}\")\n",
    "    if(tick):\n",
    "        filter_by_model_knowledge.append((prev, nxt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_by_model_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [\" \" + o[1] for o in filter_by_model_knowledge]\n",
    "\n",
    "from relations.corner import CornerEstimator\n",
    "corner_estimator = CornerEstimator(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    ln_f_name= \"model.decoder.final_layer_norm\", \n",
    "    unembedder_module_name=\"lm_head\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.171875 [(' bird', 39.188), (' plant', 37.25), (' fish', 35.812), (' food', 33.125), (' game', 32.438)]\n"
     ]
    }
   ],
   "source": [
    "simple_corner = corner_estimator.estimate_simple_corner(objects, scale_up=70)\n",
    "print(simple_corner.norm().item(), corner_estimator.get_vocab_representation(simple_corner, get_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating inverse of unbedding weights . . .\n",
      "18.265625 [(' plant', 23.969), (' bird', 22.859), (' game', 21.344), (' person', 20.828), (' drug', 20.594)]\n"
     ]
    }
   ],
   "source": [
    "lin_inv_corner = corner_estimator.estimate_lin_inv_corner(objects, target_logit_value=50)\n",
    "print(lin_inv_corner.norm().item(), corner_estimator.get_vocab_representation(lin_inv_corner, get_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.875 [(' galaxy', 24.406), (' material', 24.266), (' group', 24.266), (' star', 24.266), (' human', 24.266)]\n"
     ]
    }
   ],
   "source": [
    "lst_sq_corner = corner_estimator.estimate_corner_lstsq_solve(objects, target_logit=50)\n",
    "print(lst_sq_corner.norm().item(), corner_estimator.get_vocab_representation(lst_sq_corner, get_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_corner = corner_estimator.estimate_average_corner_with_gradient_descent(objects, average_on=5, target_logit_value=50, verbose=False)\n",
    "# print(avg_corner.norm().item(), corner_estimator.get_vocab_representation(avg_corner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_with_test_cases(relation_operator):\n",
    "    test_cases = [\n",
    "        (b, -1, h) for b, h in filter_by_model_knowledge[20:]\n",
    "    ]\n",
    "    for subject, subject_token_index, target in test_cases:\n",
    "        answer = relation_operator(\n",
    "            subject,\n",
    "            subject_token_index=subject_token_index,\n",
    "            device=model.device,\n",
    "            return_top_k=5,\n",
    "        )\n",
    "        print(f\"{subject}, target: {target}   ==>   predicted: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer, target: season   ==>   predicted: [' season', ' group', ' color', ' wind', ' plant']\n",
      "meat, target: food   ==>   predicted: [' science', ' group', ' color', ' plant', ' food']\n",
      "doll, target: toy   ==>   predicted: [' tree', ' shape', ' fish', ' star', ' group']\n",
      "gold, target: metal   ==>   predicted: [' metal', ' tree', ' wind', ' star', ' color']\n",
      "round, target: shape   ==>   predicted: [' shape', ' plant', ' wind', ' food', ' color']\n",
      "breeze, target: wind   ==>   predicted: [' color', ' tree', ' metal', ' plant', ' season']\n",
      "man, target: human   ==>   predicted: [' group', ' person', ' plant', ' color', ' food']\n",
      "hologram, target: picture   ==>   predicted: [' metal', ' color', ' device', ' tree', ' plant']\n",
      "paper, target: material   ==>   predicted: [' science', ' plant', ' wind', ' material', ' group']\n",
      "photographer, target: person   ==>   predicted: [' group', ' fish', ' tree', ' game', ' drug']\n",
      "documentary, target: film   ==>   predicted: [' film', ' material', ' science', ' group', ' star']\n",
      "anesthetic, target: drug   ==>   predicted: [' group', ' plant', ' drug', ' color', ' material']\n",
      "salad, target: dish   ==>   predicted: [' tree', ' group', ' plant', ' food', ' color']\n",
      "thumb, target: finger   ==>   predicted: [' group', ' food', ' tree', ' shape', ' plant']\n"
     ]
    }
   ],
   "source": [
    "relation = estimate.RelationOperator(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    relation = prompt,\n",
    "    layer = 15,\n",
    "    weight = torch.eye(getattr(model.config, n_embd_field)).to(model.dtype).to(model.device),\n",
    "    bias = lst_sq_corner,\n",
    "\n",
    "    layer_name_format = \"model.decoder.layers.{}\",\n",
    "    ln_f_name = \"model.decoder.final_layer_norm\"\n",
    ")\n",
    "check_with_test_cases(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_JB(top_performers, relation_prompt, num_icl = 3, calculate_at_lnf = False):\n",
    "    try:\n",
    "        jbs = []\n",
    "        for s, s_idx, o in tqdm(top_performers):\n",
    "            others = set(top_performers) - {(s, s_idx, o)}\n",
    "            others = random.sample(list(others), k = min(num_icl, len(list(others)))) \n",
    "            prompt = \"\"\n",
    "            prompt += \"\\n\".join(relation_prompt.format(s_other) + f\" {o_other}.\" for s_other, idx_other, o_other in others) + \"\\n\"\n",
    "            prompt += relation_prompt\n",
    "            print(\"subject: \", s)\n",
    "            print(prompt)\n",
    "\n",
    "            jb, _ = estimate.relation_operator_from_sample(\n",
    "                model, tokenizer,\n",
    "                s, prompt,\n",
    "                subject_token_index= s_idx,\n",
    "                layer = 15,\n",
    "                device = model.device,\n",
    "                # calculate_at_lnf = calculate_at_lnf\n",
    "\n",
    "                layer_name_format = \"model.decoder.layers.{}\",\n",
    "                ln_f_name = \"model.decoder.final_layer_norm\",\n",
    "                n_layer_field = \"num_hidden_layers\"\n",
    "            )\n",
    "            print(jb.weight.norm(), jb.bias.norm())\n",
    "            print()\n",
    "            jbs.append(jb)\n",
    "        \n",
    "        weight = torch.stack([jb.weight for jb in jbs]).mean(dim=0)\n",
    "        bias  = torch.stack([jb.bias for jb in jbs]).mean(dim=0)\n",
    "\n",
    "        return weight, bias\n",
    "    except RuntimeError as e:\n",
    "        if(str(e).startswith(\"CUDA out of memory\")):\n",
    "            print(\"CUDA out of memory\")\n",
    "        if(num_icl > 1):\n",
    "            num_icl -= 1\n",
    "            print(\"trying with smaller icl >> \", num_icl)\n",
    "            return get_averaged_JB(top_performers, relation_prompt, num_icl, calculate_at_lnf)\n",
    "        else:\n",
    "            raise Exception(\"RuntimeError >> can't calculate Jacobian with minimum number of icl examples\")\n",
    "\n",
    "def get_multiple_averaged_JB(top_performers, relation_prompt, N = 3, num_icl = 2, calculate_at_lnf = False):\n",
    "    weights_and_biases = []\n",
    "    sample_size = min(len(top_performers), num_icl + 2)\n",
    "    for _ in tqdm(range(N)):\n",
    "        cur_sample = random.sample(top_performers, k = sample_size)\n",
    "        weight, bias = get_averaged_JB(cur_sample, relation_prompt, num_icl, calculate_at_lnf)\n",
    "        weights_and_biases.append({\n",
    "            'weight': weight,\n",
    "            'bias'  : bias\n",
    "        })\n",
    "    return weights_and_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oak', -1, 'tree'), ('diamond', -1, 'gem'), ('happiness', -1, 'feeling'), ('family', -1, 'group'), ('thesaurus', -1, 'dictionary'), ('crow', -1, 'bird'), ('tennis', -1, 'sport'), ('salmon', -1, 'fish'), ('flower', -1, 'plant'), ('rosemary', -1, 'herb'), ('cucumber', -1, 'vegetable'), ('roulette', -1, 'game'), ('physics', -1, 'science'), ('earth', -1, 'planet'), ('sun', -1, 'star'), ('coffee', -1, 'beverage'), ('car', -1, 'vehicle'), ('yellow', -1, 'color'), ('fan', -1, 'device'), ('judaism', -1, 'religion')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0589753fcff74a319bddbdd904813c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7d793af820478d9c790a86a8efc35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  cucumber\n",
      " family is a group.\n",
      " roulette is a game.\n",
      " {} is a\n",
      "tensor(43.0938, device='cuda:0', dtype=torch.float16) tensor(248.8750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  roulette\n",
      " coffee is a beverage.\n",
      " cucumber is a vegetable.\n",
      " {} is a\n",
      "tensor(57.5938, device='cuda:0', dtype=torch.float16) tensor(274.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  family\n",
      " roulette is a game.\n",
      " coffee is a beverage.\n",
      " {} is a\n",
      "tensor(46.7500, device='cuda:0', dtype=torch.float16) tensor(253.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  coffee\n",
      " roulette is a game.\n",
      " cucumber is a vegetable.\n",
      " {} is a\n",
      "tensor(40.3438, device='cuda:0', dtype=torch.float16) tensor(264., device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79e747018ab493eb81bd7843e20d963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  happiness\n",
      " roulette is a game.\n",
      " yellow is a color.\n",
      " {} is a\n",
      "tensor(38., device='cuda:0', dtype=torch.float16) tensor(259.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  roulette\n",
      " happiness is a feeling.\n",
      " yellow is a color.\n",
      " {} is a\n",
      "tensor(53.2812, device='cuda:0', dtype=torch.float16) tensor(281.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  yellow\n",
      " fan is a device.\n",
      " roulette is a game.\n",
      " {} is a\n",
      "tensor(43.8750, device='cuda:0', dtype=torch.float16) tensor(227.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  fan\n",
      " roulette is a game.\n",
      " happiness is a feeling.\n",
      " {} is a\n",
      "tensor(52.8750, device='cuda:0', dtype=torch.float16) tensor(256.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ec468fe8aa458db75f7dad43c60405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  happiness\n",
      " cucumber is a vegetable.\n",
      " diamond is a gem.\n",
      " {} is a\n",
      "tensor(40.4375, device='cuda:0', dtype=torch.float16) tensor(250.3750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  diamond\n",
      " earth is a planet.\n",
      " happiness is a feeling.\n",
      " {} is a\n",
      "tensor(45.1875, device='cuda:0', dtype=torch.float16) tensor(254.3750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  cucumber\n",
      " earth is a planet.\n",
      " happiness is a feeling.\n",
      " {} is a\n",
      "tensor(40.7812, device='cuda:0', dtype=torch.float16) tensor(249.6250, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  earth\n",
      " cucumber is a vegetable.\n",
      " diamond is a gem.\n",
      " {} is a\n",
      "tensor(49.3125, device='cuda:0', dtype=torch.float16) tensor(235.6250, device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "        (b, -1, h) for b, h in filter_by_model_knowledge[:20]\n",
    "    ]\n",
    "print(samples)\n",
    "\n",
    "weights_and_biases = get_multiple_averaged_JB(\n",
    "    samples, \n",
    "    relation_prompt=\" {} is a\", \n",
    "    N = 3, \n",
    "    calculate_at_lnf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer, target: season   ==>   predicted: [' season', ' color', ' wind', ' herb', ' plant']\n",
      "meat, target: food   ==>   predicted: [' food', ' dish', ' vegetable', ' material', ' meat']\n",
      "doll, target: toy   ==>   predicted: [' toy', ' shape', ' picture', ' bird', ' person']\n",
      "gold, target: metal   ==>   predicted: [' metal', ' material', ' gem', ' color', ' religion']\n",
      "round, target: shape   ==>   predicted: [' shape', ' sport', ' season', ' wind', ' galaxy']\n",
      "breeze, target: wind   ==>   predicted: [' wind', ' season', ' feeling', ' herb', ' color']\n",
      "man, target: human   ==>   predicted: [' human', ' person', ' vehicle', ' fish', ' sport']\n",
      "hologram, target: picture   ==>   predicted: [' device', ' picture', ' material', ' science', ' film']\n",
      "paper, target: material   ==>   predicted: [' material', ' wind', ' dish', ' dictionary', ' vehicle']\n",
      "photographer, target: person   ==>   predicted: [' person', ' science', ' star', ' human', ' sport']\n",
      "documentary, target: film   ==>   predicted: [' film', ' picture', ' wind', ' dish', ' science']\n",
      "anesthetic, target: drug   ==>   predicted: [' drug', ' herb', ' feeling', ' beverage', ' material']\n",
      "salad, target: dish   ==>   predicted: [' dish', ' food', ' vegetable', ' season', ' beverage']\n",
      "thumb, target: finger   ==>   predicted: [' finger', ' shape', ' fish', ' device', ' star']\n"
     ]
    }
   ],
   "source": [
    "relation_operator = estimate.RelationOperator(\n",
    "    model = model,\n",
    "    tokenizer= tokenizer,\n",
    "    relation = prompt,\n",
    "    layer = 15,\n",
    "    weight = torch.stack(\n",
    "        [wb['weight'] for wb in weights_and_biases]\n",
    "    ).mean(dim=0),\n",
    "    # bias = torch.stack(\n",
    "    #     [wb['bias'] for wb in weights_and_biases]\n",
    "    # ).mean(dim=0),\n",
    "    bias = lst_sq_corner,\n",
    "\n",
    "    layer_name_format = \"model.decoder.layers.{}\",\n",
    "    ln_f_name = \"model.decoder.final_layer_norm\",\n",
    ")\n",
    "\n",
    "check_with_test_cases(relation_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' type', ' kind', ' good', ' ', ' very']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner_estimator.get_vocab_representation(\n",
    "    torch.stack(\n",
    "        [wb['bias'] for wb in weights_and_biases]\n",
    "    ).mean(dim=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4104f34302edfbfea7294aa0a5e7d82342a152e8e30f6673f70b28d5f99d4ac0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
