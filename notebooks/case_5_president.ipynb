{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import transformers\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from relations import estimate\n",
    "from util import model_utils\n",
    "from baukit import nethook\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook/galactica-6.7b ==> device: cuda:0, memory: 13314719744\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"facebook/galactica-6.7b\" # \"EleutherAI/gpt-j-6B\"\n",
    "n_embd_field = \"hidden_size\"\n",
    "\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "print(f\"{MODEL_NAME} ==> device: {model.device}, memory: {model.get_memory_footprint()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['George Washington',\n",
       " 'John Adams',\n",
       " 'Thomas Jefferson',\n",
       " 'James Madison',\n",
       " 'James Monroe',\n",
       " 'John Quincy Adams',\n",
       " 'Andrew Jackson',\n",
       " 'Martin Van Buren',\n",
       " 'William Henry Harrison',\n",
       " 'John Tyler',\n",
       " 'James K. Polk',\n",
       " 'Zachary Taylor',\n",
       " 'Millard Fillmore',\n",
       " 'Franklin Pierce',\n",
       " 'James Buchanan',\n",
       " 'Abraham Lincoln',\n",
       " 'Andrew Johnson',\n",
       " 'Ulysses S. Grant',\n",
       " 'Rutherford B. Hayes',\n",
       " 'James Garfield',\n",
       " 'Chester A. Arthur',\n",
       " 'Grover Cleveland',\n",
       " 'Benjamin Harrison',\n",
       " 'Grover Cleveland',\n",
       " 'William McKinley',\n",
       " 'Theodore Roosevelt',\n",
       " 'William Howard Taft',\n",
       " 'Woodrow Wilson',\n",
       " 'Warren G. Harding',\n",
       " 'Calvin Coolidge',\n",
       " 'Herbert Hoover',\n",
       " 'Franklin D. Roosevelt',\n",
       " 'Harry S. Truman',\n",
       " 'Dwight D. Eisenhower',\n",
       " 'John F. Kennedy',\n",
       " 'Lyndon B. Johnson',\n",
       " 'Richard M. Nixon',\n",
       " 'Gerald R. Ford',\n",
       " 'James Carter',\n",
       " 'Ronald Reagan',\n",
       " 'George H. W. Bush',\n",
       " 'William J. Clinton',\n",
       " 'George W. Bush',\n",
       " 'Barack Obama',\n",
       " 'Donald Trump',\n",
       " 'Joe Biden']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents = []\n",
    "with open(\"data/list_of_potus.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    presidents = [p.strip() for p in lines[1:len(lines):3]]\n",
    "\n",
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation_prompt = \"was succeeded by\"\n",
    "# prev_presidents = random.sample(range(len(presidents)-1), k = 3)\n",
    "\n",
    "# icl_prompt = \"\"\n",
    "# for p in prev_presidents:\n",
    "#     icl_prompt += f\"{presidents[p]} {relation_prompt} {presidents[p+1]}\\n\"\n",
    "# icl_prompt += \"{} \" + relation_prompt\n",
    "# print(icl_prompt)\n",
    "\n",
    "icl_prompt = \"\"\"Richard M. Nixon was succeeded by Gerald R. Ford\n",
    "Woodrow Wilson was succeeded by Warren G. Harding\n",
    "James Carter was succeeded by Ronald Reagan\n",
    "{} was succeeded by\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington >> John Adams ===> [(' Abraham', 0.4851), (' Theod', 0.1306), (' Thomas', 0.0683), (' John', 0.0371), (' Dw', 0.0312)] :: False\n",
      "John Adams >> Thomas Jefferson ===> [(' Ly', 0.1379), (' John', 0.1041), (' Harry', 0.0798), (' Theod', 0.0786), (' Franklin', 0.0773)] :: False\n",
      "Thomas Jefferson >> James Madison ===> [(' James', 0.1458), (' Theod', 0.1277), (' George', 0.0986), (' John', 0.0986), (' Abraham', 0.0898)] :: True\n",
      "James Madison >> James Monroe ===> [(' Abraham', 0.1854), (' Theod', 0.1586), (' John', 0.0977), (' Wood', 0.0732), (' William', 0.0693)] :: False\n",
      "James Monroe >> John Quincy Adams ===> [(' Theod', 0.2141), (' Harry', 0.1309), (' William', 0.1219), (' Herbert', 0.106), (' Cal', 0.0459)] :: False\n",
      "John Quincy Adams >> Andrew Jackson ===> [(' Theod', 0.1938), (' William', 0.1261), (' Franklin', 0.0967), (' Herbert', 0.0629), (' Ly', 0.062)] :: False\n",
      "Andrew Jackson >> Martin Van Buren ===> [(' Bill', 0.2067), (' Ly', 0.1177), (' John', 0.0714), (' Jimmy', 0.0682), (' Andrew', 0.0531)] :: False\n",
      "Martin Van Buren >> William Henry Harrison ===> [(' Herbert', 0.1642), (' G', 0.1483), (' Franklin', 0.1372), (' Dw', 0.1183), (' William', 0.0706)] :: False\n",
      "William Henry Harrison >> John Tyler ===> [(' Benjamin', 0.3325), (' Theod', 0.1204), (' John', 0.0847), (' Abraham', 0.0686), (' Thomas', 0.0649)] :: False\n",
      "John Tyler >> James K. Polk ===> [(' Ly', 0.2051), (' William', 0.1097), (' Theod', 0.0809), (' George', 0.0487), (' Richard', 0.044)] :: False\n",
      "James K. Polk >> Zachary Taylor ===> [(' Franklin', 0.2416), (' Theod', 0.142), (' William', 0.1366), (' Herbert', 0.115), (' Harry', 0.0465)] :: False\n",
      "Zachary Taylor >> Millard Fillmore ===> [(' Donald', 0.3997), (' Bill', 0.2969), (' George', 0.1627), (' John', 0.0191), (' Bar', 0.0112)] :: False\n",
      "Millard Fillmore >> Franklin Pierce ===> [(' Franklin', 0.3328), (' Herbert', 0.1987), (' Theod', 0.0861), (' Ad', 0.0687), (' Harry', 0.0514)] :: True\n",
      "Franklin Pierce >> James Buchanan ===> [(' G', 0.2373), (' Richard', 0.1848), (' Harry', 0.1231), (' George', 0.1095), (' Dw', 0.0724)] :: False\n",
      "James Buchanan >> Abraham Lincoln ===> [(' Dw', 0.1573), (' Harry', 0.109), (' Herbert', 0.1016), (' Bill', 0.0955), (' William', 0.0715)] :: False\n",
      "Abraham Lincoln >> Andrew Johnson ===> [(' Andrew', 0.1239), (' Theod', 0.1173), (' Dw', 0.0914), (' John', 0.0782), (' William', 0.0643)] :: True\n",
      "Andrew Johnson >> Ulysses S. Grant ===> [(' Bill', 0.4299), (' George', 0.1558), (' Ly', 0.1122), (' Jimmy', 0.0713), (' Richard', 0.0526)] :: False\n",
      "Ulysses S. Grant >> Rutherford B. Hayes ===> [(' Dw', 0.2079), (' William', 0.1428), (' Herbert', 0.1311), (' Theod', 0.0937), (' Harry', 0.0724)] :: False\n",
      "Rutherford B. Hayes >> James Garfield ===> [(' Herbert', 0.3464), (' William', 0.1151), (' George', 0.0889), (' Dw', 0.0791), (' Theod', 0.0385)] :: False\n",
      "James Garfield >> Chester A. Arthur ===> [(' Chester', 0.2783), (' William', 0.1561), (' Herbert', 0.1188), (' Harry', 0.0574), (' Abraham', 0.0371)] :: True\n",
      "Chester A. Arthur >> Grover Cleveland ===> [(' George', 0.28), (' Herbert', 0.1176), (' Dw', 0.1131), (' Jimmy', 0.0625), (' Harry', 0.0538)] :: False\n",
      "Grover Cleveland >> Benjamin Harrison ===> [(' William', 0.3098), (' Benjamin', 0.1938), (' Thomas', 0.079), (' Herbert', 0.0736), (' Franklin', 0.0348)] :: False\n",
      "Benjamin Harrison >> Grover Cleveland ===> [(' William', 0.194), (' John', 0.1205), (' George', 0.0708), (' Theod', 0.0697), (' Cal', 0.0606)] :: False\n",
      "Grover Cleveland >> William McKinley ===> [(' William', 0.3098), (' Benjamin', 0.1938), (' Thomas', 0.079), (' Herbert', 0.0736), (' Franklin', 0.0348)] :: True\n",
      "William McKinley >> Theodore Roosevelt ===> [(' Theod', 0.3462), (' Warren', 0.1624), (' Harry', 0.0883), (' Herbert', 0.0693), (' G', 0.0385)] :: True\n",
      "Theodore Roosevelt >> William Howard Taft ===> [(' Franklin', 0.6206), (' William', 0.1364), (' Harry', 0.0747), (' Herbert', 0.0724), (' Wood', 0.018)] :: False\n",
      "William Howard Taft >> Woodrow Wilson ===> [(' Herbert', 0.3203), (' Wood', 0.1489), (' Harry', 0.1064), (' Theod', 0.0785), (' Franklin', 0.0588)] :: False\n",
      "Woodrow Wilson >> Warren G. Harding ===> [(' Franklin', 0.1511), (' Herbert', 0.1511), (' Harry', 0.1022), (' John', 0.0754), (' Richard', 0.0719)] :: False\n",
      "Warren G. Harding >> Calvin Coolidge ===> [(' George', 0.3201), (' Richard', 0.1853), (' Herbert', 0.1399), (' Walter', 0.0338), (' Harry', 0.0322)] :: False\n",
      "Calvin Coolidge >> Herbert Hoover ===> [(' Herbert', 0.7891), (' Dw', 0.0318), (' Harry', 0.0316), (' Richard', 0.0222), (' Franklin', 0.0219)] :: True\n",
      "Herbert Hoover >> Franklin D. Roosevelt ===> [(' Franklin', 0.3201), (' Dw', 0.2676), (' Harry', 0.063), (' Herbert', 0.0583), (' William', 0.0535)] :: True\n",
      "Franklin D. Roosevelt >> Harry S. Truman ===> [(' Harry', 0.8599), (' Dw', 0.0431), (' Theod', 0.0132), (' John', 0.0115), (' William', 0.0081)] :: True\n",
      "Harry S. Truman >> Dwight D. Eisenhower ===> [(' George', 0.2974), (' Dw', 0.2927), (' Walter', 0.0788), (' Bill', 0.0788), (' Richard', 0.0339)] :: False\n",
      "Dwight D. Eisenhower >> John F. Kennedy ===> [(' George', 0.5156), (' Richard', 0.2184), (' John', 0.1356), (' Harry', 0.0178), (' Jimmy', 0.0161)] :: False\n",
      "John F. Kennedy >> Lyndon B. Johnson ===> [(' Ly', 0.8521), (' Richard', 0.0562), (' Bill', 0.014), (' Jimmy', 0.0129), (' George', 0.0101)] :: True\n",
      "Lyndon B. Johnson >> Richard M. Nixon ===> [(' Richard', 0.6294), (' Bill', 0.059), (' Jimmy', 0.0481), (' G', 0.0347), (' George', 0.0297)] :: True\n",
      "Richard M. Nixon >> Gerald R. Ford ===> [(' G', 0.7061), (' George', 0.1049), (' Ronald', 0.0341), (' Jimmy', 0.0225), (' Harry', 0.0158)] :: True\n",
      "Gerald R. Ford >> James Carter ===> [(' George', 0.519), (' Jimmy', 0.194), (' Ronald', 0.0471), (' Richard', 0.0319), (' John', 0.0188)] :: False\n",
      "James Carter >> Ronald Reagan ===> [(' George', 0.5376), (' Jimmy', 0.1614), (' Ronald', 0.0662), (' Bill', 0.058), (' Walter', 0.0428)] :: False\n",
      "Ronald Reagan >> George H. W. Bush ===> [(' George', 0.9517), (' Bill', 0.009), (' Richard', 0.0049), (' Jimmy', 0.004), (' Walter', 0.004)] :: True\n",
      "George H. W. Bush >> William J. Clinton ===> [(' Bill', 0.5039), (' George', 0.3862), (' Donald', 0.0116), (' Richard', 0.0108), (' Jimmy', 0.0094)] :: False\n",
      "William J. Clinton >> George W. Bush ===> [(' Bill', 0.4741), (' George', 0.4385), (' Al', 0.028), (' Bar', 0.0056), (' Donald', 0.0047)] :: False\n",
      "George W. Bush >> Barack Obama ===> [(' Bill', 0.5581), (' George', 0.2617), (' Donald', 0.0462), (' Bar', 0.0327), (' Dick', 0.0097)] :: False\n",
      "Barack Obama >> Donald Trump ===> [(' Donald', 0.6533), (' Joe', 0.1481), (' Bill', 0.0536), (' George', 0.0292), (' John', 0.0153)] :: True\n",
      "Donald Trump >> Joe Biden ===> [(' Joe', 0.5098), (' Mike', 0.1309), (' Donald', 0.0729), (' Bill', 0.0628), (' George', 0.0242)] :: True\n"
     ]
    }
   ],
   "source": [
    "filter_by_model_knowledge = []\n",
    "for prev, nxt in zip(presidents[:-1], presidents[1:]):\n",
    "    txt, ret_dict = model_utils.generate_fast(\n",
    "        model, tokenizer, \n",
    "        prompts=[icl_prompt.format(prev)], max_new_tokens=10, \n",
    "        get_answer_tokens=True, argmax_greedy=True\n",
    "    )\n",
    "\n",
    "    tick = nxt.startswith(ret_dict['answer'][0]['top_token'].strip())\n",
    "    print(f\"{prev} >> {nxt} ===> {[(ans['token'], ans['p']) for ans in ret_dict['answer'][0]['candidates']]} :: {tick}\")\n",
    "    if(tick):\n",
    "        filter_by_model_knowledge.append((prev, nxt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter_by_model_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [\" \" + o[1] for o in filter_by_model_knowledge]\n",
    "\n",
    "from relations.corner import CornerEstimator\n",
    "corner_estimator = CornerEstimator(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    ln_f_name= \"model.decoder.final_layer_norm\", \n",
    "    unembedder_module_name=\"lm_head\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.171875 [(' bird', 39.188), (' plant', 37.25), (' fish', 35.812), (' food', 33.125), (' game', 32.438)]\n"
     ]
    }
   ],
   "source": [
    "simple_corner = corner_estimator.estimate_simple_corner(objects, scale_up=70)\n",
    "print(simple_corner.norm().item(), corner_estimator.get_vocab_representation(simple_corner, get_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating inverse of unbedding weights . . .\n",
      "18.265625 [(' plant', 23.969), (' bird', 22.859), (' game', 21.344), (' person', 20.828), (' drug', 20.594)]\n"
     ]
    }
   ],
   "source": [
    "lin_inv_corner = corner_estimator.estimate_lin_inv_corner(objects, target_logit_value=50)\n",
    "print(lin_inv_corner.norm().item(), corner_estimator.get_vocab_representation(lin_inv_corner, get_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.875 [(' galaxy', 24.406), (' material', 24.266), (' group', 24.266), (' star', 24.266), (' human', 24.266)]\n"
     ]
    }
   ],
   "source": [
    "lst_sq_corner = corner_estimator.estimate_corner_lstsq_solve(objects, target_logit=50)\n",
    "print(lst_sq_corner.norm().item(), corner_estimator.get_vocab_representation(lst_sq_corner, get_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_corner = corner_estimator.estimate_average_corner_with_gradient_descent(objects, average_on=5, target_logit_value=50, verbose=False)\n",
    "# print(avg_corner.norm().item(), corner_estimator.get_vocab_representation(avg_corner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_with_test_cases(relation_operator):\n",
    "    test_cases = [\n",
    "        (b, -1, h) for b, h in filter_by_model_knowledge[20:]\n",
    "    ]\n",
    "    for subject, subject_token_index, target in test_cases:\n",
    "        answer = relation_operator(\n",
    "            subject,\n",
    "            subject_token_index=subject_token_index,\n",
    "            device=model.device,\n",
    "            return_top_k=5,\n",
    "        )\n",
    "        print(f\"{subject}, target: {target}   ==>   predicted: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer, target: season   ==>   predicted: [' season', ' group', ' color', ' wind', ' plant']\n",
      "meat, target: food   ==>   predicted: [' science', ' group', ' color', ' plant', ' food']\n",
      "doll, target: toy   ==>   predicted: [' tree', ' shape', ' fish', ' star', ' group']\n",
      "gold, target: metal   ==>   predicted: [' metal', ' tree', ' wind', ' star', ' color']\n",
      "round, target: shape   ==>   predicted: [' shape', ' plant', ' wind', ' food', ' color']\n",
      "breeze, target: wind   ==>   predicted: [' color', ' tree', ' metal', ' plant', ' season']\n",
      "man, target: human   ==>   predicted: [' group', ' person', ' plant', ' color', ' food']\n",
      "hologram, target: picture   ==>   predicted: [' metal', ' color', ' device', ' tree', ' plant']\n",
      "paper, target: material   ==>   predicted: [' science', ' plant', ' wind', ' material', ' group']\n",
      "photographer, target: person   ==>   predicted: [' group', ' fish', ' tree', ' game', ' drug']\n",
      "documentary, target: film   ==>   predicted: [' film', ' material', ' science', ' group', ' star']\n",
      "anesthetic, target: drug   ==>   predicted: [' group', ' plant', ' drug', ' color', ' material']\n",
      "salad, target: dish   ==>   predicted: [' tree', ' group', ' plant', ' food', ' color']\n",
      "thumb, target: finger   ==>   predicted: [' group', ' food', ' tree', ' shape', ' plant']\n"
     ]
    }
   ],
   "source": [
    "relation = estimate.RelationOperator(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    relation = prompt,\n",
    "    layer = 15,\n",
    "    weight = torch.eye(getattr(model.config, n_embd_field)).to(model.dtype).to(model.device),\n",
    "    bias = lst_sq_corner,\n",
    "\n",
    "    layer_name_format = \"model.decoder.layers.{}\",\n",
    "    ln_f_name = \"model.decoder.final_layer_norm\"\n",
    ")\n",
    "check_with_test_cases(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_JB(top_performers, relation_prompt, num_icl = 3, calculate_at_lnf = False):\n",
    "    try:\n",
    "        jbs = []\n",
    "        for s, s_idx, o in tqdm(top_performers):\n",
    "            others = set(top_performers) - {(s, s_idx, o)}\n",
    "            others = random.sample(list(others), k = min(num_icl, len(list(others)))) \n",
    "            prompt = \"\"\n",
    "            prompt += \"\\n\".join(relation_prompt.format(s_other) + f\" {o_other}.\" for s_other, idx_other, o_other in others) + \"\\n\"\n",
    "            prompt += relation_prompt\n",
    "            print(\"subject: \", s)\n",
    "            print(prompt)\n",
    "\n",
    "            jb, _ = estimate.relation_operator_from_sample(\n",
    "                model, tokenizer,\n",
    "                s, prompt,\n",
    "                subject_token_index= s_idx,\n",
    "                layer = 15,\n",
    "                device = model.device,\n",
    "                # calculate_at_lnf = calculate_at_lnf\n",
    "\n",
    "                layer_name_format = \"model.decoder.layers.{}\",\n",
    "                ln_f_name = \"model.decoder.final_layer_norm\",\n",
    "                n_layer_field = \"num_hidden_layers\"\n",
    "            )\n",
    "            print(jb.weight.norm(), jb.bias.norm())\n",
    "            print()\n",
    "            jbs.append(jb)\n",
    "        \n",
    "        weight = torch.stack([jb.weight for jb in jbs]).mean(dim=0)\n",
    "        bias  = torch.stack([jb.bias for jb in jbs]).mean(dim=0)\n",
    "\n",
    "        return weight, bias\n",
    "    except RuntimeError as e:\n",
    "        if(str(e).startswith(\"CUDA out of memory\")):\n",
    "            print(\"CUDA out of memory\")\n",
    "        if(num_icl > 1):\n",
    "            num_icl -= 1\n",
    "            print(\"trying with smaller icl >> \", num_icl)\n",
    "            return get_averaged_JB(top_performers, relation_prompt, num_icl, calculate_at_lnf)\n",
    "        else:\n",
    "            raise Exception(\"RuntimeError >> can't calculate Jacobian with minimum number of icl examples\")\n",
    "\n",
    "def get_multiple_averaged_JB(top_performers, relation_prompt, N = 3, num_icl = 2, calculate_at_lnf = False):\n",
    "    weights_and_biases = []\n",
    "    sample_size = min(len(top_performers), num_icl + 2)\n",
    "    for _ in tqdm(range(N)):\n",
    "        cur_sample = random.sample(top_performers, k = sample_size)\n",
    "        weight, bias = get_averaged_JB(cur_sample, relation_prompt, num_icl, calculate_at_lnf)\n",
    "        weights_and_biases.append({\n",
    "            'weight': weight,\n",
    "            'bias'  : bias\n",
    "        })\n",
    "    return weights_and_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oak', -1, 'tree'), ('diamond', -1, 'gem'), ('happiness', -1, 'feeling'), ('family', -1, 'group'), ('thesaurus', -1, 'dictionary'), ('crow', -1, 'bird'), ('tennis', -1, 'sport'), ('salmon', -1, 'fish'), ('flower', -1, 'plant'), ('rosemary', -1, 'herb'), ('cucumber', -1, 'vegetable'), ('roulette', -1, 'game'), ('physics', -1, 'science'), ('earth', -1, 'planet'), ('sun', -1, 'star'), ('coffee', -1, 'beverage'), ('car', -1, 'vehicle'), ('yellow', -1, 'color'), ('fan', -1, 'device'), ('judaism', -1, 'religion')]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0589753fcff74a319bddbdd904813c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7d793af820478d9c790a86a8efc35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  cucumber\n",
      " family is a group.\n",
      " roulette is a game.\n",
      " {} is a\n",
      "tensor(43.0938, device='cuda:0', dtype=torch.float16) tensor(248.8750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  roulette\n",
      " coffee is a beverage.\n",
      " cucumber is a vegetable.\n",
      " {} is a\n",
      "tensor(57.5938, device='cuda:0', dtype=torch.float16) tensor(274.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  family\n",
      " roulette is a game.\n",
      " coffee is a beverage.\n",
      " {} is a\n",
      "tensor(46.7500, device='cuda:0', dtype=torch.float16) tensor(253.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  coffee\n",
      " roulette is a game.\n",
      " cucumber is a vegetable.\n",
      " {} is a\n",
      "tensor(40.3438, device='cuda:0', dtype=torch.float16) tensor(264., device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e79e747018ab493eb81bd7843e20d963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  happiness\n",
      " roulette is a game.\n",
      " yellow is a color.\n",
      " {} is a\n",
      "tensor(38., device='cuda:0', dtype=torch.float16) tensor(259.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  roulette\n",
      " happiness is a feeling.\n",
      " yellow is a color.\n",
      " {} is a\n",
      "tensor(53.2812, device='cuda:0', dtype=torch.float16) tensor(281.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  yellow\n",
      " fan is a device.\n",
      " roulette is a game.\n",
      " {} is a\n",
      "tensor(43.8750, device='cuda:0', dtype=torch.float16) tensor(227.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  fan\n",
      " roulette is a game.\n",
      " happiness is a feeling.\n",
      " {} is a\n",
      "tensor(52.8750, device='cuda:0', dtype=torch.float16) tensor(256.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ec468fe8aa458db75f7dad43c60405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  happiness\n",
      " cucumber is a vegetable.\n",
      " diamond is a gem.\n",
      " {} is a\n",
      "tensor(40.4375, device='cuda:0', dtype=torch.float16) tensor(250.3750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  diamond\n",
      " earth is a planet.\n",
      " happiness is a feeling.\n",
      " {} is a\n",
      "tensor(45.1875, device='cuda:0', dtype=torch.float16) tensor(254.3750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  cucumber\n",
      " earth is a planet.\n",
      " happiness is a feeling.\n",
      " {} is a\n",
      "tensor(40.7812, device='cuda:0', dtype=torch.float16) tensor(249.6250, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  earth\n",
      " cucumber is a vegetable.\n",
      " diamond is a gem.\n",
      " {} is a\n",
      "tensor(49.3125, device='cuda:0', dtype=torch.float16) tensor(235.6250, device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "        (b, -1, h) for b, h in filter_by_model_knowledge[:20]\n",
    "    ]\n",
    "print(samples)\n",
    "\n",
    "weights_and_biases = get_multiple_averaged_JB(\n",
    "    samples, \n",
    "    relation_prompt=\" {} is a\", \n",
    "    N = 3, \n",
    "    calculate_at_lnf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summer, target: season   ==>   predicted: [' season', ' color', ' wind', ' herb', ' plant']\n",
      "meat, target: food   ==>   predicted: [' food', ' dish', ' vegetable', ' material', ' meat']\n",
      "doll, target: toy   ==>   predicted: [' toy', ' shape', ' picture', ' bird', ' person']\n",
      "gold, target: metal   ==>   predicted: [' metal', ' material', ' gem', ' color', ' religion']\n",
      "round, target: shape   ==>   predicted: [' shape', ' sport', ' season', ' wind', ' galaxy']\n",
      "breeze, target: wind   ==>   predicted: [' wind', ' season', ' feeling', ' herb', ' color']\n",
      "man, target: human   ==>   predicted: [' human', ' person', ' vehicle', ' fish', ' sport']\n",
      "hologram, target: picture   ==>   predicted: [' device', ' picture', ' material', ' science', ' film']\n",
      "paper, target: material   ==>   predicted: [' material', ' wind', ' dish', ' dictionary', ' vehicle']\n",
      "photographer, target: person   ==>   predicted: [' person', ' science', ' star', ' human', ' sport']\n",
      "documentary, target: film   ==>   predicted: [' film', ' picture', ' wind', ' dish', ' science']\n",
      "anesthetic, target: drug   ==>   predicted: [' drug', ' herb', ' feeling', ' beverage', ' material']\n",
      "salad, target: dish   ==>   predicted: [' dish', ' food', ' vegetable', ' season', ' beverage']\n",
      "thumb, target: finger   ==>   predicted: [' finger', ' shape', ' fish', ' device', ' star']\n"
     ]
    }
   ],
   "source": [
    "relation_operator = estimate.RelationOperator(\n",
    "    model = model,\n",
    "    tokenizer= tokenizer,\n",
    "    relation = prompt,\n",
    "    layer = 15,\n",
    "    weight = torch.stack(\n",
    "        [wb['weight'] for wb in weights_and_biases]\n",
    "    ).mean(dim=0),\n",
    "    # bias = torch.stack(\n",
    "    #     [wb['bias'] for wb in weights_and_biases]\n",
    "    # ).mean(dim=0),\n",
    "    bias = lst_sq_corner,\n",
    "\n",
    "    layer_name_format = \"model.decoder.layers.{}\",\n",
    "    ln_f_name = \"model.decoder.final_layer_norm\",\n",
    ")\n",
    "\n",
    "check_with_test_cases(relation_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' type', ' kind', ' good', ' ', ' very']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner_estimator.get_vocab_representation(\n",
    "    torch.stack(\n",
    "        [wb['bias'] for wb in weights_and_biases]\n",
    "    ).mean(dim=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4104f34302edfbfea7294aa0a5e7d82342a152e8e30f6673f70b28d5f99d4ac0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
