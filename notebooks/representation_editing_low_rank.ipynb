{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"..\")\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import models, data, operators, editors, functional, metrics, lens\n",
    "from src.utils import logging_utils, experiment_utils\n",
    "import logging\n",
    "import torch\n",
    "import baukit\n",
    "\n",
    "logging_utils.configure(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21 16:45:53 src.models INFO     loading EleutherAI/gpt-j-6B (device=cuda, fp16=True)\n",
      "2023-07-21 16:46:02 src.models INFO     dtype: torch.float16, device: cuda:0, memory: 12219206136\n"
     ]
    }
   ],
   "source": [
    "mt = models.load_model(\"gptj\", fp16=True, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-21 17:12:18 src.utils.experiment_utils INFO     setting all seeds to 123456\n",
      "2023-07-21 17:12:18 src.operators WARNING  relation has > 1 prompt_templates, will use first (The capital city of {} is)\n",
      "2023-07-21 17:12:44 src.operators WARNING  relation has > 1 prompt_templates, will use first (The official currency of {} is the)\n",
      "2023-07-21 17:13:12 src.operators WARNING  relation has > 1 prompt_templates, will use first (People in {} speak)\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "layer = 5\n",
    "rank = 50\n",
    "beta = 2.25\n",
    "n_train = 5\n",
    "selected_relations = [r for r in dataset if r.name in [\n",
    "        \"country capital city\",\n",
    "        \"country currency\",\n",
    "        \"country language\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "experiment_utils.set_seed(123456)\n",
    "##################################\n",
    "\n",
    "\n",
    "relation_properties = {}\n",
    "\n",
    "for relation in selected_relations:\n",
    "    train, test = relation.split(n_train)\n",
    "    prompt_template = relation.prompt_templates[0]\n",
    "\n",
    "    relation_prompt = functional.make_prompt(\n",
    "        mt=mt,\n",
    "        prompt_template=prompt_template,\n",
    "        subject=\"{}\",\n",
    "        examples=train.samples,\n",
    "    )\n",
    "\n",
    "    estimator = operators.JacobianIclMeanEstimator(\n",
    "        mt = mt, h_layer=layer, beta=beta, rank=rank\n",
    "    )\n",
    "    operator = estimator(train)\n",
    "\n",
    "    relation_properties[relation.name] = {\n",
    "        \"train\": train,\n",
    "        \"prompt_template\": prompt_template,\n",
    "        \"prompt\": relation_prompt,\n",
    "        \"operator\": operator,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "country capital city\n",
      "-----------------------------------\n",
      "['Pakistan -> Islamabad', 'Argentina -> Buenos Aires', 'Peru -> Lima', 'Australia -> Canberra', 'Germany -> Berlin']\n",
      "<|endoftext|>The capital city of Pakistan is Islamabad\n",
      "The capital city of Argentina is Buenos Aires\n",
      "The capital city of Peru is Lima\n",
      "The capital city of Australia is Canberra\n",
      "The capital city of Germany is Berlin\n",
      "The capital city of {} is\n",
      "-----------------------------------\n",
      "country currency\n",
      "-----------------------------------\n",
      "['Norway -> Krone', 'Russia -> Ruble', 'Argentina -> Peso', 'New Zealand -> Dollar', 'Czech Republic -> Koruna']\n",
      "<|endoftext|>The official currency of Norway is the Krone\n",
      "The official currency of Russia is the Ruble\n",
      "The official currency of Argentina is the Peso\n",
      "The official currency of New Zealand is the Dollar\n",
      "The official currency of Czech Republic is the Koruna\n",
      "The official currency of {} is the\n",
      "-----------------------------------\n",
      "country language\n",
      "-----------------------------------\n",
      "['Chile -> Spanish', 'India -> Hindi', 'South Korea -> Korean', 'Germany -> German', 'United States -> English']\n",
      "<|endoftext|>People in Chile speak Spanish\n",
      "People in India speak Hindi\n",
      "People in South Korea speak Korean\n",
      "People in Germany speak German\n",
      "People in United States speak English\n",
      "People in {} speak\n"
     ]
    }
   ],
   "source": [
    "for relation_name in relation_properties:\n",
    "    print(\"-----------------------------------\")\n",
    "    print(relation_name)\n",
    "    print(\"-----------------------------------\")\n",
    "    print(f\"{[sample.__str__() for sample in relation_properties[relation_name]['train'].samples]}\")\n",
    "    print(relation_properties[relation_name]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chile -- country capital city --  Santiago (p=0.996)\n",
      "Chile -- country currency --  Pes (p=0.757)\n",
      "Chile -- country language --  Spanish (p=0.937)\n",
      "=================================\n",
      "Russia -- country capital city --  Moscow (p=0.988)\n",
      "Tokyo -- country currency --  Yen (p=0.969)\n",
      "Brazil -- country language --  Portuguese (p=0.877)\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "source_subject = \"Chile\"\n",
    "targ_prop_for_subj = {\n",
    "    \"country capital city\": \"Russia\",\n",
    "    \"country currency\": \"Tokyo\",\n",
    "    \"country language\": \"Brazil\"      \n",
    "}\n",
    "##################################################\n",
    "\n",
    "for prop in targ_prop_for_subj:\n",
    "    prompt = relation_properties[prop]['prompt'].format(source_subject)\n",
    "    obj = functional.predict_next_token(mt = mt, prompt = prompt, k=3)[0]\n",
    "    print(f\"{source_subject} -- {prop} -- {obj[0].__str__()}\")\n",
    "print(\"=================================\")\n",
    "\n",
    "for prop, subj in targ_prop_for_subj.items():\n",
    "    prompt = relation_properties[prop]['prompt'].format(subj)\n",
    "    obj = functional.predict_next_token(mt = mt, prompt = prompt, k=3)[0]\n",
    "    print(f\"{subj} -- {prop} -- {obj[0].__str__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation_name in relation_properties:\n",
    "    relation_properties[relation_name][\"W_inv\"] = functional.low_rank_pinv(\n",
    "        matrix = relation_properties[relation_name][\"operator\"].weight,\n",
    "        rank=rank,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_s(\n",
    "    prop, \n",
    "    source_subject, \n",
    "    target_subject,\n",
    "    fix_latent_norm = None,\n",
    "):\n",
    "    w_p_inv = relation_properties[prop][\"W_inv\"]\n",
    "    hs_and_zs = functional.compute_hs_and_zs(\n",
    "        mt = mt,\n",
    "        prompt_template = relation_properties[prop][\"prompt_template\"],\n",
    "        subjects = [source_subject, target_subject],\n",
    "        h_layer= layer,\n",
    "        z_layer=-1,\n",
    "        examples= relation_properties[prop][\"train\"].samples,\n",
    "    )\n",
    "\n",
    "    z_source = hs_and_zs.z_by_subj[source_subject]\n",
    "    z_target = hs_and_zs.z_by_subj[targ_prop_for_subj[prop]]\n",
    "    # print(z_target.norm().item(), z_source.norm().item())\n",
    "\n",
    "    z_source *= fix_latent_norm / z_source.norm() if fix_latent_norm is not None else 1.0\n",
    "    z_target *= z_source.norm() / z_target.norm() if fix_latent_norm is not None else 1.0\n",
    "    # print(z_target.norm().item(), z_source.norm().item())\n",
    "\n",
    "    delta_s = w_p_inv @  (z_target.squeeze() - z_source.squeeze())\n",
    "    # print(delta_s.norm().item())\n",
    "\n",
    "    return delta_s, hs_and_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_s_by_prop = {}\n",
    "for relation_name in targ_prop_for_subj:\n",
    "    delta_s, hs_and_zs = get_delta_s(\n",
    "        prop = relation_name,\n",
    "        source_subject = source_subject,\n",
    "        target_subject = targ_prop_for_subj[relation_name],\n",
    "        fix_latent_norm=250\n",
    "    )\n",
    "\n",
    "    delta_s_by_prop[relation_name] = {\n",
    "        \"delta_s\": delta_s,\n",
    "        \"hs_and_zs\": hs_and_zs,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -- 0 -- 1912.0, 1.0009765625\n",
      "0 -- 1 -- 1266.0, 0.568359375\n",
      "0 -- 2 -- 315.25, 0.236083984375\n",
      "1 -- 0 -- 1266.0, 0.568359375\n",
      "1 -- 1 -- 2594.0, 1.0\n",
      "1 -- 2 -- 395.75, 0.25439453125\n",
      "2 -- 0 -- 315.25, 0.236083984375\n",
      "2 -- 1 -- 395.75, 0.25439453125\n",
      "2 -- 2 -- 932.5, 1.0009765625\n"
     ]
    }
   ],
   "source": [
    "drr = [prop[\"delta_s\"] for relation, prop in delta_s_by_prop.items()]\n",
    "for i in range(len(drr)):\n",
    "    for j in range(len(drr)):\n",
    "        print(f\"{i} -- {j} -- {drr[i].T @ drr[j]}, {torch.cosine_similarity(drr[i], drr[j], dim=0).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(43.7188, device='cuda:0', dtype=torch.float16)\n",
      "tensor(50.9375, device='cuda:0', dtype=torch.float16)\n",
      "tensor(30.5312, device='cuda:0', dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([4096]), 96.9375)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cumulative_delta_s = torch.zeros_like(delta_s_by_prop[prop][\"delta_s\"])\n",
    "for relation_name in delta_s_by_prop:\n",
    "    cumulative_delta_s += delta_s_by_prop[relation_name][\"delta_s\"]\n",
    "    print(delta_s_by_prop[relation_name][\"delta_s\"].norm())\n",
    "cumulative_delta_s.shape, cumulative_delta_s.norm().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Yen', 0.877),\n",
       " (' Japanese', 0.061),\n",
       " (' Y', 0.044),\n",
       " (' Dollar', 0.003),\n",
       " (' yen', 0.003),\n",
       " (' Â¥', 0.001),\n",
       " (' Ren', 0.001),\n",
       " (' Yu', 0.001),\n",
       " (' Yuan', 0.001),\n",
       " (' Japan', 0.001)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = \"country currency\"\n",
    "\n",
    "delta_s, hs_and_zs = get_delta_s(\n",
    "    prop = prop,\n",
    "    source_subject = source_subject,\n",
    "    target_subject = targ_prop_for_subj[prop],\n",
    "    fix_latent_norm = 250\n",
    ")\n",
    "\n",
    "def get_intervention(h, int_layer, subj_idx):\n",
    "    def edit_output(output, layer):\n",
    "        if(layer != int_layer):\n",
    "            return output\n",
    "        functional.untuple(output)[:, subj_idx] = h\n",
    "        return output\n",
    "    return edit_output\n",
    "\n",
    "prompt = relation_properties[prop][\"prompt\"].format(source_subject)\n",
    "\n",
    "h_index, inputs = functional.find_subject_token_index(\n",
    "    mt=mt,\n",
    "    prompt=prompt,\n",
    "    subject=source_subject,\n",
    ")\n",
    "\n",
    "h_layer, z_layer = models.determine_layer_paths(model = mt, layers = [layer, -1])\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model, layers = [h_layer, z_layer],\n",
    "    edit_output=get_intervention(\n",
    "        # h = hs_and_zs.h_by_subj[source_subject]\n",
    "        h = hs_and_zs.h_by_subj[source_subject] + delta_s,\n",
    "        # h = hs_and_zs.h_by_subj[source_subject] + cumulative_delta_s, \n",
    "        int_layer = h_layer, \n",
    "        subj_idx = h_index\n",
    "    )\n",
    ") as traces:\n",
    "    outputs = mt.model(\n",
    "        input_ids = inputs.input_ids,\n",
    "        attention_mask = inputs.attention_mask,\n",
    "    )\n",
    "\n",
    "lens.interpret_logits(\n",
    "    mt = mt, \n",
    "    logits = outputs.logits[0][-1], \n",
    "    get_proba=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
