{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../../context-mediation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd95185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "device = \"cuda\"\n",
    "config = \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(config, revision=\"float16\", low_cpu_mem_usage=True)\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(config)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2643226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data\n",
    "\n",
    "counterfact = data.load_dataset(\"counterfact\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9ff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfact[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c92b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "samples_by_relation = defaultdict(list)\n",
    "for sample in counterfact:\n",
    "    relation_id = sample[\"source\"][\"requested_rewrite\"][\"relation_id\"]\n",
    "    samples_by_relation[relation_id].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ded5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples_by_relation), {r: len(s) for r, s in samples_by_relation.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import tokenizer_utils\n",
    "\n",
    "import baukit\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "h_layer = 15\n",
    "z_layer = model.config.n_layer - 1\n",
    "\n",
    "h_layername = f\"transformer.h.{h_layer}\"\n",
    "z_layername = f\"transformer.h.{z_layer}\"\n",
    "\n",
    "preds_by_relation = defaultdict(list)\n",
    "h_by_relation = defaultdict(list)\n",
    "z_by_relation = defaultdict(list)\n",
    "with counterfact.formatted_as(\"torch\"):\n",
    "    loader = DataLoader(counterfact, batch_size=32, shuffle=False)\n",
    "    for batch in tqdm(loader):\n",
    "        inputs = tokenizer(\n",
    "            batch[\"prompt\"],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"longest\",\n",
    "            return_offsets_mapping=True\n",
    "        ).to(device)\n",
    "        offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "        with torch.inference_mode():\n",
    "            with baukit.TraceDict(model, (h_layername, z_layername)) as ret:\n",
    "                outputs = model(**inputs)\n",
    "\n",
    "        batch_idx = torch.arange(len(batch[\"prompt\"]))\n",
    "        prompt_idx = inputs.attention_mask.sum(dim=-1) - 1\n",
    "        ids = outputs.logits[batch_idx, prompt_idx].topk(dim=-1, k=5).indices\n",
    "        tokens = tokenizer_utils.batch_convert_ids_to_tokens(ids.tolist(), tokenizer)\n",
    "\n",
    "        for i, (rid, entity, prompt, preds, h, z) in enumerate(zip(\n",
    "            batch[\"source\"][\"requested_rewrite\"][\"relation_id\"],\n",
    "            batch[\"entity\"],\n",
    "            batch[\"prompt\"],\n",
    "            tokens,\n",
    "            ret[h_layername].output[0],\n",
    "            ret[z_layername].output[0],\n",
    "        )):\n",
    "            _, entity_j = tokenizer_utils.find_token_range(\n",
    "                prompt,\n",
    "                entity, \n",
    "                offset_mapping=offset_mapping[i])\n",
    "            preds_by_relation[rid].append(preds)\n",
    "            h_by_relation[rid].append(h[entity_j - 1].cpu())\n",
    "            z_by_relation[rid].append(z[prompt_idx[i].item()].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3dab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_by_relation[\"P264\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c86101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relations import estimate\n",
    "\n",
    "layer = 15\n",
    "\n",
    "accs_by_relation = {}\n",
    "for rid, samples in samples_by_relation.items():\n",
    "    print(f\"---- {rid} ----\")\n",
    "    samples = [\n",
    "        s\n",
    "        for i, s in enumerate(samples)\n",
    "        if any(\n",
    "            pred.strip(\"ĠĊ \").lower()\n",
    "            in\n",
    "            s[\"source\"][\"requested_rewrite\"][\"target_true\"][\"str\"].lower()\n",
    "            for pred in preds_by_relation[rid][i][:3]\n",
    "            if pred.strip(\"ĠĊ \").lower()\n",
    "        )\n",
    "    ]\n",
    "    print(f\"{len(samples)} known samples\")\n",
    "\n",
    "    trains = samples[:5]\n",
    "    tests = samples[5:55]\n",
    "\n",
    "    operators = []\n",
    "    for train in tqdm(trains, desc=\"train\"):\n",
    "        operator = estimate.estimate_relation_operator(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            relation=train[\"source\"][\"requested_rewrite\"][\"prompt\"],\n",
    "            subject=train[\"source\"][\"requested_rewrite\"][\"subject\"],\n",
    "            layer=layer,\n",
    "            device=device,\n",
    "        )\n",
    "        operators.append(operator)\n",
    "    \n",
    "    operator_a = estimate.RelationOperator(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        relation=trains[0][\"source\"][\"requested_rewrite\"][\"prompt\"],\n",
    "        weight=torch.stack([o.weight for o in operators]).mean(dim=0),\n",
    "        bias=torch.stack([o.bias for o in operators]).mean(dim=0),\n",
    "        layer=layer,\n",
    "    )\n",
    "\n",
    "    correct_by_k = defaultdict(int)\n",
    "    for test in tqdm(tests, desc=\"test\"):\n",
    "        rr = test[\"source\"][\"requested_rewrite\"]\n",
    "        subject = rr[\"subject\"]\n",
    "        expected = rr[\"target_true\"][\"str\"]\n",
    "\n",
    "        preds = operator_a(subject, device=device, return_top_k=5)\n",
    "        for k in (1, 3, 5):\n",
    "            actuals = [p.strip(\"ĠĊ \").lower() for p in preds[:k]]\n",
    "            correct_by_k[k] += expected.lower() in actuals\n",
    "\n",
    "    accs_by_relation[rid] = {\n",
    "        k: correct / len(tests)\n",
    "        for k, correct in correct_by_k.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_by_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa950ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_by_relation = {}\n",
    "for rid, samples in samples_by_relation.items():\n",
    "    targets_by_relation[rid] = {\n",
    "        sample[\"source\"][\"requested_rewrite\"][\"target_true\"][\"str\"]\n",
    "        for sample in samples\n",
    "    }\n",
    "{rid: len(targets) for rid, targets in targets_by_relation.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df658ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_by_relation = {}\n",
    "for rid, samples in samples_by_relation.items():\n",
    "    prompts_by_relation[rid] = [\n",
    "        sample[\"source\"][\"requested_rewrite\"][\"prompt\"]\n",
    "        for sample in samples\n",
    "    ]\n",
    "{rid: prompts for rid, prompts in prompts_by_relation.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bed79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
