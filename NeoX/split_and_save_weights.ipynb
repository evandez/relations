{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from relations import estimate\n",
    "from util import model_utils\n",
    "import baukit\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################\n",
    "MODEL_NAME = \"EleutherAI/gpt-neox-20b\" # options gpt2-{} | \"EleutherAI/gpt-neox-20b\" | \"EleutherAI/gpt-j-6B\"\n",
    "\n",
    "layer_name_format = \"gpt_neox.layers.{}\"\n",
    "final_layer_norm = \"gpt_neox.final_layer_norm\"\n",
    "unembed = \"embed_out\"\n",
    "num_layer_field = \"num_hidden_layers\"\n",
    "break_layer_idx = 22\n",
    "\n",
    "# layer_name_format = \"transformer.h.{}\"\n",
    "# final_layer_norm = \"transformer.ln_f\"\n",
    "# unembed = \"lm_head\"\n",
    "# num_layer_field = \"n_layer\"\n",
    "# break_layer_idx = 23\n",
    "######################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Space Needle is located in the country of\n",
      "The Space Needle is located in the country of Washington, in the city of Seattle. The Space\n",
      "p(answer):  p(' Washington'[5041])=0.2216, p(' Seattle'[16335])=0.1621, p(' the'[253])=0.1522, p(' Malaysia'[23799])=0.0182, p(' Canada'[6144])=0.0171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = [\"The Space Needle is located in the country of\"]\n",
    "\n",
    "txt, ret_dict = model_utils.generate_fast(\n",
    "    model, tokenizer,\n",
    "    prompt,\n",
    "    argmax_greedy = True,\n",
    "    max_out_len= 20,\n",
    "    # debug=True,\n",
    "    get_answer_tokens=True,\n",
    ")\n",
    "model_utils.print_formatted_results(prompt, txt, ret_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy weights of layers from `break_layer_idx` to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "part_config = copy.deepcopy(model.config)\n",
    "\n",
    "setattr(part_config, num_layer_field, mt.num_layers - break_layer_idx)\n",
    "part_num_layers = getattr(part_config, num_layer_field)\n",
    "\n",
    "part_layer_names = [layer_name_format.format(idx) for idx in range(part_num_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_neox.layers.0 << gpt_neox.layers.22\n",
      "gpt_neox.layers.1 << gpt_neox.layers.23\n",
      "gpt_neox.layers.2 << gpt_neox.layers.24\n",
      "gpt_neox.layers.3 << gpt_neox.layers.25\n",
      "gpt_neox.layers.4 << gpt_neox.layers.26\n",
      "gpt_neox.layers.5 << gpt_neox.layers.27\n",
      "gpt_neox.layers.6 << gpt_neox.layers.28\n",
      "gpt_neox.layers.7 << gpt_neox.layers.29\n",
      "gpt_neox.layers.8 << gpt_neox.layers.30\n",
      "gpt_neox.layers.9 << gpt_neox.layers.31\n",
      "gpt_neox.layers.10 << gpt_neox.layers.32\n",
      "gpt_neox.layers.11 << gpt_neox.layers.33\n",
      "gpt_neox.layers.12 << gpt_neox.layers.34\n",
      "gpt_neox.layers.13 << gpt_neox.layers.35\n",
      "gpt_neox.layers.14 << gpt_neox.layers.36\n",
      "gpt_neox.layers.15 << gpt_neox.layers.37\n",
      "gpt_neox.layers.16 << gpt_neox.layers.38\n",
      "gpt_neox.layers.17 << gpt_neox.layers.39\n",
      "gpt_neox.layers.18 << gpt_neox.layers.40\n",
      "gpt_neox.layers.19 << gpt_neox.layers.41\n",
      "gpt_neox.layers.20 << gpt_neox.layers.42\n",
      "gpt_neox.layers.21 << gpt_neox.layers.43\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "\n",
    "def get_param_names(layer_name):\n",
    "    param_names = []\n",
    "    for key in state_dict:\n",
    "        if(key.startswith(layer_name)):\n",
    "            param_names.append(key)\n",
    "    return param_names\n",
    "\n",
    "for idx in range(break_layer_idx, mt.num_layers):\n",
    "    part_layer_name = layer_name_format.format(idx - break_layer_idx)\n",
    "    full_layer_name = layer_name_format.format(idx)\n",
    "    \n",
    "    print(part_layer_name, \"<<\", full_layer_name)\n",
    "\n",
    "    part_param_names = get_param_names(part_layer_name)\n",
    "    full_param_names = get_param_names(full_layer_name)\n",
    "    for part_param, full_param in zip(part_param_names, full_param_names):\n",
    "        # print(part_param, full_param)\n",
    "        state_dict[part_param][...] = state_dict[full_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting >>  gpt_neox.layers.22\n",
      "deleting >>  gpt_neox.layers.23\n",
      "deleting >>  gpt_neox.layers.24\n",
      "deleting >>  gpt_neox.layers.25\n",
      "deleting >>  gpt_neox.layers.26\n",
      "deleting >>  gpt_neox.layers.27\n",
      "deleting >>  gpt_neox.layers.28\n",
      "deleting >>  gpt_neox.layers.29\n",
      "deleting >>  gpt_neox.layers.30\n",
      "deleting >>  gpt_neox.layers.31\n",
      "deleting >>  gpt_neox.layers.32\n",
      "deleting >>  gpt_neox.layers.33\n",
      "deleting >>  gpt_neox.layers.34\n",
      "deleting >>  gpt_neox.layers.35\n",
      "deleting >>  gpt_neox.layers.36\n",
      "deleting >>  gpt_neox.layers.37\n",
      "deleting >>  gpt_neox.layers.38\n",
      "deleting >>  gpt_neox.layers.39\n",
      "deleting >>  gpt_neox.layers.40\n",
      "deleting >>  gpt_neox.layers.41\n",
      "deleting >>  gpt_neox.layers.42\n",
      "deleting >>  gpt_neox.layers.43\n"
     ]
    }
   ],
   "source": [
    "for idx in range(part_num_layers, mt.num_layers):\n",
    "    layer_name = layer_name_format.format(idx)\n",
    "    print(\"deleting >> \", layer_name)\n",
    "    param_names = get_param_names(layer_name)\n",
    "    for param in param_names:\n",
    "        state_dict.pop(param)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the weights of layer part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = f\"{MODEL_NAME}__last_{part_num_layers}_layers\"\n",
    "os.makedirs(path_name, exist_ok = True)\n",
    "\n",
    "part_config.save_pretrained(path_name)\n",
    "torch.save(state_dict, f\"{path_name}/pytorch_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4104f34302edfbfea7294aa0a5e7d82342a152e8e30f6673f70b28d5f99d4ac0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
