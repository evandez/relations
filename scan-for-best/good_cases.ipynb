{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from relations import estimate\n",
    "from util import model_utils\n",
    "from dsets.counterfact import CounterFactDataset\n",
    "from util import nethook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=False)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    (\"The Great Wall\", -1, \"China\"),\n",
    "    (\"Niagara Falls\", -2, \"Canada\"),\n",
    "    (\"Valdemarsvik\", -1, \"Sweden\"),\n",
    "    (\"Kyoto University\", -2, \"Japan\"),\n",
    "    (\"Hattfjelldal\", -1, \"Norway\"),\n",
    "    (\"Ginza\", -1, \"Japan\"),\n",
    "    (\"Sydney Hospital\", -2, \"Australia\"),\n",
    "    (\"Mahalangur Himal\", -1, \"Nepal\"),\n",
    "    (\"Higashikagawa\", -1, \"Japan\"),\n",
    "    (\"Trento\", -1, \"Italy\"),\n",
    "    (\"Taj Mahal\", -1, \"India\")\n",
    "]\n",
    "\n",
    "def check_with_test_cases(relation_operator):\n",
    "    for subject, subject_token_index, target in test_cases:\n",
    "        objects = relation_operator(\n",
    "            subject,\n",
    "            subject_token_index=subject_token_index,\n",
    "            device=model.device,\n",
    "            return_top_k=5,\n",
    "        )\n",
    "        print(f\"{subject}, target: {target}   ==>   predicted: {objects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "relation_dct = {\n",
    "    'P17': {'relation': '{} is located in the country of', 'correct_predict': \"P17/correct_prediction_P17__gpt2-xl.json\", 'cached_JB': \"P17/cached_jacobians/jacobian_calculations__all_sub_toks__P17__layer_25.npz\"},\n",
    "    'P641': {'relation': '{} plays the sport of', 'correct_predict': \"P641/correct_prediction_P641__gpt2-xl.json\", 'cached_JB': \"P641/jacobian_calculations__all_sub_toks__P641__layer_25.npz\"},\n",
    "    'P103': {'relation': 'The mother tongue of {} is', 'correct_predict': \"P103/correct_prediction_P103__gpt2-xl.json\", 'cached_JB': \"P103/jacobian_calculations__all_sub_toks__P103__layer_25.npz\"},\n",
    "    'P176': {'relation': '{} is produced by', 'correct_predict': \"P176/correct_prediction_P176__gpt2-xl.json\", 'cached_JB': \"P176/jacobian_calculations__all_sub_toks__P176__layer_25.npz\"},\n",
    "}\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cases = {\n",
    "    'P17':[\n",
    "        ('Etobicoke North', 2, 'Canada'),\n",
    "        ('Menangle Park', 1, 'Australia'),\n",
    "        ('Miramichi Centre', 2, 'Canada'),\n",
    "        ('Campeche Bank', 2, 'Mexico'),\n",
    "        ('Naumburg (Saale)', 5, 'Germany'),\n",
    "        ('plaza de Cibeles', 5, 'Spain'),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "relation_id = \"P17\"\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Jh_norm': 23.247802734375, 'bias_norm': 486.58489990234375, 'h_info': {'h_index': 2, 'token_id': 20803, 'token': 'obic'}, 'consider_residual': False}\n",
      "{'Jh_norm': 22.141036987304688, 'bias_norm': 522.3410034179688, 'h_info': {'h_index': 1, 'token_id': 9248, 'token': 'angle'}, 'consider_residual': False}\n",
      "{'Jh_norm': 26.415491104125977, 'bias_norm': 430.8843994140625, 'h_info': {'h_index': 2, 'token_id': 16590, 'token': 'ichi'}, 'consider_residual': False}\n",
      "{'Jh_norm': 46.61355209350586, 'bias_norm': 443.0304870605469, 'h_info': {'h_index': 2, 'token_id': 2395, 'token': 'che'}, 'consider_residual': False}\n",
      "{'Jh_norm': 31.205049514770508, 'bias_norm': 517.58056640625, 'h_info': {'h_index': 5, 'token_id': 1000, 'token': 'ale'}, 'consider_residual': False}\n",
      "{'Jh_norm': 17.898963928222656, 'bias_norm': 446.3467102050781, 'h_info': {'h_index': 5, 'token_id': 274, 'token': 'es'}, 'consider_residual': False}\n"
     ]
    }
   ],
   "source": [
    "relation_collection = []\n",
    "for subject, idx, target in good_cases[relation_id]:\n",
    "    relation_operator = estimate.estimate_relation_operator(\n",
    "        model, tokenizer,\n",
    "        subject, relation_dct[relation_id]['relation'],\n",
    "        layer=25, subject_token_index = idx,\n",
    "        device=model.device,\n",
    "    )\n",
    "    print(relation_operator.misc)   \n",
    "    # check_with_test_cases(relation_operator)\n",
    "    # print()\n",
    "    relation_collection.append(relation_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.594758987426758 [0.0, 16.952, 18.875, 27.862, 17.031, 19.042]\n",
      "17.02851104736328 [16.952, 0.0, 19.567, 28.279, 18.751, 20.4]\n",
      "18.64788246154785 [18.875, 19.567, 0.0, 27.658, 20.576, 20.895]\n",
      "28.792652130126953 [27.862, 28.279, 27.658, 0.0, 28.578, 24.671]\n",
      "15.542061805725098 [17.031, 18.751, 20.576, 28.578, 0.0, 19.969]\n",
      "18.99873924255371 [19.042, 20.4, 20.895, 24.671, 19.969, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for r1 in relation_collection:\n",
    "    arr = []\n",
    "    for r2 in relation_collection:\n",
    "        # print(r1.bias.norm().item(), r2.bias.norm().item(), torch.dist(r1.bias, r2.bias).item())\n",
    "        arr.append(np.round(torch.dist(r1.weight, r2.weight).item(), 3))\n",
    "    print(r1.weight.norm().item(), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "precalculated_relations = np.load(\n",
    "    \"P17/cached_jacobians/jacobian_calculations__all_sub_toks__P17__layer_25.npz\",\n",
    "    allow_pickle= True\n",
    ")['jacobians']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(precalculated_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cases = []\n",
    "for c in precalculated_relations:\n",
    "    bad_cases += c['all_weights_and_biases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.320530891418457 [0.0, 6.46, 10.998, 9.945, 6.528, 13.408]\n",
      "5.322466850280762 [6.46, 0.0, 11.687, 10.626, 7.393, 14.152]\n",
      "11.044798851013184 [10.998, 11.687, 0.0, 12.696, 11.647, 15.394]\n",
      "9.669387817382812 [9.945, 10.626, 12.696, 0.0, 10.527, 14.935]\n",
      "5.642831325531006 [6.528, 7.393, 11.647, 10.527, 0.0, 13.834]\n",
      "13.551694869995117 [13.408, 14.152, 15.394, 14.935, 13.834, 0.0]\n"
     ]
    }
   ],
   "source": [
    "relation_collection_bad = random.sample(bad_cases, 6)\n",
    "\n",
    "for r1 in relation_collection_bad:\n",
    "    r1_bias = torch.tensor(r1['weight'])\n",
    "    arr = []\n",
    "    for r2 in relation_collection_bad:\n",
    "        r2_bias = torch.tensor(r2['weight'])\n",
    "        # print(r1_bias.norm().item(), r2_bias.norm().item(), torch.dist(r1_bias, r2_bias).item())\n",
    "        arr.append(np.round(torch.dist(r1_bias, r2_bias).item(), 3))\n",
    "    print(r1_bias.norm().item(), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3439fe3f7dcaddaf51997811d25ada8e7c0985d2997d22a3ed461af94d2f9f43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
