{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from relations import estimate\n",
    "from util import model_utils\n",
    "from dsets.counterfact import CounterFactDataset\n",
    "from util import nethook\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "relation_dct = {\n",
    "    'P17'   : {'relation': '{} is located in the country of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P641'  : {'relation': '{} plays the sport of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P103'  : {'relation': 'The mother tongue of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P176'  : {'relation': '{} is produced by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P140'  : {'relation': 'The official religion of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "    # 'P1303' : {'relation': '{} plays the instrument', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P190'  : {'relation': 'What is the twin city of {}? It is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P740'  : {'relation': '{} was founded in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P178'  : {'relation': '{} was developed by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P495'  : {'relation': '{}, that originated in the country of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P127'  : {'relation': '{} is owned by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P413'  : {'relation': '{} plays in the position of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P39'   : {'relation': '{}, who holds the position of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P159'  : {'relation': 'The headquarter of {} is located in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P20'   : {'relation': '{} died in the city of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P136'  : {'relation': 'What does {} play? They play', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P106'  : {'relation': 'The profession of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P30'   : {'relation': '{} is located in the continent of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P937'  : {'relation': '{} worked in the city of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P449'  : {'relation': '{} was released on', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P27'   : {'relation': '{} is a citizen of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P101'  : {'relation': '{} works in the field of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P19'   : {'relation': '{} was born in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P37'   : {'relation': 'In {}, an official language is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P138'  : {'relation': '{}, named after', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P131'  : {'relation': '{} is located in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P407'  : {'relation': '{} was written in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P108'  : {'relation': '{}, who is employed by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P36'   : {'relation': 'The capital of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "}\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped  P131\n",
      "skipped  P407\n",
      "skipped  P108\n"
     ]
    }
   ],
   "source": [
    "root_path = \"gpt-j\"\n",
    "\n",
    "for relation in relation_dct:\n",
    "    path = f\"{root_path}/{relation}\"\n",
    "    if \"performance\" not in os.listdir(path):\n",
    "        print(\"skipped \", relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} works in the field of\n"
     ]
    }
   ],
   "source": [
    "relation_id = \"P101\"\n",
    "\n",
    "print(relation_dct[relation_id]['relation'])\n",
    "\n",
    "with open(f\"gpt-j/{relation_id}/performance\") as f:\n",
    "    performance = json.load(f)\n",
    "\n",
    "performance.sort(key = itemgetter('p@3'), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hypatia', 2, 'mathematics'),\n",
       " ('Sima Qian', 2, 'history'),\n",
       " ('Carl Menger', 2, 'economics'),\n",
       " ('Euclid', 0, 'geometry'),\n",
       " ('Michael Jackson', 1, 'musician')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consider_top = 5\n",
    "subject__top_performers = []\n",
    "object__top_performers = []\n",
    "top_performers = []\n",
    "\n",
    "for candidate in performance:\n",
    "    subject = candidate['subject']\n",
    "    sub_idx = candidate['misc']['h_info']['h_index']\n",
    "    object = candidate['object']\n",
    "    if(subject in subject__top_performers or object in object__top_performers):\n",
    "        continue\n",
    "    if(len(tokenizer(subject).input_ids) > 3):\n",
    "        continue\n",
    "    \n",
    "    subject__top_performers.append(subject)\n",
    "    object__top_performers.append(object)\n",
    "    top_performers.append((\n",
    "        subject, sub_idx, object  #, candidate['p@3']\n",
    "    ))\n",
    "\n",
    "    if(len(top_performers) == consider_top):\n",
    "        break \n",
    "\n",
    "top_performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = relation_dct[relation_id]['relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c86ea0b1414da5a13a6cf6f9ca2bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  Hypatia\n",
      "Euclid works in the field of geometry.\n",
      "Michael Jackson works in the field of musician.\n",
      "Carl Menger works in the field of economics.\n",
      "{} works in the field of\n",
      "tensor(29.5469, device='cuda:0', dtype=torch.float16) tensor(274.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Sima Qian\n",
      "Michael Jackson works in the field of musician.\n",
      "Carl Menger works in the field of economics.\n",
      "Hypatia works in the field of mathematics.\n",
      "{} works in the field of\n",
      "tensor(4.3320, device='cuda:0', dtype=torch.float16) tensor(279.5000, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Carl Menger\n",
      "Hypatia works in the field of mathematics.\n",
      "Euclid works in the field of geometry.\n",
      "Sima Qian works in the field of history.\n",
      "{} works in the field of\n",
      "tensor(23.1094, device='cuda:0', dtype=torch.float16) tensor(253.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Euclid\n",
      "Sima Qian works in the field of history.\n",
      "Carl Menger works in the field of economics.\n",
      "Michael Jackson works in the field of musician.\n",
      "{} works in the field of\n",
      "tensor(2.3203, device='cuda:0', dtype=torch.float16) tensor(303.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Michael Jackson\n",
      "Sima Qian works in the field of history.\n",
      "Hypatia works in the field of mathematics.\n",
      "Carl Menger works in the field of economics.\n",
      "{} works in the field of\n",
      "tensor(4.0391, device='cuda:0', dtype=torch.float16) tensor(295.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jbs = []\n",
    "for s, s_idx, o in tqdm(top_performers):\n",
    "    others = set(top_performers) - {(s, s_idx, o)}\n",
    "    others = random.sample(list(others), k = 3) \n",
    "    prompt = \"\"\n",
    "    prompt += \"\\n\".join(r.format(s_other) + f\" {o_other}.\" for s_other, idx_other, o_other in others) + \"\\n\"\n",
    "    prompt += r\n",
    "    print(\"subject: \", s)\n",
    "    print(prompt)\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    jb = estimate.estimate_relation_operator(\n",
    "        model, tokenizer,\n",
    "        s, prompt,\n",
    "        subject_token_index= s_idx,\n",
    "        layer = 15,\n",
    "        device = model.device,\n",
    "    )\n",
    "    print(jb.weight.norm(), jb.bias.norm())\n",
    "    print()\n",
    "    jbs.append(jb)\n",
    "\n",
    "relation = estimate.RelationOperator(\n",
    "    weight=torch.stack([jb.weight for jb in jbs]).mean(dim=0),\n",
    "    bias=torch.stack([jb.bias for jb in jbs]).mean(dim=0),\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer= 15 ,\n",
    "    relation= relation_dct[relation_id]['relation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugh Jackman >>  [' mathematics', ' philosophy', ' history', ' the', ' science']\n",
      "Michael Phelps >>  [' mathematics', ' philosophy', ' history', ' the', ' science']\n",
      "Agatha Christie >>  [' mathematics', ' philosophy', ' history', ' the', '\\n']\n",
      "Barack Obama >>  [' mathematics', ' philosophy', ' history', ' the', ' science']\n",
      "Sherlock Holmes >>  [' mathematics', ' philosophy', ' history', ' the', ' ancient']\n",
      "Alan Turing >>  [' mathematics', ' philosophy', ' history', ' the', ' ancient']\n",
      "Bill Gates >>  [' mathematics', ' philosophy', ' history', ' the', ' science']\n",
      "Michelangelo >>  [' mathematics', ' philosophy', ' history', ' the', ' science']\n"
     ]
    }
   ],
   "source": [
    "test_subjects = [\n",
    "    \"Hugh Jackman\",\n",
    "    \"Michael Phelps\",\n",
    "    \"Agatha Christie\",\n",
    "    \"Barack Obama\",\n",
    "    \"Sherlock Holmes\",\n",
    "    \"Alan Turing\",\n",
    "    \"Bill Gates\",\n",
    "    \"Michelangelo\"\n",
    "]\n",
    "\n",
    "for sub in test_subjects:\n",
    "    print(f\"{sub} >> \", relation(sub, device= model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    # (\"Statue of Liberty\", -1, \"United States\"),\n",
    "    (\"The Great Wall\", -1, \"China\"),\n",
    "    (\"Niagara Falls\", -2, \"Canada\"),\n",
    "    (\"Valdemarsvik\", -1, \"Sweden\"),\n",
    "    (\"Kyoto University\", -2, \"Japan\"),\n",
    "    (\"Hattfjelldal\", -1, \"Norway\"),\n",
    "    (\"Ginza\", -1, \"Japan\"),\n",
    "    (\"Sydney Hospital\", -2, \"Australia\"),\n",
    "    (\"Mahalangur Himal\", -1, \"Nepal\"),\n",
    "    (\"Higashikagawa\", -1, \"Japan\"),\n",
    "    (\"Trento\", -1, \"Italy\"),\n",
    "    (\"Taj Mahal\", -1, \"India\"),\n",
    "    (\"Hagia Sophia\", -1, \"Turkey\"),\n",
    "    (\"Colosseum\", -1, \"Italy\"),\n",
    "    (\"Mount Everest\", -1, \"Nepal\"),\n",
    "    (\"Valencia\", -1, \"Spain\"),\n",
    "    (\"Lake Baikal\", -1, \"Russia\"),\n",
    "    (\"Merlion Park\", -1, \"Singapore\"),\n",
    "    (\"Cologne Cathedral\", -1, \"Germany\"),\n",
    "    (\"Buda Castle\", -1, \"Hungary\")\n",
    "]\n",
    "\n",
    "def check_with_test_cases(relation_operator):\n",
    "    for subject, subject_token_index, target in test_cases:\n",
    "        objects = relation_operator(\n",
    "            subject,\n",
    "            subject_token_index=subject_token_index,\n",
    "            device=model.device,\n",
    "            return_top_k=5,\n",
    "        )\n",
    "        print(f\"{subject}, target: {target}   ==>   predicted: {objects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Great Wall, target: China   ==>   predicted: [' Italy', ' France', ' Russia', ' Germany', ' United']\n",
      "Niagara Falls, target: Canada   ==>   predicted: [' Italy', ' France', ' Germany', ' United', ' Canada']\n",
      "Valdemarsvik, target: Sweden   ==>   predicted: [' Italy', ' France', ' Finland', ' Russia', ' Germany']\n",
      "Kyoto University, target: Japan   ==>   predicted: [' Japan', ' Italy', ' France', ' United', ' Germany']\n",
      "Hattfjelldal, target: Norway   ==>   predicted: [' Italy', ' France', ' Germany', ' Finland', ' Russia']\n",
      "Ginza, target: Japan   ==>   predicted: [' Italy', ' Japan', ' France', ' Russia', ' Germany']\n",
      "Sydney Hospital, target: Australia   ==>   predicted: [' Italy', ' France', ' Australia', ' United', ' Germany']\n",
      "Mahalangur Himal, target: Nepal   ==>   predicted: [' Italy', ' France', ' India', ' Germany', ' United']\n",
      "Higashikagawa, target: Japan   ==>   predicted: [' Italy', ' Japan', ' France', ' Germany', ' United']\n",
      "Trento, target: Italy   ==>   predicted: [' Italy', ' France', ' Germany', ' United', ' Spain']\n",
      "Taj Mahal, target: India   ==>   predicted: [' Italy', ' France', ' United', ' India', ' Germany']\n",
      "Hagia Sophia, target: Turkey   ==>   predicted: [' Italy', ' Turkey', ' France', ' Russia', ' Germany']\n",
      "Colosseum, target: Italy   ==>   predicted: [' Italy', ' France', ' Spain', ' Germany', ' United']\n",
      "Mount Everest, target: Nepal   ==>   predicted: [' Italy', ' France', ' Russia', ' United', ' the']\n",
      "Valencia, target: Spain   ==>   predicted: [' Italy', ' Spain', ' France', ' Germany', ' United']\n",
      "Lake Baikal, target: Russia   ==>   predicted: [' Russia', ' Italy', ' France', ' Germany', ' United']\n",
      "Merlion Park, target: Singapore   ==>   predicted: [' Italy', ' France', ' United', ' Germany', ' the']\n",
      "Cologne Cathedral, target: Germany   ==>   predicted: [' Italy', ' Germany', ' France', ' Belgium', ' United']\n",
      "Buda Castle, target: Hungary   ==>   predicted: [' Italy', ' Germany', ' France', ' United', ' Spain']\n"
     ]
    }
   ],
   "source": [
    "check_with_test_cases(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Italy', ' France', ' United', ' Germany', ' Ireland']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation(\"Clonlara GAA\", device = model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3439fe3f7dcaddaf51997811d25ada8e7c0985d2997d22a3ed461af94d2f9f43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
