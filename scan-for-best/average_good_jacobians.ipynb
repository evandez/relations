{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from relations import estimate\n",
    "from util import model_utils\n",
    "from dsets.counterfact import CounterFactDataset\n",
    "from util import nethook\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"EleutherAI/gpt-j-6B\"  # gpt2-{medium,large,xl} or EleutherAI/gpt-j-6B\n",
    "mt = model_utils.ModelAndTokenizer(MODEL_NAME, low_cpu_mem_usage=True, torch_dtype=torch.float16)\n",
    "\n",
    "model = mt.model\n",
    "tokenizer = mt.tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_save_path = \"gpt-j/jacobians_averaged\"\n",
    "os.makedirs(jb_save_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off = 50 # minimum number of correct predictions\n",
    "\n",
    "###########################################################################\n",
    "relation_dct = {\n",
    "    'P17'   : {'relation': '{} is located in the country of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P641'  : {'relation': '{} plays the sport of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P103'  : {'relation': 'The mother tongue of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P176'  : {'relation': '{} is produced by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P140'  : {'relation': 'The official religion of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P1303' : {'relation': '{} plays the instrument', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P190'  : {'relation': 'What is the twin city of {}? It is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P740'  : {'relation': '{} was founded in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P178'  : {'relation': '{} was developed by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P495'  : {'relation': '{}, that originated in the country of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P127'  : {'relation': '{} is owned by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P413'  : {'relation': '{} plays in the position of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P39'   : {'relation': '{}, who holds the position of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P159'  : {'relation': 'The headquarter of {} is located in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P20'   : {'relation': '{} died in the city of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P136'  : {'relation': 'What does {} play? They play', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P106'  : {'relation': 'The profession of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P30'   : {'relation': '{} is located in the continent of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P937'  : {'relation': '{} worked in the city of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P449'  : {'relation': '{} was released on', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P27'   : {'relation': '{} is a citizen of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P101'  : {'relation': '{} works in the field of', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P19'   : {'relation': '{} was born in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P37'   : {'relation': 'In {}, an official language is', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P138'  : {'relation': '{}, named after', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P131'  : {'relation': '{} is located in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P407'  : {'relation': '{} was written in', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P108'  : {'relation': '{}, who is employed by', 'correct_predict': None, 'cached_JB': None},\n",
    "    'P36'   : {'relation': 'The capital of {} is', 'correct_predict': None, 'cached_JB': None},\n",
    "}\n",
    "###########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped  P1303\n",
      "skipped  P190\n",
      "skipped  P740\n",
      "skipped  P413\n",
      "skipped  P39\n",
      "skipped  P136\n",
      "skipped  P449\n",
      "skipped  P138\n",
      "skipped  P131\n",
      "skipped  P407\n",
      "skipped  P108\n"
     ]
    }
   ],
   "source": [
    "root_path = \"gpt-j\"\n",
    "\n",
    "for relation in relation_dct:\n",
    "    path = f\"{root_path}/{relation}\"\n",
    "    with open(f\"{path}/correct_prediction_{relation}.json\") as f:\n",
    "        correct_predictions = json.load(f)\n",
    "    if(len(correct_predictions) < cut_off):\n",
    "    # if \"performance\" not in os.listdir(path):\n",
    "        print(\"skipped \", relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{} is located in the country of\n"
     ]
    }
   ],
   "source": [
    "relation_id = \"P17\"\n",
    "\n",
    "print(relation_dct[relation_id]['relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Umarex', 2, 'Germany'),\n",
       " ('Harnaut', 2, 'India'),\n",
       " ('Haut Atlas', 2, 'Morocco'),\n",
       " ('Ufa', 1, 'Russia'),\n",
       " ('Canada Live', 1, 'Canada')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top_performers(relation_id, consider_top = 5):\n",
    "    with open(f\"gpt-j/{relation_id}/performance\") as f:\n",
    "        performance = json.load(f)\n",
    "    performance.sort(key = itemgetter('p@3'), reverse=True)\n",
    "\n",
    "    subject__top_performers = []\n",
    "    object__top_performers = []\n",
    "    top_performers = []\n",
    "\n",
    "    for candidate in performance:\n",
    "        subject = candidate['subject']\n",
    "        try:\n",
    "            sub_idx = candidate['misc']['h_info']['sub_index']\n",
    "        except:\n",
    "            sub_idx = candidate['misc']['h_info']['h_index']\n",
    "        object = candidate['object']\n",
    "        if(subject in subject__top_performers or object in object__top_performers):\n",
    "            continue\n",
    "        if(len(tokenizer(subject).input_ids) > 3):\n",
    "            continue\n",
    "        \n",
    "        subject__top_performers.append(subject)\n",
    "        object__top_performers.append(object)\n",
    "        top_performers.append((\n",
    "            subject, sub_idx, object  #, candidate['p@3']\n",
    "        ))\n",
    "\n",
    "        if(len(top_performers) == consider_top):\n",
    "            break\n",
    "    return top_performers\n",
    "\n",
    "top_performers = get_top_performers(relation_id)\n",
    "top_performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{} is located in the country of'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = relation_dct[relation_id]['relation']\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ec5dbcf0e74847a13d9f0382f87523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  Umarex\n",
      "Haut Atlas is located in the country of Morocco.\n",
      "Canada Live is located in the country of Canada.\n",
      "Harnaut is located in the country of India.\n",
      "{} is located in the country of\n",
      "tensor(21.9531, device='cuda:0', dtype=torch.float16) tensor(342.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Harnaut\n",
      "Ufa is located in the country of Russia.\n",
      "Haut Atlas is located in the country of Morocco.\n",
      "Canada Live is located in the country of Canada.\n",
      "{} is located in the country of\n",
      "tensor(23.3281, device='cuda:0', dtype=torch.float16) tensor(306., device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Haut Atlas\n",
      "Umarex is located in the country of Germany.\n",
      "Canada Live is located in the country of Canada.\n",
      "Ufa is located in the country of Russia.\n",
      "{} is located in the country of\n",
      "tensor(10.4453, device='cuda:0', dtype=torch.float16) tensor(323., device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Ufa\n",
      "Haut Atlas is located in the country of Morocco.\n",
      "Umarex is located in the country of Germany.\n",
      "Harnaut is located in the country of India.\n",
      "{} is located in the country of\n",
      "tensor(1.9551, device='cuda:0', dtype=torch.float16) tensor(320.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Canada Live\n",
      "Harnaut is located in the country of India.\n",
      "Ufa is located in the country of Russia.\n",
      "Umarex is located in the country of Germany.\n",
      "{} is located in the country of\n",
      "tensor(18.2031, device='cuda:0', dtype=torch.float16) tensor(324.7500, device='cuda:0', dtype=torch.float16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_averaged_JB(top_performers, relation_prompt, num_icl = 3):\n",
    "    jbs = []\n",
    "    for s, s_idx, o in tqdm(top_performers):\n",
    "        others = set(top_performers) - {(s, s_idx, o)}\n",
    "        others = random.sample(list(others), k = min(num_icl, len(list(others)))) \n",
    "        prompt = \"\"\n",
    "        prompt += \"\\n\".join(relation_prompt.format(s_other) + f\" {o_other}.\" for s_other, idx_other, o_other in others) + \"\\n\"\n",
    "        prompt += relation_prompt\n",
    "        print(\"subject: \", s)\n",
    "        print(prompt)\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        jb = estimate.estimate_relation_operator(\n",
    "            model, tokenizer,\n",
    "            s, prompt,\n",
    "            subject_token_index= s_idx,\n",
    "            layer = 15,\n",
    "            device = model.device,\n",
    "        )\n",
    "        print(jb.weight.norm(), jb.bias.norm())\n",
    "        print()\n",
    "        jbs.append(jb)\n",
    "    \n",
    "    weight = torch.stack([jb.weight for jb in jbs]).mean(dim=0)\n",
    "    bias  = torch.stack([jb.bias for jb in jbs]).mean(dim=0)\n",
    "\n",
    "    return weight, bias\n",
    "\n",
    "weight, bias = get_averaged_JB(top_performers, r)\n",
    "relation = estimate.RelationOperator(\n",
    "    weight=weight,\n",
    "    bias=bias,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer= 15 ,\n",
    "    relation= relation_dct[relation_id]['relation'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_subjects = [\n",
    "#     \"Hugh Jackman\",\n",
    "#     \"Michael Phelps\",\n",
    "#     \"Agatha Christie\",\n",
    "#     \"Barack Obama\",\n",
    "#     \"Sherlock Holmes\",\n",
    "#     \"Alan Turing\",\n",
    "#     \"Bill Gates\",\n",
    "#     \"Michelangelo\"\n",
    "# ]\n",
    "\n",
    "# for sub in test_subjects:\n",
    "#     print(f\"{sub} >> \", relation(sub, device= model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Great Wall, target: China   ==>   predicted: [' China', ' Russia', ' Canada', ' Germany', ' India']\n",
      "Niagara Falls, target: Canada   ==>   predicted: [' Canada', ' Germany', ' United', ' Russia', ' Switzerland']\n",
      "Valdemarsvik, target: Sweden   ==>   predicted: [' Canada', ' Germany', ' Russia', ' Sweden', ' France']\n",
      "Kyoto University, target: Japan   ==>   predicted: [' Japan', ' Canada', ' Russia', ' India', ' Germany']\n",
      "Hattfjelldal, target: Norway   ==>   predicted: [' Canada', ' Germany', ' Russia', ' Switzerland', ' Norway']\n",
      "Ginza, target: Japan   ==>   predicted: [' Japan', ' Russia', ' Canada', ' Germany', ' France']\n",
      "Sydney Hospital, target: Australia   ==>   predicted: [' Australia', ' Canada', ' France', ' Germany', ' India']\n",
      "Mahalangur Himal, target: Nepal   ==>   predicted: [' India', ' Canada', ' Russia', ' Germany', ' Switzerland']\n",
      "Higashikagawa, target: Japan   ==>   predicted: [' Japan', ' Canada', ' Germany', ' Russia', ' India']\n",
      "Trento, target: Italy   ==>   predicted: [' Italy', ' Germany', ' Switzerland', ' Canada', ' France']\n",
      "Taj Mahal, target: India   ==>   predicted: [' India', ' Canada', ' Russia', ' Germany', ' United']\n",
      "Hagia Sophia, target: Turkey   ==>   predicted: [' Turkey', ' Russia', ' Germany', ' Canada', ' France']\n",
      "Colosseum, target: Italy   ==>   predicted: [' Italy', ' Canada', ' Germany', ' France', ' Switzerland']\n",
      "Mount Everest, target: Nepal   ==>   predicted: [' India', ' Canada', ' Russia', ' China', ' Switzerland']\n",
      "Valencia, target: Spain   ==>   predicted: [' Spain', ' France', ' Canada', ' Germany', ' Switzerland']\n",
      "Lake Baikal, target: Russia   ==>   predicted: [' Russia', ' Germany', ' Canada', ' India', ' France']\n",
      "Merlion Park, target: Singapore   ==>   predicted: [' Canada', ' Germany', ' India', ' United', ' Russia']\n",
      "Cologne Cathedral, target: Germany   ==>   predicted: [' Germany', ' France', ' Canada', ' Switzerland', ' Russia']\n",
      "Buda Castle, target: Hungary   ==>   predicted: [' Germany', ' Austria', ' Russia', ' Canada', ' France']\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    # (\"Statue of Liberty\", -1, \"United States\"),\n",
    "    (\"The Great Wall\", -1, \"China\"),\n",
    "    (\"Niagara Falls\", -2, \"Canada\"),\n",
    "    (\"Valdemarsvik\", -1, \"Sweden\"),\n",
    "    (\"Kyoto University\", -2, \"Japan\"),\n",
    "    (\"Hattfjelldal\", -1, \"Norway\"),\n",
    "    (\"Ginza\", -1, \"Japan\"),\n",
    "    (\"Sydney Hospital\", -2, \"Australia\"),\n",
    "    (\"Mahalangur Himal\", -1, \"Nepal\"),\n",
    "    (\"Higashikagawa\", -1, \"Japan\"),\n",
    "    (\"Trento\", -1, \"Italy\"),\n",
    "    (\"Taj Mahal\", -1, \"India\"),\n",
    "    (\"Hagia Sophia\", -1, \"Turkey\"),\n",
    "    (\"Colosseum\", -1, \"Italy\"),\n",
    "    (\"Mount Everest\", -1, \"Nepal\"),\n",
    "    (\"Valencia\", -1, \"Spain\"),\n",
    "    (\"Lake Baikal\", -1, \"Russia\"),\n",
    "    (\"Merlion Park\", -1, \"Singapore\"),\n",
    "    (\"Cologne Cathedral\", -1, \"Germany\"),\n",
    "    (\"Buda Castle\", -1, \"Hungary\")\n",
    "]\n",
    "\n",
    "def check_with_test_cases(relation_operator):\n",
    "    for subject, subject_token_index, target in test_cases:\n",
    "        objects = relation_operator(\n",
    "            subject,\n",
    "            subject_token_index=subject_token_index,\n",
    "            device=model.device,\n",
    "            return_top_k=5,\n",
    "        )\n",
    "        print(f\"{subject}, target: {target}   ==>   predicted: {objects}\")\n",
    "\n",
    "check_with_test_cases(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-j/jacobians_averaged/P17.npz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mjb_save_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrelation_id\u001b[39m}\u001b[39;00m\u001b[39m.npz\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m np\u001b[39m.\u001b[39msavez(\n\u001b[1;32m      4\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mjb_save_path\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mrelation_id\u001b[39m}\u001b[39;00m\u001b[39m.npz\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m     JB \u001b[39m=\u001b[39m {\n\u001b[0;32m----> 6\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m: weight\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m      7\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m  : bias\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m      8\u001b[0m     },\n\u001b[1;32m      9\u001b[0m     allow_pickle \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weight' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"{jb_save_path}/{relation_id}.npz\")\n",
    "\n",
    "np.savez(\n",
    "    f\"{jb_save_path}/{relation_id}.npz\", \n",
    "    JB = {\n",
    "        'weight': weight.cpu().numpy(),\n",
    "        'bias'  : bias.cpu().numpy()\n",
    "    },\n",
    "    allow_pickle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-j/P36'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{root_path}/{relation}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\n",
      "P407 {} was written in\n",
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\n",
      "29\n",
      "skipped P407 >>  29\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\n",
      "P108 {}, who is employed by\n",
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\n",
      "43\n",
      "skipped P108 >>  43\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\n",
      "P36 The capital of {} is\n",
      "zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\n",
      "68\n",
      "The capital of {} is\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e49e1139a54f538af2f08517069d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  United Arab Republic\n",
      "The capital of Lazio is Rome.\n",
      "The capital of Demerara is Georgetown.\n",
      "The capital of Saxony is Dresden.\n",
      "The capital of {} is\n",
      "tensor(33.5938, device='cuda:0', dtype=torch.float16) tensor(205.1250, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Saxony\n",
      "The capital of Demerara is Georgetown.\n",
      "The capital of South Yemen is Aden.\n",
      "The capital of United Arab Republic is Cairo.\n",
      "The capital of {} is\n",
      "tensor(30.6875, device='cuda:0', dtype=torch.float16) tensor(186.8750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Demerara\n",
      "The capital of United Arab Republic is Cairo.\n",
      "The capital of Lazio is Rome.\n",
      "The capital of Saxony is Dresden.\n",
      "The capital of {} is\n",
      "tensor(44.0312, device='cuda:0', dtype=torch.float16) tensor(183.8750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  South Yemen\n",
      "The capital of Demerara is Georgetown.\n",
      "The capital of United Arab Republic is Cairo.\n",
      "The capital of Lazio is Rome.\n",
      "The capital of {} is\n",
      "tensor(38.3125, device='cuda:0', dtype=torch.float16) tensor(204.2500, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "subject:  Lazio\n",
      "The capital of Saxony is Dresden.\n",
      "The capital of United Arab Republic is Cairo.\n",
      "The capital of South Yemen is Aden.\n",
      "The capital of {} is\n",
      "tensor(31.0312, device='cuda:0', dtype=torch.float16) tensor(190.3750, device='cuda:0', dtype=torch.float16)\n",
      "\n",
      "Saving weights and biases >>  gpt-j/jacobians_averaged/P36.npz\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for relation_id in relation_dct:\n",
    "    print(\"zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\")\n",
    "    print(relation_id, relation_dct[relation_id]['relation'])\n",
    "    print(\"zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz\")\n",
    "    path = f\"{root_path}/{relation_id}\"\n",
    "    try:\n",
    "        with open(f\"{path}/correct_prediction_{relation_id}.json\") as f:\n",
    "            correct_predictions = json.load(f)\n",
    "            print(len(correct_predictions))\n",
    "    except:\n",
    "        print(f\"Error opening correct prediction {relation_id} (maybe the scan skipped this relation?)\")\n",
    "        print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "        continue\n",
    "        \n",
    "    if(len(correct_predictions) < cut_off):\n",
    "        print(f\"skipped {relation_id} >> \", len(correct_predictions))\n",
    "        print(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "        continue\n",
    "\n",
    "    top_performers = get_top_performers(relation_id)\n",
    "\n",
    "    relation_prompt = relation_dct[relation_id]['relation']\n",
    "    print(relation_prompt)\n",
    "\n",
    "    weight, bias = get_averaged_JB(top_performers, relation_prompt)\n",
    "\n",
    "    save_path = f\"{jb_save_path}/{relation_id}.npz\"\n",
    "    print(\"Saving weights and biases >> \", save_path)\n",
    "    np.savez(\n",
    "        save_path, \n",
    "        JB = {\n",
    "            'weight': weight.cpu().numpy(),\n",
    "            'bias'  : bias.cpu().numpy()\n",
    "        },\n",
    "        allow_pickle = True\n",
    "    )\n",
    "    print(\"----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3439fe3f7dcaddaf51997811d25ada8e7c0985d2997d22a3ed461af94d2f9f43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
